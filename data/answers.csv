Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,OwnerUserId,OwnerDisplayName,LastEditorUserId,LastEditorDisplayName,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense
"65649022","2","","65648897","2021-01-10 00:27:05","","88","","<p>Indeed, C++20 unfortunately makes this code infinitely recursive.</p>
<p>Here's a reduced example:</p>
<pre class=""lang-cpp prettyprint-override""><code>struct F {
    /*implicit*/ F(int t_) : t(t_) {}

    // member: #1
    bool operator==(F const&amp; o) const { return t == o.t; }

    // non-member: #2
    friend bool operator==(const int&amp; y, const F&amp; x) { return x == y; }

private:
    int t;
};
</code></pre>
<p>Let's just look at <code>42 == F{42}</code>.</p>
<p>In C++17, we only had one candidate: the non-member candidate (<code>#2</code>), so we select that. Its body, <code>x == y</code>, itself only has one candidate: the member candidate (<code>#1</code>) which involves implicitly converting <code>y</code> into an <code>F</code>. And then that member candidate compares the two integer members and this is totally fine.</p>
<p>In C++20, the initial expression <code>42 == F{42}</code> now has <em>two</em> candidates: both the non-member candidate (<code>#2</code>) as before and now also the reversed member candidate (<code>#1</code> reversed). <code>#2</code> is the better match - we exactly match both arguments instead of invoking a conversion, so it's selected.</p>
<p>Now, however, <code>x == y</code> now has <em>two</em> candidates: the member candidate again (<code>#1</code>), but also the reversed non-member candidate (<code>#2</code> reversed). <code>#2</code> is the better match again for the same reason that it was a better match before: no conversions necessary. So we evaluate <code>y == x</code> instead. Infinite recursion.</p>
<p>Non-reversed candidates are preferred to reversed candidates, but only as a tiebreaker. Better conversion sequence is always first.</p>
<hr />
<p>Okay great, how can we fix it? The simplest option is removing the non-member candidate entirely:</p>
<pre class=""lang-cpp prettyprint-override""><code>struct F {
    /*implicit*/ F(int t_) : t(t_) {}

    bool operator==(F const&amp; o) const { return t == o.t; }

private:
    int t;
};
</code></pre>
<p><code>42 == F{42}</code> here evaluates as <code>F{42}.operator==(42)</code>, which works fine.</p>
<p>If we want to keep the non-member candidate, we can add its reversed candidate explicitly:</p>
<pre class=""lang-cpp prettyprint-override""><code>struct F {
    /*implicit*/ F(int t_) : t(t_) {}
    bool operator==(F const&amp; o) const { return t == o.t; }
    bool operator==(int i) const { return t == i; }
    friend bool operator==(const int&amp; y, const F&amp; x) { return x == y; }

private:
    int t;
};
</code></pre>
<p>This makes <code>42 == F{42}</code> still choose the non-member candidate, but now <code>x == y</code> in the body there will prefer the member candidate, which then does the normal equality.</p>
<p>This last version can also remove the non-member candidate. The following also works without recursion for all test cases (and is how I would write comparisons in C++20 going forward):</p>
<pre class=""lang-cpp prettyprint-override""><code>struct F {
    /*implicit*/ F(int t_) : t(t_) {}
    bool operator==(F const&amp; o) const { return t == o.t; }
    bool operator==(int i) const { return t == i; }

private:
    int t;
};
</code></pre>
","2069064","","","","","2021-01-10 00:27:05","","","","6","","","","CC BY-SA 4.0"
"66497568","2","","66497269","2021-03-05 18:13:13","","46","","<p>The basic problem comes from the facts that your type is incoherent and the standard library didn't call you on it until C++20. That is, your type was always kind of broken, but things were narrowly enough defined that you could get away with it.</p>
<p>Your type is broken because its comparison operators make no sense. It <em>advertises</em> that it is fully comparable, with all of the available comparison operators defined. This happens because you publicly inherited from <code>std::string</code>, so your type inherits those operators by implicit conversion to the base class. But the <em>behavior</em> of this slate of comparisons is incorrect because you replaced only one of them with a comparison that doesn't work like the rest.</p>
<p>And since the behavior is inconsistent, what could happen is up for grabs once C++ actually cares about you being consistent.</p>
<p>A larger problem however is an inconsistency with how the standard treats <code>operator&lt;=&gt;</code>.</p>
<p>The C++ language is designed to give priority to explicitly defined comparison operators <em>before</em> employing synthesized operators. So your type inherited from <code>std::string</code> will use your <code>operator&lt;</code> if you compare them directly.</p>
<p>C++ the library however sometimes tries to be clever.</p>
<p>Some types attempt to forward the operators provided by a given type, like <code>optional&lt;T&gt;</code>. It is designed to behave identically to <code>T</code> in its comparability, and it succeeds at this.</p>
<p>However, <code>pair</code> and <code>tuple</code> try to be a bit clever. In C++17, these types never <em>actually</em> forwarded comparison behavior; instead, it <em>synthesized</em> comparison behavior based on existing <code>operator&lt;</code> and <code>operator==</code> definitions on the types.</p>
<p>So it's no surprise that their C++20 incarnations continue that fine tradition of synthesizing comparisons. Of course, since the <em>language</em> got in on that game, the C++20 versions decided that it was best to just follow their rules.</p>
<p>Except... it couldn't follow them <em>exactly</em>. There's no way to detect whether a <code>&lt;</code> comparison is synthesized or user-provided. So there's no way to implement the language behavior in one of these types. However, you <em>can</em> detect the presence of three-way comparison behavior.</p>
<p>So they make an assumption: if your type is three-way comparable, then your type is relying on synthesized operators (if it isn't, it uses an improved form of the old method). Which is the right assumption; after all, since <code>&lt;=&gt;</code> is a new feature, old types can't possibly get one.</p>
<p>Unless of course an old type inherits from a new type that gained three-way comparability. And there's no way for a type to detect that either; it either is three-way comparable or it isn't.</p>
<p>Now fortunately, the synthesized three-way comparison operators of <code>pair</code> and <code>tuple</code> are perfectly capable of mimicking the C++17 behavior if your type <em>doesn't</em> offer three-way comparison functionality. So you can get back the old behavior by explicitly dis-inheriting the three-way comparison operator in C++20 by deleting the <code>operator&lt;=&gt;</code> overload.</p>
<p>Alternatively, you could use private inheritance and simply publicly <code>using</code> the specific APIs you wanted.</p>
<blockquote>
<p>Is the behavior change in c++20 correct/on purpose?</p>
</blockquote>
<p>That depends on what you mean by &quot;on purpose&quot;.</p>
<p>Publicly inheriting from types like <code>std::string</code> has always been somewhat morally dubious. Not so much because of the slicing/destructor problem, but more because it is kind of a cheat. Inheriting such types directly opens you up to changes in the API that you didn't expect and may not be appropriate for your type.</p>
<p>The new comparison version of <code>pair</code> and <code>tuple</code> are doing their jobs and doing them as best as C++ can permit. It's just that your type inherited something it didn't want. If you had privately inherited from <code>std::string</code> and only <code>using</code>-exposed the functionality you wanted, your type would likely be fine.</p>
<blockquote>
<p>Should there be a diagnostic?</p>
</blockquote>
<p>This can't be diagnosed outside of some compiler-intrinsic.</p>
<blockquote>
<p>Can we use other tools to spot silent breakage like this?</p>
</blockquote>
<p>Search for case where you're publicly inheriting from standard library types.</p>
","734069","","4850040","","2021-03-07 10:10:23","2021-03-07 10:10:23","","","","6","","","","CC BY-SA 4.0"
"66497576","2","","66497269","2021-03-05 18:13:46","","12","","<p>Ah! @StoryTeller nailed it with their <a href=""https://stackoverflow.com/questions/66497269/more-silent-behaviour-changes-with-c20-three-way-comparison#comment117556163_66497269"">comment</a>:</p>
<blockquote>
<p>&quot;my type doesn't define operator&lt;=&gt; nor operator==&quot; - but <code>std::string</code> does, making it a candidate due to the d[e]rived-to-base conversion. I believe all standard library types that support comparison had their members overhauled.</p>
</blockquote>
<p>Indeed, a much quicker work-around is:</p>
<pre><code>#if defined(__cpp_lib_three_way_comparison)
    std::weak_ordering operator&lt;=&gt;(
        CiKey const&amp;) const = delete;
#endif
</code></pre>
<p>Success! <a href=""https://godbolt.org/z/qEshYb"" rel=""noreferrer"">Compiler Explorer</a></p>
<h2>Better Ideas</h2>
<p>Better solution, as hinted by StoryTeller's <a href=""https://stackoverflow.com/questions/66497269/more-silent-behaviour-changes-with-c20-three-way-comparison#comment117556259_66497269"">second comment</a>:</p>
<blockquote>
<p>I guess non-virtual destructors are no longer the sole compelling reason to avoid inheriting from standard library containers :/</p>
</blockquote>
<p>Would be to avoid inheritance here:</p>
<pre><code>// represents case insensiive keys
struct CiKey {
    std::string _value;

    bool operator&lt;(CiKey const&amp; other) const {
        return boost::ilexicographical_compare(_value, other._value);
    }
};
</code></pre>
<p>Of course this requires (some) downstream changes to the using code, but it's conceptually purer and insulates against this type of &quot;standard creep&quot; in the future.</p>
<p><strong><a href=""https://godbolt.org/z/Moo6hb"" rel=""noreferrer"">Compiler Explorer</a></strong></p>
<pre><code>#include &lt;boost/algorithm/string.hpp&gt;
#include &lt;iostream&gt;
#include &lt;set&gt;
#include &lt;version&gt;

// represents case insensiive keys
struct CiKey {
    std::string _value;

    bool operator&lt;(CiKey const&amp; other) const {
        return boost::ilexicographical_compare(_value, other._value);
    }
};

using KeySet   = std::set&lt;CiKey&gt;;
using Mapping  = std::tuple&lt;CiKey, int&gt;;
using Mappings = std::set&lt;Mapping&gt;;

int main()
{
    KeySet keys { { &quot;one&quot; }, { &quot;two&quot; }, { &quot;ONE&quot; }, { &quot;three&quot; } };
    Mappings mappings { { { &quot;one&quot; }, 1 }, { { &quot;two&quot; }, 2 }, { { &quot;ONE&quot; }, 1 },
        { { &quot;three&quot; }, 3 } };

    assert(keys.size() == 3);
    assert(mappings.size() == 3);
}
</code></pre>
<h2>Remaining Questions</h2>
<p>How can we diagnose problems like these. They're so subtle they <strong>will</strong> escape code review. The situation is exacerbated by there being 2 decades of standard C++ where this worked perfectly fine and predictably.</p>
<blockquote>
<p>I guess as a sidenote, we can expect any &quot;lifted&quot; operators (thinking of std::variant/std::optional) to have similar pitfalls when used with user-defined types that inherit <em>too much</em> from standard library types.</p>
</blockquote>
","85371","","85371","","2021-03-05 21:42:59","2021-03-05 21:42:59","","","","4","","","","CC BY-SA 4.0"
"62542633","2","","62496779","2020-06-23 19:48:15","","36","","<p>Currently you cannot open an elevated <code>wt.exe</code> session from the command line without workarounds. Workarounds include using <a href=""https://github.com/microsoft/terminal/issues/632#issuecomment-616740964"" rel=""noreferrer"">gsudo</a>, Using <a href=""https://github.com/microsoft/terminal/issues/632#issuecomment-616740964"" rel=""noreferrer"">Task Scheduler</a> (I tested this one and it works but you need to use the full path to wt.exe and you can skip the shortcut creation step) OR if you are ok with a keyboard shortcut, the simplest way; using a keyboard shortcut to run Windows Terminal as Admin from the taskbar.</p>
<p>For your use case:</p>
<blockquote>
<p>For my specific instance, I simply want to make it simpler to pop open
an admin terminal, I don't need a way to elevate arbitrary commands,
then I will happily use the commands I have already shown here.</p>
</blockquote>
<p>The simplest approach will work:</p>
<p><strong>Pin Windows Terminal as the first item on the task bar. Then hit Win+Ctrl+Shift+1 to open it as admin.</strong></p>
<p>If you really must launch Windows Terminal from the command line from within Windows Terminal then create a task in the Task Scheduler:</p>
<ol>
<li>Give the task a name, check 'Run with highest privileges'.</li>
<li>Choose the 'Actions' tab, click 'New', select 'Start a program' as the action. Put the full path to <code>wt.exe</code> in the 'Program/script field'. Click OK. Click OK again.</li>
<li>Click 'Conditions' tab, uncheck &quot;Start the task only if the computer is on AC power&quot;.</li>
<li>Click 'Settings' tab, make sure &quot;Allow task to be run on demand&quot; is checked and uncheck &quot;Stop the task if running for longer than&quot;.</li>
<li>Finally in your shell (Powershell), launch an elevated Windows Terminal session by running the command: <code>schtasks /run /TN &quot;TASK_NAME&quot;</code> where TASK_NAME is the name you gave the task in step 1.</li>
</ol>
","5705559","","5705559","","2020-10-08 15:53:31","2020-10-08 15:53:31","","","","4","","","","CC BY-SA 4.0"
"63019725","2","","62496779","2020-07-21 17:19:08","","2","","<p>In my particular case I also need Windows Terminal opened as administrator all the time. This is what I did, run &quot;where wt&quot; to display the path where Windows Terminal application exe is located, it should be C:\Users\YOURUSER\AppData\Local\Microsoft\WindowsApps\wt.exe.
I created a shortcut to that file and checked &quot;Run as administrator&quot; in the advanced properties, then I just pinned it to start and voila. You can delete your temporary shortcut after that if you want.</p>
","13221865","","","","","2020-07-21 17:19:08","","","","1","","","","CC BY-SA 4.0"
"63163528","2","","62496779","2020-07-29 22:42:24","","17","","<p>Try this:</p>
<pre><code>powershell &quot;Start-Process -Verb RunAs cmd.exe '/c start wt.exe'&quot;
</code></pre>
<p>Also check out these links:</p>
<p>WT.exe command line arguments:
<a href=""https://learn.microsoft.com/en-us/windows/terminal/command-line-arguments?tabs=windows"" rel=""noreferrer"">https://learn.microsoft.com/en-us/windows/terminal/command-line-arguments?tabs=windows</a></p>
<p>Article about adding Open Windows Terminal Command Prompt to the context menu in Explorer (includes Admin):
<a href=""https://dkcool.tailnet.net/2020/07/add-open-windows-terminal-command-prompt-to-the-explorer-context-menu-in-windows-10/"" rel=""noreferrer"">https://dkcool.tailnet.net/2020/07/add-open-windows-terminal-command-prompt-to-the-explorer-context-menu-in-windows-10/</a></p>
<p>Article about adding Open Admin Command Prompt to the context menu in Explorer:
<a href=""https://dkcool.tailnet.net/2019/05/add-open-admin-command-prompt-to-the-explorer-context-menu-in-windows-10/"" rel=""noreferrer"">https://dkcool.tailnet.net/2019/05/add-open-admin-command-prompt-to-the-explorer-context-menu-in-windows-10/</a></p>
","5760389","","5760389","","2020-07-31 14:15:06","2020-07-31 14:15:06","","","","1","","","","CC BY-SA 4.0"
"66508809","2","","66497269","2021-03-06 17:48:16","","3","","<p>This is not really an answer on the different behaviors of <code>std::string::operator=()</code>, but I must point out that creating case insensitive strings should be done via customization template parameter <code>Traits</code>.</p>
<p>Example:</p>
<pre><code>// definition of basic_string:
template&lt;
    class CharT,
    class Traits = std::char_traits&lt;CharT&gt;,   // &lt;- this is the customization point.
    class Allocator = std::allocator&lt;CharT&gt;
&gt; class basic_string;
</code></pre>
<p>The example of case-insensitive string comes almost straight out from cppreference (<a href=""https://en.cppreference.com/w/cpp/string/char_traits"" rel=""nofollow noreferrer"">https://en.cppreference.com/w/cpp/string/char_traits</a>).  I've added <code>using</code> directives for case-insensitive strings.</p>
<pre><code>#include &lt;cctype&gt;
#include &lt;cwctype&gt;
#include &lt;iostream&gt;
#include &lt;locale&gt;
#include &lt;string&gt;
#include &lt;version&gt;

template &lt;typename CharT&gt; struct ci_traits : public std::char_traits&lt;CharT&gt;
{
    #ifdef __cpp_lib_constexpr_char_traits
    #define CICE constexpr
    #endif

private:
    using base = std::char_traits&lt;CharT&gt;;
    using int_type = typename base::int_type;

    static CICE CharT to_upper(CharT ch)
    {
        if constexpr (sizeof(CharT) == 1)
            return std::toupper(static_cast&lt;unsigned char&gt;(ch));
        else
            return std::toupper(CharT(ch &amp; 0xFFFF), std::locale{});
    }

public:
    using base::to_int_type;
    using base::to_char_type;

    static CICE bool eq(CharT c1, CharT c2)
    {
        return to_upper(c1) == to_upper(c2);
    }
    static CICE bool lt(CharT c1, CharT c2)
    {
        return to_upper(c1) &lt; to_upper(c2);
    }
    static CICE bool eq_int_type(const int_type&amp; c1, const int_type&amp; c2)
    {
        return to_upper(to_char_type(c1)) == to_upper(to_char_type(c2));
    }
    static CICE int compare(const CharT *s1, const CharT *s2, std::size_t n)
    {
        while (n-- != 0)
        {
            if (to_upper(*s1) &lt; to_upper(*s2))
                return -1;
            if (to_upper(*s1) &gt; to_upper(*s2))
                return 1;
            ++s1;
            ++s2;
        }
        return 0;
    }
    static CICE const CharT *find(const CharT *s, std::size_t n, CharT a)
    {
        auto const ua(to_upper(a));
        while (n-- != 0) {
            if (to_upper(*s) == ua)
                return s;
            s++;
        }
        return nullptr;
    }
    #undef CICE
};

using ci_string = std::basic_string&lt;char, ci_traits&lt;char&gt;&gt;;
using ci_wstring = std::basic_string&lt;wchar_t, ci_traits&lt;wchar_t&gt;&gt;;

// TODO consider constexpr support
template &lt;typename CharT, typename Alloc&gt;
inline std::basic_string&lt;CharT, std::char_traits&lt;CharT&gt;, Alloc&gt; string_cast(
    const std::basic_string&lt;CharT, ci_traits&lt;CharT&gt;, Alloc&gt; &amp;src)
{
    return std::basic_string&lt;CharT, std::char_traits&lt;CharT&gt;, Alloc&gt;{
        src.begin(), src.end(), src.get_allocator()};
}

template &lt;typename CharT, typename Alloc&gt;
inline std::basic_string&lt;CharT, ci_traits&lt;CharT&gt;, Alloc&gt; ci_string_cast(
    const std::basic_string&lt;CharT, std::char_traits&lt;CharT&gt;, Alloc&gt; &amp;src)
{
    return std::basic_string&lt;CharT, ci_traits&lt;CharT&gt;&gt;{src.begin(), src.end(),
                                                    src.get_allocator()};
}

int main(int argc, char**) {
    if (argc&lt;=1)
    {
        std::cout &lt;&lt; &quot;char\n&quot;;
        ci_string hello = &quot;hello&quot;;
        ci_string Hello = &quot;Hello&quot;;

        // convert a ci_string to a std::string
        std::string x = string_cast(hello);

        // convert a std::string to a ci_string
        auto ci_hello = ci_string_cast(x);

        if (hello == Hello)
            std::cout &lt;&lt; string_cast(hello) &lt;&lt; &quot; and &quot; &lt;&lt; string_cast(Hello)
                    &lt;&lt; &quot; are equal\n&quot;;

        if (hello == &quot;HELLO&quot;)
            std::cout &lt;&lt; string_cast(hello) &lt;&lt; &quot; and &quot;
                    &lt;&lt; &quot;HELLO&quot;
                    &lt;&lt; &quot; are equal\n&quot;;
    }
    else
    {
        std::cout &lt;&lt; &quot;wchar_t\n&quot;;
        ci_wstring hello = L&quot;hello&quot;;
        ci_wstring Hello = L&quot;Hello&quot;;

        // convert a ci_wstring to a std::wstring
        std::wstring x = string_cast(hello);

        // convert a std::wstring to a ci_wstring
        auto ci_hello = ci_string_cast(x);

        if (hello == Hello)
            std::wcout &lt;&lt; string_cast(hello) &lt;&lt; L&quot; and &quot; &lt;&lt; string_cast(Hello) &lt;&lt; L&quot; are equal\n&quot;;

        if (hello == L&quot;HELLO&quot;)
            std::wcout &lt;&lt; string_cast(hello) &lt;&lt; L&quot; and &quot; &lt;&lt; L&quot;HELLO&quot; &lt;&lt; L&quot; are equal\n&quot;;
    }
}
</code></pre>
<p>You can play with it here:  <a href=""https://godbolt.org/z/5ec5sz"" rel=""nofollow noreferrer"">https://godbolt.org/z/5ec5sz</a></p>
","2430669","","1069068","","2021-03-07 07:33:44","2021-03-07 07:33:44","","","","6","","","","CC BY-SA 4.0"
"63482410","2","","62496779","2020-08-19 07:54:20","","15","","<p>Not a direct answer but another option if you have <a href=""https://github.com/microsoft/PowerToys"" rel=""noreferrer"">PowerToys</a> is to:</p>
<ol>
<li>Alt + Space, type Terminal,</li>
<li>Select Run as Administrator (or Ctrl + Shift + Enter)</li>
</ol>
<p>You can install PowerToys using <a href=""https://github.com/microsoft/winget-cli"" rel=""noreferrer"">WinGet</a></p>
","1400202","","1400202","","2021-02-23 04:23:50","2021-02-23 04:23:50","","","","2","","","","CC BY-SA 4.0"
"64600593","2","","62496779","2020-10-29 23:25:46","","2","","<p>You can create a shortcut to always run Windows Terminal as administrator using this powershell script:</p>
<pre><code>$WshShell = New-Object -comObject WScript.Shell
$Shortcut = $WshShell.CreateShortcut(&quot;$Home\Desktop\Windows Terminal.lnk&quot;)
$Shortcut.TargetPath = &quot;$env:LOCALAPPDATA\Microsoft\WindowsApps\Microsoft.WindowsTerminal_8wekyb3d8bbwe\wt.exe&quot;
$Shortcut.Save()

$bytes = [System.IO.File]::ReadAllBytes(&quot;$Home\Desktop\Windows Terminal.lnk&quot;)
$bytes[0x15] = $bytes[0x15] -bor 0x20 #set byte 21 (0x15) bit 6 (0x20) ON 
[System.IO.File]::WriteAllBytes(&quot;$Home\Desktop\Windows Terminal.lnk&quot;, $bytes)
</code></pre>
<p>You can just paste it and run it from Windows Powershell ISE, it will create a Windows Terminal.lnk file on your desktop. Whenever you double click on that shortcut Windows terminal will run as an admnnistrator</p>
","14545823","","","","","2020-10-29 23:25:46","","","","0","","","","CC BY-SA 4.0"
"66043227","2","","62496779","2021-02-04 09:53:48","","1","","<p>I know this answer does not fully match your question but given that also other answers were oriented in this way I hope this won't disturb the discussion.</p>
<p>I always need to run PowerShell as Administrator and I only want to use Windows Terminal, which given it's restrictions cannot be configured to run always as Administrator.</p>
<p>I hated the need to use shortcuts and other hacks I found being suggested online, so I think I found a better solution but you have to pay the cost of a 1/2 seconds at startup.</p>
<ol>
<li>Locate your user profile (A profile is a Windows PowerShell ISE script that runs automatically when you start a new session) using _ $PROFILE</li>
<li>Edit profile with any preferred editor _ code $PROFILE</li>
<li>Adde the following code to the profile file and save it</li>
</ol>
<pre><code>if (-NOT ([Security.Principal.WindowsPrincipal] [Security.Principal.WindowsIdentity]::GetCurrent()).IsInRole([Security.Principal.WindowsBuiltInRole] &quot;Administrator&quot;)) {
    $host.ui.rawui.windowtitle=&quot;Bootstrapper&quot;
    Start-Process -Verb RunAs wt
} else {
    $Processes = Get-Process | Where-Object {$_.mainWindowTitle -eq 'Bootstrapper' -and $_.name -eq 'WindowsTerminal'}
    if($Processes.count -gt 0)
    {
        Stop-Process -Id $Processes[0].id
    }
}
</code></pre>
<p>What the script do?
You can pin Windows Terminal icon to your application bar and when you click there WT will start as non elevated user, but the profile will understand if this is the case.
When you are not running as Administrator it will change the name of the window and start a new WT as administrator.
The new instance will also execute the profile file and if the instance is runinng as Administrator, it will look for the WT named Bootstrapper and kill it.
This proces takes between one and two seconds, I prefer this way other than right clicking on the icon.</p>
","2482439","","1839439","","2021-02-04 09:59:44","2021-02-04 09:59:44","","","","0","","","","CC BY-SA 4.0"
"66262771","2","","62496779","2021-02-18 15:15:54","","12","","<p>With recent releases, this issue appears to be fixed.  It works now, doing exactly as you originally tried and failed (<code>Start-Process -verb RunAs wt</code>).  I would recommend trying again now with the latest releases (at least Windows Terminal, and perhaps PowerShell as well).</p>
<p>No need for workarounds anymore!!</p>
","14735125","","11810933","","2021-02-19 13:37:33","2021-02-19 13:37:33","","","","5","","","","CC BY-SA 4.0"
"66264009","2","","62496779","2021-02-18 16:26:53","","0","","<p>It's likely you were just facing a Path issue.  I know that the command examples you gave (e.g. <code>Start-Process -verb RunAs wt</code>) have worked for me for some time (as mentioned in @fialdrexs's answer).</p>
<p>Did you install Windows Terminal from a Github release or from the Store?</p>
","11810933","","","","","2021-02-18 16:26:53","","","","1","","","","CC BY-SA 4.0"
"66365285","2","","62496779","2021-02-25 08:57:38","","-2","","<p>Currently this problem was fixed, but it ended up with a weird issue. Running <code>wt.exe</code> from Win+R, searching it on start menu, and starting itself from the terminal, show the same error message.</p>
<blockquote>
<p>The application was unable to start correctly (0xc0000022). Click OK
to close the application.</p>
</blockquote>
<p>However it works when executing <code>wt</code> via Command Prompt, PowerShell, and PowerShell Core.</p>
<p>So just a quick workaround answer, start PowerShell and run the command,
<code>Start-Process -Verb RunAs wt.exe</code>;
or the simpler
<code>start -verb runas wt</code></p>
","14511192","","","","","2021-02-25 08:57:38","","","","1","","","","CC BY-SA 4.0"
"70178820","2","","62496779","2021-12-01 03:32:45","","0","","<p>I currently have the following entry in my settings.json profiles list to add an elevated Windows Terminal to the drop down options:</p>
<pre><code>{
    // https://github.com/microsoft/terminal/issues/632#issuecomment-663686412
    &quot;name&quot;: &quot;Windows Terminal (elevated)&quot;,
    &quot;commandline&quot;: &quot;%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -Command Start-Process -Verb RunAs \&quot;shell:appsFolder\\Microsoft.WindowsTerminal_8wekyb3d8bbwe!App\&quot;&quot;,
    &quot;hidden&quot;: false,
    &quot;icon&quot;: &quot;ms-appx:///Images/Square44x44Logo.targetsize-32.png&quot;
}
</code></pre>
<p>The comment with the GitHub link should get you to where I originally found this information.</p>
","455522","","","","","2021-12-01 03:32:45","","","","0","","","","CC BY-SA 4.0"
"70427554","2","","62496779","2021-12-20 20:19:40","","4","","<p>Pin to the Taskbar and hold <kbd>Ctrl + Shift</kbd> while left clicking on the Windows Terminal icon.</p>
","17727184","","","user17242583","2021-12-20 20:26:45","2021-12-20 20:26:45","","","","3","","","","CC BY-SA 4.0"
"59744386","2","","59743938","2020-01-15 02:27:27","","2","","<p>In all of the other Reactive frameworks this is really easy; you just use <code>concat</code> to concatenate and flatten the results in one step and then you can <code>reduce</code> the results into a final array.  Apple makes this difficult because <code>Publisher.Concatenate</code> has no overload that accepts an array of Publishers.  There is similar weirdness with <code>Publisher.Merge</code>.  I have a feeling this has to do with the fact that they return nested generic publishers instead of just returning a single generic type like rx Observable.  I guess you can just call <a href=""https://developer.apple.com/documentation/combine/publishers/concatenate"" rel=""nofollow noreferrer"">Concatenate</a> in a loop and then reduce the concatenated results into a single array, but I really hope they address this issue in the next release.  There is certainly the need to concat more than 2 publishers and to merge more than 4 publishers (and the overloads for these two operators aren't even consistent, which is just weird).</p>

<p>EDIT:</p>

<p>I came back to this and found that you can indeed concat an arbitrary array of publishers and they will emit in sequence.  I have no idea why there isn't a function like <code>ConcatenateMany</code> to do this for you but it looks like as long as you are willing to use a type erased publisher its not that hard to write one yourself.  This example shows that merge emits in temporal order while concat emits in the order of combination:</p>

<pre><code>import PlaygroundSupport
import SwiftUI
import Combine

let p = Just&lt;Int&gt;(1).append(2).append(3).delay(for: .seconds(0.25), scheduler: RunLoop.main).eraseToAnyPublisher()
let q = Just&lt;Int&gt;(4).append(5).append(6).eraseToAnyPublisher()
let r = Just&lt;Int&gt;(7).append(8).append(9).delay(for: .seconds(0.5), scheduler: RunLoop.main).eraseToAnyPublisher()
let concatenated: AnyPublisher&lt;Int, Never&gt; = [q,r].reduce(p) { total, next in
  total.append(next).eraseToAnyPublisher()
}

var subscriptions = Set&lt;AnyCancellable&gt;()

concatenated
  .sink(receiveValue: { v in
    print(""concatenated: \(v)"")
  }).store(in: &amp;subscriptions)

Publishers
  .MergeMany([p,q,r])
  .sink(receiveValue: { v in
    print(""merge: \(v)"")
  }).store(in: &amp;subscriptions)
</code></pre>
","5012441","","5012441","","2020-01-21 04:32:57","2020-01-21 04:32:57","","","","8","","","","CC BY-SA 4.0"
"59757177","2","","59743938","2020-01-15 18:01:45","","2","","<p>Here is one page playground code that depicts possible approach. The main idea is to transform async API calls into chain of <code>Future</code> publishers, thus making serial pipeline.</p>

<p>Input: range of int from 1 to 10 that asynchrounosly on background queue converted into strings</p>

<p><strong>Demo of direct call to async API:</strong></p>

<pre><code>let group = DispatchGroup()
inputValues.map {
    group.enter()
    asyncCall(input: $0) { (output, _) in
        print(""&gt;&gt; \(output), in \(Thread.current)"")
        group.leave()
    }
}
group.wait()
</code></pre>

<p>Output:</p>

<blockquote>
<pre><code>&gt;&gt; 1, in &lt;NSThread: 0x7fe76264fff0&gt;{number = 4, name = (null)}
&gt;&gt; 3, in &lt;NSThread: 0x7fe762446b90&gt;{number = 3, name = (null)}
&gt;&gt; 5, in &lt;NSThread: 0x7fe7624461f0&gt;{number = 5, name = (null)}
&gt;&gt; 6, in &lt;NSThread: 0x7fe762461ce0&gt;{number = 6, name = (null)}
&gt;&gt; 10, in &lt;NSThread: 0x7fe76246a7b0&gt;{number = 7, name = (null)}
&gt;&gt; 4, in &lt;NSThread: 0x7fe764c37d30&gt;{number = 8, name = (null)}
&gt;&gt; 7, in &lt;NSThread: 0x7fe764c37cb0&gt;{number = 9, name = (null)}
&gt;&gt; 8, in &lt;NSThread: 0x7fe76246b540&gt;{number = 10, name = (null)}
&gt;&gt; 9, in &lt;NSThread: 0x7fe7625164b0&gt;{number = 11, name = (null)}
&gt;&gt; 2, in &lt;NSThread: 0x7fe764c37f50&gt;{number = 12, name = (null)}
</code></pre>
</blockquote>

<p><strong>Demo of combine pipeline:</strong></p>

<p>Output:</p>

<blockquote>
<pre><code>&gt;&gt; got 1
&gt;&gt; got 2
&gt;&gt; got 3
&gt;&gt; got 4
&gt;&gt; got 5
&gt;&gt; got 6
&gt;&gt; got 7
&gt;&gt; got 8
&gt;&gt; got 9
&gt;&gt; got 10
&gt;&gt;&gt;&gt; finished with true
</code></pre>
</blockquote>

<p>Code:</p>

<pre><code>import Cocoa
import Combine
import PlaygroundSupport

// Assuming there is some Asynchronous API with
// (eg. process Int input value during some time and generates String result)
func asyncCall(input: Int, completion: @escaping (String, Error?) -&gt; Void) {
    DispatchQueue.global(qos: .background).async {
            sleep(.random(in: 1...5)) // wait for random Async API output
            completion(""\(input)"", nil)
        }
}

// There are some input values to be processed serially
let inputValues = Array(1...10)

// Prepare one pipeline item based on Future, which trasform Async -&gt; Sync
func makeFuture(input: Int) -&gt; AnyPublisher&lt;Bool, Error&gt; {
    Future&lt;String, Error&gt; { promise in
        asyncCall(input: input) { (value, error) in
            if let error = error {
                promise(.failure(error))
            } else {
                promise(.success(value))
            }
        }
    }
    .receive(on: DispatchQueue.main)
    .map {
        print(""&gt;&gt; got \($0)"") // &lt;&lt; sideeffect of pipeline item
        return true
    }
    .eraseToAnyPublisher()
}

// Create pipeline trasnforming input values into chain of Future publishers
var subscribers = Set&lt;AnyCancellable&gt;()
let pipeline =
    inputValues
    .reduce(nil as AnyPublisher&lt;Bool, Error&gt;?) { (chain, value) in
        if let chain = chain {
            return chain.flatMap { _ in
                makeFuture(input: value)
            }.eraseToAnyPublisher()
        } else {
            return makeFuture(input: value)
        }
    }

// Execute pipeline
pipeline?
    .sink(receiveCompletion: { _ in
        // &lt;&lt; do something on completion if needed
    }) { output in
        print(""&gt;&gt;&gt;&gt; finished with \(output)"")
    }
    .store(in: &amp;subscribers)

PlaygroundPage.current.needsIndefiniteExecution = true
</code></pre>
","12299030","","12299030","","2020-01-18 19:19:03","2020-01-18 19:19:03","","","","0","","","","CC BY-SA 4.0"
"59829746","2","","59743938","2020-01-20 19:28:35","","9","","<p>I've only briefly tested this, but at first pass it appears that each request waits for the previous request to finish before starting.</p>

<p>I'm posting this solution in search of feedback. Please be critical if this isn't a good solution.</p>

<pre class=""lang-swift prettyprint-override""><code>extension Collection where Element: Publisher {

    func serialize() -&gt; AnyPublisher&lt;Element.Output, Element.Failure&gt;? {
        // If the collection is empty, we can't just create an arbititary publisher
        // so we return nil to indicate that we had nothing to serialize.
        if isEmpty { return nil }

        // We know at this point that it's safe to grab the first publisher.
        let first = self.first!

        // If there was only a single publisher then we can just return it.
        if count == 1 { return first.eraseToAnyPublisher() }

        // We're going to build up the output starting with the first publisher.
        var output = first.eraseToAnyPublisher()

        // We iterate over the rest of the publishers (skipping over the first.)
        for publisher in self.dropFirst() {
            // We build up the output by appending the next publisher.
            output = output.append(publisher).eraseToAnyPublisher()
        }

        return output
    }
}

</code></pre>

<hr>

<p>A more concise version of this solution (provided by @matt):</p>

<pre class=""lang-swift prettyprint-override""><code>extension Collection where Element: Publisher {
    func serialize() -&gt; AnyPublisher&lt;Element.Output, Element.Failure&gt;? {
        guard let start = self.first else { return nil }
        return self.dropFirst().reduce(start.eraseToAnyPublisher()) {
            $0.append($1).eraseToAnyPublisher()
        }
    }
}
</code></pre>
","4283188","","4283188","","2020-02-27 16:41:30","2020-02-27 16:41:30","","","","1","","","","CC BY-SA 4.0"
"59889174","2","","59743938","2020-01-24 01:06:55","","9","","<p>You could create custom Subscriber where receive returning Subscribers.Demand.max(1). In that case the subscriber will request next value only when received one. The example is for Int.publisher, but some random delay in map mimics network traffic :-)</p>

<pre><code>import PlaygroundSupport
import SwiftUI
import Combine

class MySubscriber: Subscriber {
  typealias Input = String
  typealias Failure = Never

  func receive(subscription: Subscription) {
    print(""Received subscription"", Thread.current.isMainThread)
    subscription.request(.max(1))
  }

  func receive(_ input: Input) -&gt; Subscribers.Demand {
    print(""Received input: \(input)"", Thread.current.isMainThread)
    return .max(1)
  }

  func receive(completion: Subscribers.Completion&lt;Never&gt;) {
    DispatchQueue.main.async {
        print(""Received completion: \(completion)"", Thread.current.isMainThread)
        PlaygroundPage.current.finishExecution()
    }
  }
}

(110...120)
    .publisher.receive(on: DispatchQueue.global())
    .map {
        print(Thread.current.isMainThread, Thread.current)
        usleep(UInt32.random(in: 10000 ... 1000000))
        return String(format: ""%02x"", $0)
    }
    .subscribe(on: DispatchQueue.main)
    .subscribe(MySubscriber())

print(""Hello"")

PlaygroundPage.current.needsIndefiniteExecution = true
</code></pre>

<p>Playground print ...</p>

<pre><code>Hello
Received subscription true
false &lt;NSThread: 0x600000064780&gt;{number = 5, name = (null)}
Received input: 6e false
false &lt;NSThread: 0x60000007cc80&gt;{number = 9, name = (null)}
Received input: 6f false
false &lt;NSThread: 0x60000007cc80&gt;{number = 9, name = (null)}
Received input: 70 false
false &lt;NSThread: 0x60000007cc80&gt;{number = 9, name = (null)}
Received input: 71 false
false &lt;NSThread: 0x60000007cc80&gt;{number = 9, name = (null)}
Received input: 72 false
false &lt;NSThread: 0x600000064780&gt;{number = 5, name = (null)}
Received input: 73 false
false &lt;NSThread: 0x600000064780&gt;{number = 5, name = (null)}
Received input: 74 false
false &lt;NSThread: 0x60000004dc80&gt;{number = 8, name = (null)}
Received input: 75 false
false &lt;NSThread: 0x60000004dc80&gt;{number = 8, name = (null)}
Received input: 76 false
false &lt;NSThread: 0x60000004dc80&gt;{number = 8, name = (null)}
Received input: 77 false
false &lt;NSThread: 0x600000053400&gt;{number = 3, name = (null)}
Received input: 78 false
Received completion: finished true
</code></pre>

<p><strong>UPDATE</strong>
finally i found <code>.flatMap(maxPublishers: )</code>, which force me to update this interesting topic with little bit different approach. Please, see that I am using global queue for scheduling, not only some random delay, just to be sure that receiving serialized stream is not ""random"" or ""lucky"" behavior :-)</p>

<pre><code>import PlaygroundSupport
import Combine
import Foundation

PlaygroundPage.current.needsIndefiniteExecution = true

let A = (1 ... 9)
    .publisher
    .flatMap(maxPublishers: .max(1)) { value in
        [value].publisher
            .flatMap { value in
                Just(value)
                    .delay(for: .milliseconds(Int.random(in: 0 ... 100)), scheduler: DispatchQueue.global())
        }
}
.sink { value in
    print(value, ""A"")
}

let B = (1 ... 9)
    .publisher
    .flatMap { value in
        [value].publisher
            .flatMap { value in
                Just(value)
                    .delay(for: .milliseconds(Int.random(in: 0 ... 100)), scheduler: RunLoop.main)
        }
}
.sink { value in
    print(""     "",value, ""B"")
}
</code></pre>

<p>prints</p>

<pre><code>1 A
      4 B
      5 B
      7 B
      1 B
      2 B
      8 B
      6 B
2 A
      3 B
      9 B
3 A
4 A
5 A
6 A
7 A
8 A
9 A
</code></pre>

<p>Based on written here</p>

<p><strong>.serialize()?</strong></p>

<p>defined by Clay Ellis accepted answer could be replaced by </p>

<p><strong>.publisher.flatMap(maxPublishers: .max(1)){$0}</strong></p>

<p>while ""unserialzed"" version must use </p>

<p><strong>.publisher.flatMap{$0}</strong></p>

<p>""real world example""</p>

<pre><code>import PlaygroundSupport
import Foundation
import Combine

let path = ""postman-echo.com/get""
let urls: [URL] = ""... which proves the downloads are happening serially .-)"".map(String.init).compactMap { (parameter) in
    var components = URLComponents()
    components.scheme = ""https""
    components.path = path
    components.queryItems = [URLQueryItem(name: parameter, value: nil)]
    return components.url
}
//[""https://postman-echo.com/get?]
struct Postman: Decodable {
    var args: [String: String]
}


let collection = urls.compactMap { value in
        URLSession.shared.dataTaskPublisher(for: value)
        .tryMap { data, response -&gt; Data in
            return data
        }
        .decode(type: Postman.self, decoder: JSONDecoder())
        .catch {_ in
            Just(Postman(args: [:]))
    }
}

extension Collection where Element: Publisher {
    func serialize() -&gt; AnyPublisher&lt;Element.Output, Element.Failure&gt;? {
        guard let start = self.first else { return nil }
        return self.dropFirst().reduce(start.eraseToAnyPublisher()) {
            return $0.append($1).eraseToAnyPublisher()
        }
    }
}

var streamA = """"
let A = collection
    .publisher.flatMap{$0}

    .sink(receiveCompletion: { (c) in
        print(streamA, ""     "", c, ""    .publisher.flatMap{$0}"")
    }, receiveValue: { (postman) in
        print(postman.args.keys.joined(), terminator: """", to: &amp;streamA)
    })


var streamC = """"
let C = collection
    .serialize()?

    .sink(receiveCompletion: { (c) in
        print(streamC, ""     "", c, ""    .serialize()?"")
    }, receiveValue: { (postman) in
        print(postman.args.keys.joined(), terminator: """", to: &amp;streamC)
    })

var streamD = """"
let D = collection
    .publisher.flatMap(maxPublishers: .max(1)){$0}

    .sink(receiveCompletion: { (c) in
        print(streamD, ""     "", c, ""    .publisher.flatMap(maxPublishers: .max(1)){$0}"")
    }, receiveValue: { (postman) in
        print(postman.args.keys.joined(), terminator: """", to: &amp;streamD)
    })

PlaygroundPage.current.needsIndefiniteExecution = true
</code></pre>

<p>prints</p>

<pre><code>.w.h i.c hporves ht edownloadsa erh appeninsg eriall y.-)       finished     .publisher.flatMap{$0}
... which proves the downloads are happening serially .-)       finished     .publisher.flatMap(maxPublishers: .max(1)){$0}
... which proves the downloads are happening serially .-)       finished     .serialize()?
</code></pre>

<p>Seem to me very useful in other scenarios as well. Try to use default value of maxPublishers in next snippet and compare the results :-)</p>

<pre><code>import Combine

let sequencePublisher = Publishers.Sequence&lt;Range&lt;Int&gt;, Never&gt;(sequence: 0..&lt;Int.max)
let subject = PassthroughSubject&lt;String, Never&gt;()

let handle = subject
    .zip(sequencePublisher.print())
    //.publish
    .flatMap(maxPublishers: .max(1), { (pair)  in
        Just(pair)
    })
    .print()
    .sink { letters, digits in
        print(letters, digits)
    }

""Hello World!"".map(String.init).forEach { (s) in
    subject.send(s)
}
subject.send(completion: .finished)
</code></pre>
","3441734","","3441734","","2020-01-25 19:14:23","2020-01-25 19:14:23","","","","4","","","","CC BY-SA 4.0"
"59889993","2","","59743938","2020-01-24 03:22:15","","8","","<p>From the original question:</p>

<blockquote>
  <p>I did try making an array of the URLs and map it to an array of publishers. I know I can ""produce"" a publisher and cause it to publish on down the pipeline using <code>flatMap</code>. But then I'm still doing all the downloading simultaneously. There isn't any Combine way to walk the array in a controlled manner — or is there?</p>
</blockquote>

<hr>

<p>Here's a toy example to stand in for the real problem:</p>

<pre><code>let collection = (1 ... 10).map {
    Just($0).delay(
        for: .seconds(Double.random(in:1...5)),
        scheduler: DispatchQueue.main)
        .eraseToAnyPublisher()
}
collection.publisher
    .flatMap() {$0}
    .sink {print($0)}.store(in:&amp;self.storage)
</code></pre>

<p>This emits the integers from 1 to 10 in random order arriving at random times. The goal is to do something with <code>collection</code> that will cause it to emit the integers from 1 to 10 in order.</p>

<hr>

<p>Now we're going to change just one thing: in the line </p>

<pre><code>.flatMap {$0}
</code></pre>

<p>we add the <code>maxPublishers</code> parameter:</p>

<pre><code>let collection = (1 ... 10).map {
    Just($0).delay(
        for: .seconds(Double.random(in:1...5)),
        scheduler: DispatchQueue.main)
        .eraseToAnyPublisher()
}
collection.publisher
    .flatMap(maxPublishers:.max(1)) {$0}
    .sink {print($0)}.store(in:&amp;self.storage)
</code></pre>

<p>Presto, we now <em>do</em> emit the integers from 1 to 10, in order, with random intervals between them.</p>

<hr>

<p>Let's apply this to the original problem. To demonstrate, I need a fairly slow Internet connection and a fairly large resource to download. First, I'll do it with ordinary <code>.flatMap</code>:</p>

<pre><code>let eph = URLSessionConfiguration.ephemeral
let session = URLSession(configuration: eph)
let url = ""https://photojournal.jpl.nasa.gov/tiff/PIA23172.tif""
let collection = [url, url, url]
    .map {URL(string:$0)!}
    .map {session.dataTaskPublisher(for: $0)
        .eraseToAnyPublisher()
}
collection.publisher.setFailureType(to: URLError.self)
    .handleEvents(receiveOutput: {_ in print(""start"")})
    .flatMap() {$0}
    .map {$0.data}
    .sink(receiveCompletion: {comp in
        switch comp {
        case .failure(let err): print(""error"", err)
        case .finished: print(""finished"")
        }
    }, receiveValue: {_ in print(""done"")})
    .store(in:&amp;self.storage)
</code></pre>

<p>The result is</p>

<pre><code>start
start
start
done
done
done
finished
</code></pre>

<p>which shows that we are doing the three downloads simultaneously. Okay, now change</p>

<pre><code>    .flatMap() {$0}
</code></pre>

<p>to</p>

<pre><code>    .flatMap(maxPublishers:.max(1) {$0}
</code></pre>

<p>The result now is:</p>

<pre><code>start
done
start
done
start
done
finished
</code></pre>

<p>So we are now downloading serially, which is the problem originally to be solved.</p>

<hr>

<h3>append</h3>

<p>In keeping with the principle of TIMTOWTDI, we can instead chain the publishers with <code>append</code> to serialize them:</p>

<pre><code>let collection = (1 ... 10).map {
    Just($0).delay(
        for: .seconds(Double.random(in:1...5)),
        scheduler: DispatchQueue.main)
        .eraseToAnyPublisher()
}
let pub = collection.dropFirst().reduce(collection.first!) {
    return $0.append($1).eraseToAnyPublisher()
}
</code></pre>

<p>The result is a publisher that serializes the delayed publishers in the original collection. Let's prove it by subscribing to it:</p>

<pre><code>pub.sink {print($0)}.store(in:&amp;self.storage)
</code></pre>

<p>Sure enough, the integers now arrive in order (with random intervals between).</p>

<hr>

<p>We can encapsulate the creation of <code>pub</code> from a collection of publishers with an extension on Collection, as suggested by Clay Ellis:</p>

<pre><code>extension Collection where Element: Publisher {
    func serialize() -&gt; AnyPublisher&lt;Element.Output, Element.Failure&gt;? {
        guard let start = self.first else { return nil }
        return self.dropFirst().reduce(start.eraseToAnyPublisher()) {
            return $0.append($1).eraseToAnyPublisher()
        }
    }
}
</code></pre>
","341994","","341994","","2020-01-25 19:55:14","2020-01-25 19:55:14","","","","0","","","","CC BY-SA 4.0"
"61195234","2","","59743938","2020-04-13 19:25:27","","20","","<p>Use <code>flatMap(maxPublishers:transform:)</code> with <code>.max(1)</code>, e.g.</p>
<pre><code>func imagesPublisher(for urls: [URL]) -&gt; AnyPublisher&lt;UIImage, URLError&gt; {
    Publishers.Sequence(sequence: urls.map { self.imagePublisher(for: $0) })
        .flatMap(maxPublishers: .max(1)) { $0 }
        .eraseToAnyPublisher()
}
</code></pre>
<p>Where</p>
<pre><code>func imagePublisher(for url: URL) -&gt; AnyPublisher&lt;UIImage, URLError&gt; {
    URLSession.shared.dataTaskPublisher(for: url)
        .compactMap { UIImage(data: $0.data) }
        .receive(on: RunLoop.main)
        .eraseToAnyPublisher()
}
</code></pre>
<p>and</p>
<pre><code>var imageRequests: AnyCancellable?

func fetchImages() {
    imageRequests = imagesPublisher(for: urls).sink { completion in
        switch completion {
        case .finished:
            print(&quot;done&quot;)
        case .failure(let error):
            print(&quot;failed&quot;, error)
        }
    } receiveValue: { image in
        // do whatever you want with the images as they come in
    }
}
</code></pre>
<p>That resulted in:</p>
<p><a href=""https://i.stack.imgur.com/85XDo.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/85XDo.png"" alt=""serial"" /></a></p>
<p>But we should recognize that you take a big performance hit doing them sequentially, like that. For example, if I bump it up to 6 at a time, it’s more than twice as fast:</p>
<p><a href=""https://i.stack.imgur.com/54Ulm.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/54Ulm.png"" alt=""concurrent"" /></a></p>
<p>Personally, I’d recommend only downloading sequentially if you absolutely must (which, when downloading a series of images/files, is almost certainly not the case). Yes, performing requests concurrently can result in them not finishing in a particular order, but we just use a structure that is order independent (e.g. a dictionary rather than a simple array), but the performance gains are so significant that it’s generally worth it.</p>
<p>But, if you want them downloaded sequentially, the <code>maxPublishers</code> parameter can achieve that.</p>
","1271826","","1271826","","2020-12-14 15:21:04","2020-12-14 15:21:04","","","","5","","","","CC BY-SA 4.0"
"63750587","2","","63705739","2020-09-05 04:55:32","","1","","<p>At some point, the processor needs to be able to read the instructions in your app to know what it’s supposed to do.  The operating system itself needs to know what to do with your app.</p>
<p>Ignoring how an app is packaged for a moment, for the aforementioned reasons, it seems to me there is no technical reason why your app cannot be modified by Google or any technical entity that has the knowledge and resources to do so. Let me explain further why:</p>
<p>It doesn’t matter how the app is packaged - the moment the operating system loads the app, you know what the app does. If the operating system did not know how to handle an app, the app would be useless.
You can try to obfuscate it, the way some popular worms tried to hide their purpose, but it really just delays the inevitable. People have been disassembling and decompiling software right from the beginning, that’s why many licenses used to explicitly prohibit disassembly.
Knowing this, it should be apparent that if “Google” wanted to modify your app they could, because even if the package is obfuscated, when the app is ultimately executing you could see what its doing then, document it, and then modify the app as required. They also have all the technical skills and resources to do so.</p>
<p>Let’s step back for a moment:</p>
<p>The purpose of signing something with a signature, is so that one can determine if the copy of the app they have received is authentic - in this case, if the app that an end user has received matches what is on the play store. The purpose being to ensure the copy you have is the same as the one distributed to other users.
You’re asking if there is a technical reason why Google cannot modify the app - no there isn’t. You’ve mentioned yourself that an apk is just a zip file. If your app was signed by yourself, and that same signature was included in the copy of the app that the end user received, then the end user could verify if Google had tampered with your app. But if your signature is stripped, then the user is left with having to trust Google.</p>
<p>Your question is interesting, because it made me think of something else : I guess the context in which you asked your question was “would Google be able to modify the app before distribution”. With modern devices becoming increasingly powerful, what’s to stop the operating system (since a manufacturer can customise their version of android), from modifying the app after distribution, or in future, on the fly while it executes?</p>
<p>I’m leaving this paper here below:</p>
<p><a href=""https://www.cs.cmu.edu/%7Erdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf"" rel=""nofollow noreferrer"">https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf</a></p>
<p>The reason being it seems this will always be a perennial question, as it’s impossible for human beings to single handedly verify every piece of software in the kind of systems we use today.</p>
<p>I also find it a bit funny that people think that just because source code is available for an app, that it means they can trust the app which is actually running on their device - unless they’ve gone through the trouble of actually examining the app on their device, it technically is possible that the app running on their device is not the same as the source code describes - it could have been modified by both the developer themselves, or the store distributing the app for malicious or accidental reasons.</p>
<p>But trust has to begin somewhere 🤷‍♂️. In future, with Quantum Computing, maybe the way we do things will change. But again, there are so few of us who actually understand how every piece of a system works, we will still have to place our trust somewhere. Even if we understand something, having the resources to verify it is another matter as well...</p>
<p><strong>so what stops Google from modifying it?</strong></p>
<ul>
<li>Do they really need to? It’s the developers which create value for Google Play by creating and submitting their apps.</li>
<li>Would you trust Google if they modified your app without your permission? How would it affect your perception of them as a company, since privacy is already a major issue.</li>
<li>In the event that a modification of theirs causes your app to behave incorrectly and cause damage to a customer, yourself or some third party entity, who will be held liable?</li>
</ul>
<p>The above are just some of the reasons to think about when considering if Google will modify your app. It’s a can of worms. In the end, it boils down to cost-benefit &amp; risk-reward analysis. What would they modify your app for, and is it worth any risk of repercussions?</p>
<p>In summation, there is no technical reason why they can’t. Why they don’t / won’t boils down to their business motivations and model. There is nothing to say why they will or won’t in future. But there is no reason to arbitrarily modify an app - there has to be a valid business reason which results in some kind of gain.</p>
","1266109","","1266109","","2020-09-05 06:06:51","2020-09-05 06:06:51","","","","6","","","","CC BY-SA 4.0"
"63798409","2","","63705739","2020-09-08 16:56:35","","0","","<p>Simple answer: Google can, if they want to. In a digital signature scheme the signer has complete capability of modifying the document prior to signing.</p>
<p>Why they won't: Because developer can easily detect it, and the payload which is of most importance - the classes*.dex, actually containing the code - can easily be decompiled by interested third parties (or the app creator) to figure out any added code. (Adding code into JNI libraries is even less likely). To clarify, the detection by the developer is as easy as unzipping the APK and comparing its contents to what the developer submitted.</p>
<p>The impact of adding code to an app without notifying the developer would likely cause quite a backlash if discovered. Of course, at any further date Google could decide to change their terms of use, migrate from DEX to LLVM bitcode, or do something else, which might change this behavior.</p>
<p>Clarification: It is true, that Google could in theory ship modified apps only to certain targets, but once again it suffices that one such incident be detected (maybe by a concerned app-user mailing his or her APK to the developer?) for the implications to be far reaching for Google.</p>
<p>This, btw, holds true for Apple as well, being the signer of all App-Store apps. In the Apple case it's even more of a question, since apps may get recompiled by Apple (from BitCode to to the underlying ARMv8 variant), and apps deploy encrypted by FairPlay, which makes it virtually impossible to decrypt the app outside a jailbroken device.</p>
<p>As an anecdote, you could wonder if a malicious device vendor couldn't change dex2oat (the on-device compiler) to inject arbitrary code when the app is installed and compiled on the device itself. This would be much harder to detect, since on a non rooted device there would not be an easy way to access the compiled art/oat files of the app. But then, malicious vendors can also directly modify the Android frameworks, as well.</p>
","1734439","","1734439","","2020-09-08 17:07:31","2020-09-08 17:07:31","","","","9","","","","CC BY-SA 4.0"
"63829509","2","","63705739","2020-09-10 12:17:29","","12","","<p>Google doesn't just have the capability to modify <code>.apk</code> files uploaded to it's Google Play signing program- they already are.</p>
<p>Granted, this is at the moment a minor change and certainly a non-malicious one; but it remains an actual change of your <code>.apk</code>. They add</p>
<pre><code>&lt;meta-data
      android:name=&quot;com.android.vending.derived.apk.id&quot;
      android:value=&quot;1&quot; /&gt;
</code></pre>
<p>to the <code>AndroidManifest.xml</code></p>
<p>Below is a comparison that I made in 2018 while researching this topic. It has the apk before upload (signed with upload key), and the apk as downloaded from Google Play with Google play signing enabled.
<a href=""https://i.stack.imgur.com/tPrQz.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/tPrQz.png"" alt=""Comparison of apk before-after Google play signing"" /></a>
As you can see from this graphic; there's only two changes- the old signing (upload key) was removed, and replaced with Google signing. And also the AndroidManifest.xml was slightly appended (with the meta-data mentioned above)</p>
<p>I'll also point out this Google IO video from 2017 where they're introducing Google Play signing: <a href=""https://www.youtube.com/watch?v=5tdGAP927dk&amp;feature=youtu.be"" rel=""noreferrer"">https://www.youtube.com/watch?v=5tdGAP927dk&amp;feature=youtu.be</a>. From 11:25 in they're talking about something called &quot;App signing + optimizations&quot;. The idea was that they could optimize apks for you, and generate sub-apks.
<a href=""https://i.stack.imgur.com/RvAsD.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/RvAsD.png"" alt=""Planned architecture of Google play signing optimizations"" /></a>
This was something that you could enable on a per-apk basis within Google Play. Today of course, you'll find no mention of any of this in any documentation, other than in this video- That's because they later came up with app bundles and essentially moved all this work into that. So, this is mostly relevant because the question was &quot;What Stops Google From Modifying Our APKs That It Signs Via the App Signing Service?&quot;, and this shows that even specifically for <code>.apk</code> files they can; they intended to; and they were.</p>
<p>As others have pointed out; whoever has the signing keys and access to the Google Play account for the given app- can upload any <code>.apk</code> or <code>.aab</code> containing anything; as long as the packageName remains the same, and versionCode is incremented by one. The same applies of course to Google when Google Play signing is enabled. If they wanted, they could change, remove or add to any and all parts of the application.</p>
<p>It's worth keeping in mind that while yes; Google could modify everything and anything within the Google Play signed <code>.apk</code> file(s), those modifications aren't necessarily evil or with a bad intent. Whether for optimization purposes, compatibility or hot-fixing; there are plenty of reasons Google could or would modify the uploaded apk and justify those modifications. And they wouldn't necessarily warn the developers about this; nor would developers necessarily react to a discovery of this with an outcry.</p>
<p>I do believe that we're very unlikely to see Google perform purposely malicious content changes to uploaded apps, mostly for business, reputation and ethical risks outlined well in the other answers here already. I just can't picture this being a valuable attack vector for Google that outweighs the rather heavy cost-risk, and considering the other, often stronger vectors available to them.</p>
<p>Lastly, I'll mention integrity checks as one way this would be discovered. There are several solutions in this space that goes further than signature checks to verify the integrity of the app. Whether app developers roll their own, or use an off-the-shelves solution- these checks typically run during runtime on device to verify the integrity of the apk; comparing against records taken during compile-time or near compile-time. Modifications performed to the apk during transit does get picked up by this, including whatever change Google Play might do.</p>
<p>Disclaimer: I work for a app-security company that performs such integrity checks (any many other checks and verifications) on the apps that we protect. We've had to map out and account for all changes Google Play might do to an app both for regular apk files and app bundles- so we can distinguish between Google Play doing optimizations and a malicious actor repackaging the app.</p>
","2923245","","","","","2020-09-10 12:17:29","","","","0","","","","CC BY-SA 4.0"
"66721210","2","","59743938","2021-03-20 11:49:35","","1","","<p>What about the dynamic array of URLs, something like data bus ?</p>
<pre><code>      var array: [AnyPublisher&lt;Data, URLError&gt;] = []

      array.append(Task())

      array.publisher
         .flatMap { $0 }
         .sink {

         }
         // it will be finished
      array.append(Task())
      array.append(Task())
      array.append(Task())
</code></pre>
","4137436","","","","","2021-03-20 11:49:35","","","","0","","","","CC BY-SA 4.0"
"66735288","2","","59743938","2021-03-21 17:15:24","","1","","<p>Another approach, if you want to collect all the results of the downloads, in order to know which one failed and which one not, is to write a custom publisher that looks like this:</p>
<pre class=""lang-swift prettyprint-override""><code>extension Publishers {
    struct Serialize&lt;Upstream: Publisher&gt;: Publisher {
        typealias Output = [Result&lt;Upstream.Output, Upstream.Failure&gt;]
        typealias Failure = Never

        let upstreams: [Upstream]

        init&lt;C: Collection&gt;(_ upstreams: C) where C.Element == Upstream {
            self.upstreams = Array(upstreams)
        }

        init(_ upstreams: Upstream...) {
            self.upstreams = upstreams
        }

        func receive&lt;S&gt;(subscriber: S) where S : Subscriber, Self.Failure == S.Failure, Self.Output == S.Input {
            guard let first = upstreams.first else { return Empty().subscribe(subscriber) }
            first
                .map { Result&lt;Upstream.Output, Upstream.Failure&gt;.success($0) }
                .catch { Just(Result&lt;Upstream.Output, Upstream.Failure&gt;.failure($0)) }
                .map { [$0] }
                .append(Serialize(upstreams.dropFirst()))
                .collect()
                .map { $0.flatMap { $0 } }
                .subscribe(subscriber)
        }
    }
}

extension Collection where Element: Publisher {  
    func serializedPublishers() -&gt; Publishers.Serialize&lt;Element&gt; {
        .init(self)
    }
}
</code></pre>
<p>The publisher takes the first download task, converts its output/failure to a <code>Result</code> instance, and prepends it to the &quot;recursive&quot; call for the rest of the list.</p>
<p>Usage: <code>Publishers.Serialize(listOfDownloadTasks)</code>, or <code>listOfDownloadTasks.serializedPublishers()</code>.</p>
<p>One minor inconvenient of this implementation is the fact that the <code>Result</code> instance needs to be wrapped into an array, just to be flattened three steps later in the pipeline. Perhaps someone can suggest a better alternative to that.</p>
","1974224","","1974224","","2021-03-22 15:15:32","2021-03-22 15:15:32","","","","0","","","","CC BY-SA 4.0"
"67081617","2","","67081496","2021-04-13 20:01:18","","9","","<p>Combination of a named vector and <em>coalesce</em>:</p>
<pre><code># make lookup vector
lookupV &lt;- setNames(lookup$new, lookup$old)

data %&gt;% 
  mutate(x = coalesce(lookupV[ x ], x))
#   id x
# 1  1 a
# 2  2 a
# 3  3 B
# 4  4 C
# 5  5 d
</code></pre>
<p>Or <em>data.table</em>:</p>
<pre><code>library(data.table)

setDT(data)
data[ x %in% names(lookupV), x := lookupV[ x ] ]
</code></pre>
<p>This post might have a better solution for data.table - &quot;update on merge&quot;:</p>
<ul>
<li><a href=""https://stackoverflow.com/q/44433451/680068"">R data table: update join</a></li>
</ul>
","680068","","680068","","2021-04-13 20:06:30","2021-04-13 20:06:30","","","","1","","","","CC BY-SA 4.0"
"67081757","2","","67081496","2021-04-13 20:10:58","","8","","<p>A <code>base R</code> option using <del><code>%in%</code> and</del> <code>match</code> - thanks to @LMc &amp; @nicola</p>
<pre><code>tochange &lt;- match(data$x, lookup$old, nomatch = 0)
data$x[tochange &gt; 0] &lt;- lookup$new[tochange]
</code></pre>
<hr />
<p>One more <code>data.table</code> option using <code>set()</code> and <code>chmatch</code></p>
<pre><code>library(data.table)
setDT(data)

tochange &lt;- data[, chmatch(x, lookup$old, nomatch = 0)]
set(data, i = which(tochange &gt; 0), j = &quot;x&quot;, value = lookup$new[tochange])
</code></pre>
<p>Result</p>
<pre><code>data
#  id  x
#1  1  a
#2  2  a
#3  3  B
#4  4  C
#5  5  d
#6  6 AA
#7  7  !
</code></pre>
","8583393","","8583393","","2021-04-18 11:03:09","2021-04-18 11:03:09","","","","0","","","","CC BY-SA 4.0"
"71000683","2","","62496779","2022-02-05 17:59:10","","5","","<p>Windows Terminal has a feature to <a href=""https://learn.microsoft.com/en-us/windows/terminal/customize-settings/profile-general#automatically-run-as-administrator-preview"" rel=""noreferrer"">automatically run as administrator</a> in the preview; no need for workarounds now.</p>
","2345490","","7941251","","2022-02-06 03:05:23","2022-02-06 03:05:23","","","","1","","","","CC BY-SA 4.0"
"71104539","2","","63705739","2022-02-13 20:24:29","","0","","<p>Apologies for potential anachronism here.</p>
<p>When you say</p>
<blockquote>
<p>the App Signing service strips away whatever signature that we have</p>
</blockquote>
<p>are you <em><strong>sure</strong></em> this is what it does? One could imagine an alternative scheme, which could achieve everything noted in other answers / comments as actually occurring:</p>
<p>Assume that the dev has uploaded their artefacts (let's say as an .obb) and signed it using their upload key. Google appends its additional metadata (think of it as a kind of diff file) and re-signs the resulting expanded payload. On receipt at the device, android checks that the payload it has received was correctly signed by Google (which it was), removes (but keeps) the metadata Google added, then checks the remaining payload (the dev's .obb) against the dev's signature. If that checks out, which it presumably will, it applies the change implicit in the added metadata to the original .obb</p>
<p>That .obb becomes the artifact which android installs. It isn't what the dev uploaded.
Google hasn't stripped the dev's upload signature, they've just added extra payload in a way which doesn't invalidate the original signature, then added some more payload and a signature of their own.</p>
<p>I'm not saying this is what they are doing, just that this is what they <em><strong>might</strong></em> be doing. You would be able to detect this once you had downloaded the payload and installed it on a device. Could it be made to happen or not according to which device the download was sent to? I expect that wouldn't be hard. And in that case, you wouldn't be able to detect it unless you had access to a device which had been targetted for the modification. It would be very difficult to detect the modification process while it was occurring. You could tell the difference between a modified payload and an unmodified payload immediately on receipt at the device because the presence or absence of the metadata &quot;diff&quot; would change the file size.</p>
<p>I don't know whether <code>bundletool</code> could support such a scheme. I guess that's where you could look for clues.</p>
<p>They may just be stripping the dev's upload signature and replacing it with their own. The only protection against signature stripping comes from checks done by the receiver.</p>
<p>When it comes down to it, you cannot trust any crypto scheme if you might consider the receiving endpoint to be compromised. Whether the payload is encrypted (which in this case it isn't) or merely signed, if the endpoint is not going to enforce the scheme, the sender and the user are both potentially exposed.</p>
<p>Technically, in this case, the crypto on the endpoint is in the control of the device manufacturer, although it is questionable whether they would actually exercise that control against the will or interests of the OS provider - Google - assuming that manufacturers even check these things.</p>
","14700699","","","","","2022-02-13 20:24:29","","","","4","","","","CC BY-SA 4.0"
"72336625","2","","62496779","2022-05-22 10:17:23","","0","","<p>I find a away to workaround, just create a file bat with content</p>
<blockquote>
<p>powershell Start-Process -Verb RunAs wt.exe</p>
</blockquote>
<ol>
<li>Save file yourfile.bat to folder you want.</li>
<li>Add path folder to System Environment.</li>
<li>Press WINDOW + R and type file bat name.</li>
</ol>
","13219187","","","","","2022-05-22 10:17:23","","","","0","","","","CC BY-SA 4.0"
"61122329","2","","61114929","2020-04-09 13:30:21","","10","","<blockquote>
  <p>I am aware that testing <code>__cplusplus</code> via preprocessor is possible, however compilers phase in C++20 support in various stages so this is not a reliable indicator in either direction.</p>
</blockquote>

<p>Indeed! In fact, this is why we now have an entirely new method of detecting feature support for compilers that are in various stages of release: feature-test macros! If you look at <a href=""https://isocpp.org/std/standing-documents/sd-6-sg10-feature-test-recommendations"" rel=""noreferrer"">SD-FeatureTest</a>, there are large tables of macros corresponding to each language and library feature adopted into the standard, where each macro will be defined with the specified value once a feature is adopted.</p>

<p>In your specific case, you want <a href=""https://isocpp.org/std/standing-documents/sd-6-sg10-feature-test-recommendations#__cpp_lib_endian"" rel=""noreferrer""><code>__cpp_lib_endian</code></a>.</p>

<p>Now the problem with library macros is that we started added them <em>before</em> we added a place to put them - which would be <code>&lt;version&gt;</code>. If you're on a compiler that has <code>&lt;version&gt;</code> (which would be gcc 9+, clang 7+ with libc++, and I don't know about MSVC), you can just include that. But it might not, so you might also have to try to include the correct header (in this case <code>&lt;bit&gt;</code>). </p>

<pre><code>#if __has_include(&lt;bit&gt;)
#  include &lt;bit&gt;
#  ifdef __cpp_lib_endian
#    define HAS_ENDIAN 1
#  endif
#endif

#ifdef HAS_ENDIAN
constexpr bool is_little_endian = std::endian::native == std::endian::little;
#else
constexpr bool is_little_endian = /* ... figure it out ... */;
#endif
</code></pre>

<p>Although it might be better to do:</p>

<pre><code>#ifdef HAS_ENDIAN
using my_endian = std::endian;
#else
enum class my_endian {
   // copy some existing implementation
};
#endif

constexpr bool is_little_endian = my_endian::native == my_endian::little;
</code></pre>
","2069064","","2069064","","2020-04-10 13:44:33","2020-04-10 13:44:33","","","","1","","","","CC BY-SA 4.0"
"61181916","2","","61177302","2020-04-13 05:18:13","","7","","<p>This goes all the way back to the <a href=""https://wg21.link/n3351"" rel=""nofollow noreferrer"">Palo Alto report</a>, §3.3 and D.2.</p>
<p>For the cross-type concepts to be mathematically sound, you need to define what the cross-type comparison means. For <code>equality_comparable_with</code>, <code>t == u</code> generally means that <code>t</code> and <code>u</code> are equal, but what does it even mean for two values of different types to be equal? The design says that cross-type equality is defined by mapping them to the common (reference) type (this conversion is required to preserve the value).</p>
<p>Where the strong axioms of <code>equality_comparable_with</code> is not desirable, the standard uses the exposition-only concept <em><code>weakly-equality-comparable-with</code></em>, and that concept doesn't require a common reference. It is, however, a &quot;semantic abomination&quot; (in the words of Casey Carter) and is exposition-only for that reason: it allows having <code>t == u</code> and <code>t2 == u</code> but <code>t != t2</code> (this is actually necessary for sentinels).</p>
","2756719","","1896169","","2021-04-04 05:36:37","2021-04-04 05:36:37","","","","5","","","","CC BY-SA 4.0"
"61245662","2","","60583049","2020-04-16 08:18:29","","7","","<p>So following MDN documentation on this:</p>

<p><a href=""https://developer.mozilla.org/en-US/docs/Web/API/Window/close"" rel=""noreferrer"">window.close</a></p>

<blockquote>
  <p>In the past, when you called the window object's close() method directly, rather than calling close() on a window instance, the browser closed the frontmost window, whether your script created that window or not. <strong>This is no longer the case; for security reasons, scripts are no longer allowed to close windows they didn't open.</strong></p>
</blockquote>

<p>Following the <a href=""https://html.spec.whatwg.org/multipage/window-object.html#dom-window-close"" rel=""noreferrer"">living standard</a></p>

<blockquote>
  <p>If current is null or its is closing is true, then return. <strong>(Here is when the problem comes, as browsing context is null unless you opened a new document using the javascript context)</strong></p>
  
  <p>If all the following are true:</p>
  
  <ul>
  <li>current is script-closable</li>
  <li>the incumbent global object's browsing context is familiar with current</li>
  <li>the incumbent global object's browsing context is allowed to navigate current</li>
  </ul>
</blockquote>

<p>Also from the second part the script is going to be considered non-script-closable (<a href=""https://html.spec.whatwg.org/multipage/window-object.html#script-closable"" rel=""noreferrer"">Here you have more info</a>)</p>

<blockquote>
  <p>A browsing context is script-closable if it is an auxiliary browsing context that was created by a script (as opposed to by an action of the user), or if it is a top-level browsing context whose session history contains only one Document.</p>
</blockquote>

<p>So I am afraid that in modern browsers is quite impossible to actually close the current tab without having control over who opened it. This also applies to windows opened by iframes. All the info is in the current standard that I linked and the reasons are among the ones I quoted. Back some years there were work arounds using <code>open("""", ""_self"")</code> and similar solutions, but I believe this one have been patched.</p>

<p>In case of PWA, you will be only able to close the application as long as there are no push events in the browse history (this means that <code>window.history.length</code> remains 1 for the whole navigation. In that case your application will be considered a top-level browsing context with only one document, hence <code>window.close()</code> will do. This last affirmation can be tested: Go to twitter.com -> Install Twitter PWA -> Open the PWA -> open console and write <code>window.close()</code>, it will inmediately shut the window. In the moment it navigates into any link within the PWA, the condition of history having only one document is unmeet.</p>

<p>Extra trying to find why was this a security issue:
<a href=""https://security.stackexchange.com/questions/120116/security-feature-preventing-javascript-from-closing-the-window"">https://security.stackexchange.com/questions/120116/security-feature-preventing-javascript-from-closing-the-window</a></p>

<p><a href=""https://security.stackexchange.com/questions/133744/why-do-browsers-disallow-script-closing-an-opener-window-yet-allow-changing-its"">https://security.stackexchange.com/questions/133744/why-do-browsers-disallow-script-closing-an-opener-window-yet-allow-changing-its</a></p>
","4734657","","4734657","","2020-04-17 16:10:29","2020-04-17 16:10:29","","","","11","","","","CC BY-SA 4.0"
"61278375","2","","61278180","2020-04-17 18:34:17","","1","","<p>A user defined literal suffix, <em>ud-suffix</em>, is an <em>identifier</em>.  An <em>identifier</em> is a sequence of letters (including some non-ASCII characters), the underscore, and numbers that does not start with a number.  The period character is not included.</p>

<p>Therefore it is a compiler bug as it is treating the non-identifier sequence <code>f.T</code> as an identifier.</p>

<p>The <code>0.</code> is a <em>fractional-constant</em>, which can be followed by an optional exponent, then either a <em>ud-suffix</em> (for a user defined literal) or a <em>floating-point-suffix</em> (one of <code>fFlL</code>). The <code>f</code> can be considered a <em>ud-suffx</em> as well, but since it matches another literal type it should be that and not the UDL. A <em>ud-suffix</em> is defined in the grammar as an identifier.</p>
","5231607","","5231607","","2020-04-17 22:40:50","2020-04-17 22:40:50","","","","3","","","","CC BY-SA 4.0"
"61283275","2","","61278180","2020-04-18 01:42:05","","3","","<p>The parsing of numerical tokens is quite crude, and allows many things that aren't actually valid numbers. In C++98, the grammar for a ""preprocessing number"", found in [lex.ppnumber], is</p>

<pre><code>pp-number:
    digit
    . digit
    pp-number digit
    pp-number nondigit
    pp-number e sign
    pp-number E sign
    pp-number .
</code></pre>

<p>Here, a ""nondigit"" is any character that can be used in an identifier, other than digits, and a ""sign"" is either + or -. Later standards would expand the definition to allow single quotes (C++14), and sequences of the form p-, p+, P-, P+ (C++17).</p>

<p>The upshot is that, in any version of the standard, while a preprocessing number is required to start with a digit, or a period followed by a digit, after that an arbitrary sequence of digits, letters, and periods may follow. Using the maximal munch rule, it follows that <code>0.f.T::~T();</code> is required to be tokenized as <code>0.f.T :: ~ T ( ) ;</code>, even though <code>0.f.T</code> isn't a valid numerical token. </p>

<p>Thus, the code is <strong>not</strong> syntactically valid.</p>
","2673243","","","","","2020-04-18 01:42:05","","","","1","","","","CC BY-SA 4.0"
"61400345","2","","61398801","2020-04-24 02:56:16","","7","","<p><em>Disclosure: IntelliJ IDEA developer is here.</em></p>

<hr>

<p>Currently, IntelliJ IDEA only suggests converting the complete literal concatenation into the text block. Here, however, you have a concatenation that involves the <code>tableName</code> variable. This prevents inspection from starting. You can work-around this adding bogus parentheses:</p>

<pre class=""lang-java prettyprint-override""><code>String sql = ""CREATE TABLE "" + tableName + ("" (\n"" +
             ""  id_ UUID DEFAULT random_uuid() PRIMARY KEY ,\n"" +
             ""  when_ TIMESTAMP WITHOUT TIME ZONE NOT NULL\n"" +
             ""  duration_ STRING NOT NULL\n"" +
             "");"");
</code></pre>

<p>After that, the conversion is suggested on the first <code>\n</code> character:</p>

<p><a href=""https://i.stack.imgur.com/ttIr2.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ttIr2.png"" alt=""IntelliJ IDEA screenshot""></a></p>

<p>The result after removing parentheses looks like this:</p>

<pre class=""lang-java prettyprint-override""><code>String sql = ""CREATE TABLE "" + tableName + """"""
         (
          id_ UUID DEFAULT random_uuid() PRIMARY KEY ,
          when_ TIMESTAMP WITHOUT TIME ZONE NOT NULL
          duration_ STRING NOT NULL
        );"""""";
</code></pre>

<p>I filed an <a href=""https://youtrack.jetbrains.com/issue/IDEA-238736"" rel=""noreferrer"">issue</a> to suggest the conversion if only a part of concatenation can be converted to the text block.</p>

<p>An alternative solution, which actually is promoted by JDK, is to use string formatting. First, use intention action ""Replace '+' with 'String.format()'"" (it's available via Alt+Enter everywhere inside the concatenation). The result looks like this:</p>

<pre class=""lang-java prettyprint-override""><code>String sql = String
    .format(""CREATE TABLE %s (\n  id_ UUID DEFAULT random_uuid() PRIMARY KEY ,\n  when_ TIMESTAMP WITHOUT TIME "" +
            ""ZONE NOT NULL\n  duration_ STRING NOT NULL\n);"", tableName);
</code></pre>

<p>Now it's immediately suggested to use text block, and the result looks like this:</p>

<pre class=""lang-java prettyprint-override""><code>String sql = String.format(""""""
        CREATE TABLE %s (
          id_ UUID DEFAULT random_uuid() PRIMARY KEY ,
          when_ TIMESTAMP WITHOUT TIME ZONE NOT NULL
          duration_ STRING NOT NULL
        );"""""", tableName);
</code></pre>

<p>Unfortunately, a new instance method <code>.formatted()</code> is not suggested (filed <a href=""https://youtrack.jetbrains.com/issue/IDEA-238738"" rel=""noreferrer"">another issue</a>), so it will require some manual work to convert it:</p>

<pre class=""lang-java prettyprint-override""><code>String sql = """"""
        CREATE TABLE %s (
          id_ UUID DEFAULT random_uuid() PRIMARY KEY ,
          when_ TIMESTAMP WITHOUT TIME ZONE NOT NULL
          duration_ STRING NOT NULL
        );"""""".formatted(tableName);
</code></pre>
","4856258","","","","","2020-04-24 02:56:16","","","","0","","","","CC BY-SA 4.0"
"62193239","2","","62184501","2020-06-04 11:14:19","","14","","<p>V8 developer here. What you're seeing is fairly typical:</p>

<p>The built-in <code>.slice()</code> function for regular arrays is heavily optimized, taking all sorts of shortcuts and specializations (it even goes as far as using <code>memcpy</code> for arrays containing only numbers, hence copying more than one element at a time using your CPU's vector registers!). That makes it the fastest option.</p>

<p>Calling <code>Array.prototype.slice</code> on a custom object (like a subclassed array, or just <code>let obj = {length: 100_000_000, foo: ""bar"", ...}</code>) doesn't fit the restrictions of the fast path, so it's handled by a generic implementation of the <code>.slice</code> builtin, which is much slower, but can handle anything you throw at it. This is not JavaScript code, so it doesn't collect type feedback and can't get optimized dynamically. The upside is that it gives you the same performance every time, no matter what. This performance is not actually <em>bad</em>, it just pales in comparison to the optimizations you get with the alternatives.</p>

<p>Your own implementation, like all JavaScript functions, gets the benefit of dynamic optimization, so while it naturally can't have any fancy shortcuts built into it right away, it can adapt to the situation at hand (like the type of object it's operating on). That explains why it's faster than the generic builtin, and also why it provides consistent performance in both of your test cases. That said, if your scenario were more complicated, you could probably pollute this function's type feedback to the point where it becomes slower than the generic builtin.</p>

<p>With the <code>[i, item] of source.entries()</code> approach you're coming close to the spec behavior of <code>.slice()</code> very concisely at the cost of some overhead; a plain old <code>for (let i = 0; i &lt; source.length; i++) {...}</code> loop would be about twice as fast, even if you add an <code>if (i in source)</code> check to reflect <code>.slice()</code>'s ""HasElement"" check on every iteration.</p>

<hr>

<p>More generally: you'll probably see the same general pattern for many other JS builtins -- it's a natural consequence of running on an optimizing engine for a dynamic language. As much as we'd love to just make everything fast, there are two reasons why that won't happen:</p>

<p>(1) Implementing fast paths comes at a cost: it takes more engineering time to develop (and debug) them; it takes more time to update them when the JS spec changes; it creates an amount of code complexity that quickly becomes unmanageable leading to further development slowdown and/or functionality bugs and/or security bugs; it takes more binary size to ship them to our users and more memory to load such binaries; it takes more CPU time to decide which path to take before any of the actual work can start; etc. Since none of those resources are infinite, we'll always have to choose where to spend them, and where not.</p>

<p>(2) Speed is fundamentally at odds with flexibility. Fast paths are fast because they get to make restrictive assumptions. Extending fast paths as much as possible so that they apply to as many cases as possible is part of what we do, but it'll always be easy for user code to construct a situation that makes it impossible to take the shortcuts that make a fast path fast.</p>
","6036428","","","","","2020-06-04 11:14:19","","","","9","","","","CC BY-SA 4.0"
"62742065","2","","62738704","2020-07-05 14:35:25","","4","","<p>The second Attempt Edited after comment</p>
<pre class=""lang-rb prettyprint-override""><code># This solution has a limit you have to return the `Proc` itself
with_proc = proc do |aproc, others|
  aproc.instance_variable_set(:@a, aproc.instance_variable_get(:@a) || 0)
  aproc.instance_variable_set(:@a, aproc.instance_variable_get(:@a) + 1)
  p self: aproc, arg: others, '@a': aproc.instance_variable_get(:@a)
  aproc
end

prc = with_proc.(with_proc, :foo)
# =&gt; {:self=&gt;#&lt;Proc:0x000055864be1a740@pro_self.rb:1&gt;, :arg=&gt;:foo, :@a=&gt;1}

puts &quot;prc: #{prc}&quot;
puts &quot;prc.equal?(with_proc): #{prc.equal?(with_proc)}&quot;
# =&gt; prc: #&lt;Proc:0x000055864be1a740@pro_self.rb:1&gt;
# =&gt; prc.equal?(with_proc): true

prc.call(prc, :bar)
puts &quot;prc @a: #{prc.instance_variable_get(:@a)}&quot;
# =&gt; {:self=&gt;#&lt;Proc:0x000055864be1a740@pro_self.rb:1&gt;, :arg=&gt;:bar, :@a=&gt;2}
# =&gt; prc @a: 2

other_prc = prc.call(prc.clone, :baz)
puts &quot;other_prc: #{other_prc}&quot;
# =&gt; {:self=&gt;#&lt;Proc:0x000055864be1a0b0@pro_self.rb:1&gt;, :arg=&gt;:baz, :@a=&gt;3}
# =&gt; other_prc: #&lt;Proc:0x000055864be1a0b0@pro_self.rb:1&gt;


other_prc.call(other_prc, :qux)
#=&gt; {:self=&gt;#&lt;Proc:0x000055864be1a0b0@pro_self.rb:1&gt;, :arg=&gt;:qux, :@a=&gt;4}

prc.call(prc, :quux)
# =&gt; {:self=&gt;#&lt;Proc:0x000055864be1a740@pro_self.rb:1&gt;, :arg=&gt;:quux, :@a=&gt;3}
</code></pre>
<p>With this solution you can return whatever is necessary</p>
<pre class=""lang-rb prettyprint-override""><code>prc = proc do |ref_to_self, others|
  self_reference = ref_to_self.instance_variable_get(:@ident)
  self_reference.instance_variable_set(:@a, self_reference.instance_variable_get(:@a) || 0)
  self_reference.instance_variable_set(:@a, self_reference.instance_variable_get(:@a) + 1)
  p ({self: self_reference.instance_variable_get(:@ident),
    arg: others,
    '@a': self_reference.instance_variable_get(:@a)})
end
prc.instance_variable_set(:@ident, prc)
prc.call(prc, :foo)

puts &quot;prc: #{prc}&quot;

prc.call(prc, :bar)
puts &quot;prc @a: #{prc.instance_variable_get(:@a)}&quot;

other_prc = prc.clone
other_prc.instance_variable_set(:@ident, other_prc)
other_prc.call(other_prc, :baz)
puts &quot;other_prc: #{other_prc}&quot;

other_prc.call(other_prc, :qux)

prc.call(prc, :quux)
# {:self=&gt;#&lt;Proc:0x00005559f1f6d808@pro_self.rb:71&gt;, :arg=&gt;:foo, :@a=&gt;1}
# prc: #&lt;Proc:0x00005559f1f6d808@pro_self.rb:71&gt;
# {:self=&gt;#&lt;Proc:0x00005559f1f6d808@pro_self.rb:71&gt;, :arg=&gt;:bar, :@a=&gt;2}
# prc @a: 2
# {:self=&gt;#&lt;Proc:0x00005559f1f6d1f0@pro_self.rb:71&gt;, :arg=&gt;:baz, :@a=&gt;3}
# other_prc: #&lt;Proc:0x00005559f1f6d1f0@pro_self.rb:71&gt;
# {:self=&gt;#&lt;Proc:0x00005559f1f6d1f0@pro_self.rb:71&gt;, :arg=&gt;:qux, :@a=&gt;4}
# {:self=&gt;#&lt;Proc:0x00005559f1f6d808@pro_self.rb:71&gt;, :arg=&gt;:quux, :@a=&gt;3}
</code></pre>
<p>First Attempt</p>
<p>Edited after comment. That I know there is not a direct way to reference a <code>Proc</code> object inside the block you pass to <code>new</code> I tried to get closer to your code using tap.
I hope this can help</p>
<pre class=""lang-rb prettyprint-override""><code>def proc_reference_to_self(a_proc)
  first = Proc.new do
    puts &quot;Hello&quot;

  end.tap(&amp;a_proc)
end

second_prc = Proc.new do |first|
  p first
  first.call
  puts &quot;second_prc&quot;
  p second_prc
end

# This execute second_prc as a block
proc_reference_to_self(second_prc)

# first and second are different objects but you can still reference first
# inside second_proc

# &lt;Proc:0x000055603a8c72e8@ruby_array_of_paths.rb:75&gt;
# Hello
# second_prc
# &lt;Proc:0x000055603a8c7338@ruby_array_of_paths.rb:81&gt;
</code></pre>
","9174431","","9174431","","2020-07-21 19:28:40","2020-07-21 19:28:40","","","","4","","","","CC BY-SA 4.0"
"67289417","2","","67289057","2021-04-27 19:21:53","","20","","<p>Isn't an answer to &quot;why&quot;; however you could change it to a ternary operator slicing the result of the array assignment to a Span:</p>
<pre><code>public static void StackAllocFun(int count)
{
    int[] oversized = null;
    try
    {
        Span&lt;int&gt; s = ((uint)count &lt; 32) ?
            stackalloc int[count] :
            (oversized = ArrayPool&lt;int&gt;.Shared.Rent(count)).AsSpan(0, count);

        Populate(s);
        DoSomethingWith(s);
    }
    finally
    {
        if (oversized is not null)
        {
            ArrayPool&lt;int&gt;.Shared.Return(oversized);
        }
    }
}
</code></pre>
","1109918","","1109918","","2021-04-27 20:11:38","2021-04-27 20:11:38","","","","2","","","","CC BY-SA 4.0"
"60151054","2","","60150749","2020-02-10 13:04:01","","44","","<p>Here is a trick which triggers a linker error if a required initializer is missing:</p>

<pre><code>struct init_required_t {
    template &lt;class T&gt;
    operator T() const; // Left undefined
} static const init_required;
</code></pre>

<p>Usage:</p>

<pre><code>struct Foo {
    int bar = init_required;
};

int main() {
    Foo f;
}
</code></pre>

<p>Outcome:</p>

<pre><code>/tmp/ccxwN7Pn.o: In function `Foo::Foo()':
prog.cc:(.text._ZN3FooC2Ev[_ZN3FooC5Ev]+0x12): undefined reference to `init_required_t::operator int&lt;int&gt;() const'
collect2: error: ld returned 1 exit status
</code></pre>

<p>Caveats:</p>

<ul>
<li>Prior to C++14, this prevents <code>Foo</code> from being an aggregate at all.</li>
<li>This technically relies on undefined behaviour (ODR violation), but should work on any sane platform.</li>
</ul>
","3233393","","3233393","","2020-02-11 15:07:48","2020-02-11 15:07:48","","","","13","","","","CC BY-SA 4.0"
"67290012","2","","67289057","2021-04-27 20:09:11","","57","","<p>The <code>Span&lt;T&gt; / ref</code> feature is essentially a series of rules about to which scope a given value can escape by value or by reference. While this is written in terms of method scopes  it's helpful to simplify to just one of two statements:</p>
<ol>
<li>The value cannot be returned from the method</li>
<li>The value can be returned from the method</li>
</ol>
<p>The <a href=""https://github.com/dotnet/csharplang/blob/main/proposals/csharp-7.2/span-safety.md"" rel=""nofollow noreferrer"">span safety doc</a> goes into great detail about how the scope is calculated for various statements and expressions. The relevant part here though is for how <a href=""https://github.com/dotnet/csharplang/blob/main/proposals/csharp-7.2/span-safety.md#locals"" rel=""nofollow noreferrer"">locals</a> are processed.</p>
<p>The main take away is that whether or not a local can return is calculated at the local declaration time. At the point the local is declared the compiler examines the initializer and makes a decision about whether the local can or cannot be return from the method. In the case there is an initializer then the local will be able to return if the initialization expression is able to be returned.</p>
<p>How do you handle the case where a local is declared but there is no initializer? The compiler has to make a decision: can it or can it not return? When designing the feature we made the decision that the default would be &quot;it can be returned&quot; because it's the decision that caused the least amount of friction for existing patterns.</p>
<p>That did leave us with the problem of how developers could declare a local that wasn't safe to return but also lacked an initializer. Eventually we settled on the pattern of <code>= stackalloc [0]</code>. This is an expression that is safe to optimize away and a strong indicator, basically a requirement, that the local isn't safe to return.</p>
<p>Knowing that this explains the behavior you are seeing:</p>
<ul>
<li><code>Span&lt;int&gt; s = stackalloc[0]</code>: this is not safe to return hence the later <code>stackalloc</code> succeeds</li>
<li><code>Span&lt;int&gt; s = default</code>: this is safe to return because <code>default</code> is safe to return. This means the later <code>stackalloc</code> fails because you're assigning a value that isn't safe to return to a local that is marked as safe to return</li>
<li><code>Span&lt;int&gt; s;</code>: this is safe to return because that is the default for unininitialized locals. This means the later <code>stackalloc</code> fails because you're assigning a value that isn't safe to return to a local that is marked as safe to return</li>
</ul>
<p>The real downside to the <code>= stackalloc[0]</code> approach is that it's only applicable to <code>Span&lt;T&gt;</code>. It's not a general solution for <code>ref struct</code>. In practice though it's not as much of a problem for other types. There is some speculation on how we could make it <a href=""https://github.com/dotnet/csharplang/blob/main/proposals/low-level-struct-improvements.md#allowing-attributes-on-locals"" rel=""nofollow noreferrer"">more general</a> but not enough evidence to justify doing it at this point.</p>
","23283","","2501279","","2022-04-25 07:56:58","2022-04-25 07:56:58","","","","3","","","","CC BY-SA 4.0"
"62969918","2","","62969917","2020-07-18 14:48:59","","387","","<p>The Android Gradle Plugin needs to know about new manifest elements, particularly
for the manifest merger process. The plugin has a tendency to get confused if it
sees elements in the manifest merger that it does not recognize, tossing out
build errors like the one in the question.</p>
<p>In this case, Android 11 introduced <code>&lt;queries&gt;</code> as a manifest element, and older versions of the Android Gradle Plugin do not know about that element.</p>
<p>The fact that this occurs from manifest merger means that simply upgrading a dependency
might bring about this error. For example, if you upgrade to the latest
version of <code>com.awesome:awesome-library</code>, and it contained a <code>&lt;queries&gt;</code> element
in its manifest, you might crash with the aforementioned error in your builds,
even without any other changes in your code.</p>
<p>Google released a series of patch versions of the Android Gradle Plugin to address this:</p>
<ul>
<li><code>3.3.3</code></li>
<li><code>3.4.3</code></li>
<li><code>3.5.4</code></li>
<li><code>3.6.4</code></li>
<li><code>4.0.1</code></li>
</ul>
<p>If you are using an existing plugin in the <code>3.3.*</code> through <code>4.0.*</code> series, upgrade
to the associated patch version (or higher) from that list, and you should no longer
run into that error (e.g., <code>classpath 'com.android.tools.build:gradle:4.0.1'</code>).</p>
<p>If you are using Android Studio 4.1 or higher, with a matching
Android Gradle Plugin (e.g., in the <code>4.1.*</code> series), you should be fine without
any changes. Those plugin versions were already aware of <code>&lt;queries&gt;</code>.</p>
<p>See <a href=""https://android-developers.googleblog.com/2020/07/preparing-your-build-for-package-visibility-in-android-11.html"" rel=""noreferrer"">this Android Developers Blog post</a> for more.</p>
","115145","","115145","","2020-12-02 00:04:04","2020-12-02 00:04:04","","","","12","","","","CC BY-SA 4.0"
"64854044","2","","62969917","2020-11-16 07:24:38","","99","","<p>I had this issue in Flutter, but I believe this solution will work for both Flutter and native Flutter development.</p>
<p>Follow these steps</p>
<ol>
<li><p>Read this short blog post to get some understanding: <em><a href=""https://android-developers.googleblog.com/2020/07/preparing-your-build-for-package-visibility-in-android-11.html"" rel=""nofollow noreferrer"">Preparing your Gradle build for package visibility in Android 11</a></em></p>
</li>
<li><p>Delete the <em>.gradle</em> folder inside the Android folder, i.e., android &gt; .gradle</p>
</li>
<li><p>In the project <em>build.gradle</em> file, upgrade your class path appropriately based on the blog in the link above, e.g., I upgraded to  <code>classpath 'com.android.tools.build:gradle:4.0.1'</code></p>
</li>
<li><p>Upgrade the distribution URL too. It's in android&gt;gradle&gt;gradle-wrapper.properties file appropriately. E.g., I upgraded it to <code>distributionUrl=https\://services.gradle.org/distributions/gradle-6.1.1-all.zip </code></p>
</li>
<li><p>You can invalidate caches and restart your Android Studio. Make sure you have a good Internet connection, because it will download the new <a href=""https://en.wikipedia.org/wiki/Gradle"" rel=""nofollow noreferrer"">Gradle</a> files.</p>
</li>
</ol>
","8095270","","63550","","2022-08-19 15:46:22","2022-08-19 15:46:22","","","","5","","","","CC BY-SA 4.0"
"66851218","2","","62969917","2021-03-29 08:49:38","","58","","<p>Fixing the error is very simple.
Update your Android Studio to the last version
and use the last stable <a href=""https://en.wikipedia.org/wiki/Gradle"" rel=""noreferrer"">Gradle</a> plugin version.
At the current time, I use <strong>Android Studio</strong> version <strong>4.1.3</strong> with <strong>Gradle Plugin 6.8.2</strong></p>
<p>For use in <em>queries</em>, you should write <em>queries</em> code in out of <em>application</em> tag, not inside <strong>application</strong> tag.</p>
<p>For more information, see the photo below:</p>
<p><a href=""https://i.stack.imgur.com/ks0AY.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ks0AY.jpg"" alt=""https://i.stack.imgur.com/ks0AY.jpg"" /></a></p>
","7654269","","63550","","2022-08-19 15:37:29","2022-08-19 15:37:29","","","","2","","","","CC BY-SA 4.0"
"60140212","2","","60114639","2020-02-09 18:59:33","","24","","<h2>Interim solution</h2>

<p>Here are the solutions for different variants of <em>Chrome</em> users.</p>

<ul>
<li><p>If you are using <em>Chrome v80</em>, using the recently released <a href=""https://chromedriver.storage.googleapis.com/index.html?path=80.0.3987.106/"" rel=""noreferrer"">ChromeDriver 80.0.3987.106</a> solves the issue.</p>

<ul>
<li><p>Code Block:</p>

<pre><code>System.setProperty(""webdriver.chrome.driver"", ""C:\\Utility\\BrowserDrivers\\chromedriver.exe"");
WebDriver driver =  new ChromeDriver();
driver.quit();
</code></pre></li>
<li><p>Console Output:</p>

<pre><code>Starting ChromeDriver 80.0.3987.106 (f68069574609230cf9b635cd784cfb1bf81bb53a-refs/branch-heads/3987@{#882}) on port 20041
Only local connections are allowed.
Please protect ports used by ChromeDriver and related test frameworks to prevent access by malicious code.
Feb 14, 2020 9:50:57 PM org.openqa.selenium.remote.ProtocolHandshake createSession
INFO: Detected dialect: W3C
</code></pre></li>
</ul></li>
<li><p>If you are using <em>Chrome v81</em>, using the recently released <a href=""https://chromedriver.storage.googleapis.com/index.html?path=81.0.4044.20/"" rel=""noreferrer"">ChromeDriver 81.0.4044.20</a> solves the issue.</p></li>
<li>If you are using <em>Chrome</em> from <a href=""https://sites.google.com/a/chromium.org/chromedriver/chromedriver-canary"" rel=""noreferrer"">Dev or Canary</a> channel you need to pickup the platform specific binaries:

<ul>
<li><a href=""https://commondatastorage.googleapis.com/chromium-browser-snapshots/index.html?prefix=Linux_x64/"" rel=""noreferrer""><em>Linux (64-bit)</em></a></li>
<li><a href=""https://commondatastorage.googleapis.com/chromium-browser-snapshots/index.html?prefix=Mac/"" rel=""noreferrer""><em>Mac OS X (64-bit)</em></a></li>
<li><a href=""https://commondatastorage.googleapis.com/chromium-browser-snapshots/index.html?prefix=Win/"" rel=""noreferrer""><em>Windows (32-bit)</em></a></li>
</ul></li>
</ul>

<hr>

<h2>Permanent Solution</h2>

<p>However, <code>@bugdroid</code> submitted the actual fix through this <a href=""https://chromium.googlesource.com/chromium/src.git/+/dcbaf5c4515f769df80c54ba50baa4b61e634709"" rel=""noreferrer"">revision</a> / <a href=""https://chromium.googlesource.com/chromium/src/+/dcbaf5c4515f769df80c54ba50baa4b61e634709"" rel=""noreferrer"">commit</a> which is as follows:</p>

<blockquote>
  <p><strong>[ChromeDriver] suppress logging of retry loop timeout</strong>: <a href=""https://cr-rev.appspot.com/1924789"" rel=""noreferrer"">r1924789</a> added a retry loop while waiting for DevTools messages. This spammed users' logs with uninformative timeout reports. This CL suppresses those log messages and correctly reports the command timeout
  value when appropriate.</p>
</blockquote>

<p><strong>Note</strong>:</p>

<blockquote>
  <ul>
  <li>Status: Fixed</li>
  <li>Labels: ToBeReleased ChromeDriver-82</li>
  </ul>
</blockquote>

<hr>

<h2>History</h2>

<p>This error message...</p>

<pre><code>[1581082020.245][SEVERE]: Timed out receiving message from renderer: 0.100
</code></pre>

<p>...does not necessarily indicate a failure.</p>

<p>As @Tricia <a href=""https://groups.google.com/forum/?utm_medium=email&amp;utm_source=footer#!msg/chromedriver-users/ivfLFmdVNnQ/Z1HoX1lKEwAJ"" rel=""noreferrer"">mentions</a> that, ChromeDriver Version 80 modified a wait loop to allow more retries; this loop will generate that message, but it continues to listen. However the <em>SEVERE</em> tag for that message is misleading.</p>

<p>Further, in the discussion <a href=""https://bugs.chromium.org/p/chromedriver/issues/detail?id=3332"" rel=""noreferrer"">Issue 3332: Retry timeout logged as severe</a>, <a href=""https://bugs.chromium.org/u/1356571735/"" rel=""noreferrer"">@triciac</a> [ChromeDriver Committer] also added that, ChromeDriver team added a small timeout (100 ms) to <code>DevToolsClientImpl::HandleEventsUntil</code> to enable additional checking of navigation status. But, unfortunately when this timeout was expiring, it is logged as <em>SEVERE</em> (by <code>ProcessNextMessage</code>). In the case of this small timeout, it should not log as <em>SEVERE</em>, although timeouts from <code>SendCommandInternal</code> still should.</p>

<p>So ChromeDriver needs a way to control the logging in a better way, possibly by increasing the timeout. However, if the command finally times out, the <em>timeout</em> duration listed being very small, then it is needed to list the user-defined timeout instead.</p>

<hr>

<h2>Immediate solution</h2>

<p>As an interim solution, you can downgrade to <a href=""https://chromedriver.storage.googleapis.com/index.html?path=79.0.3945.36/"" rel=""noreferrer"">ChromeDriver v79.0.3945.36</a> as it seems the <em>SEVERE</em> logs doesn't shows up in the console but you will observe the <em>WARNING</em>:</p>

<pre><code>[WARNING]: This version of ChromeDriver has not been tested with Chrome version 80
</code></pre>

<p>which sounds like a <em>...safe workaround...</em> and had been confirmed by a <em>Chromium</em> team member.</p>

<p><img src=""https://i.stack.imgur.com/Z3vco.png"" alt=""chromedriver79""></p>

<ul>
<li><p>Code Block:</p>

<pre><code>public class A_Chrome 
{
    public static void main(String[] args) 
    {
        System.setProperty(""webdriver.chrome.driver"", ""C:\\Utility\\BrowserDrivers\\chromedriver.exe"");
        WebDriver driver =  new ChromeDriver();
        driver.get(""https://www.google.com/"");
        driver.quit();
    }
}
</code></pre></li>
<li><p>Console Output:</p>

<pre><code>Starting ChromeDriver 79.0.3945.36 (3582db32b33893869b8c1339e8f4d9ed1816f143-refs/branch-heads/3945@{#614}) on port 9200
Only local connections are allowed.
Please protect ports used by ChromeDriver and related test frameworks to prevent access by malicious code.
[1581503845.444][WARNING]: This version of ChromeDriver has not been tested with Chrome version 80.
Feb 12, 2020 4:07:26 PM org.openqa.selenium.remote.ProtocolHandshake createSession
INFO: Detected dialect: W3C
</code></pre></li>
</ul>

<hr>

<h2>tl; dr</h2>

<p>You can find a couple of relevant discussions in:</p>

<ul>
<li><a href=""https://bugs.chromium.org/p/chromedriver/issues/detail?id=3333"" rel=""noreferrer"">Issue 3333: ChromeDriver may block indefinitely while waiting for pending navigation after net::ERR_CONTENT_DECODING_FAILED</a></li>
<li><a href=""https://bugs.chromium.org/p/chromedriver/issues/detail?id=3336"" rel=""noreferrer"">Issue 3336: WebDriver 80.0.3987.16 can't open Chrome on Linux</a></li>
</ul>
","7429447","","7429447","","2020-02-17 22:19:15","2020-02-17 22:19:15","","","","6","","","","CC BY-SA 4.0"
"60140669","2","","60114639","2020-02-09 19:49:59","","16","","<p><strong>Root cause:</strong> Whenever you are loading some page with the help of selenium driver,  then <code>driver</code> script wait till page is completely loaded. But sometimes webdriver takes more time to load a page, in that case, you will see the <code>TimeoutException</code> exception in your console.</p>
<p><strong>Solution:</strong> When Page Loading takes too much time and you need to stop <strong>downloading additional subresources (images, CSS, js, etc)</strong> you can change the pageLoadStrategy through the webdriver.</p>
<p>Below code just load the <strong>html content</strong> from page. You can set page load strategy from <strong>chromeoptions</strong></p>
<pre><code>ChromeOptions options = new ChromeOptions();
options.setPageLoadStrategy(PageLoadStrategy.NONE);
</code></pre>
<p><strong>Updated Solution -2:</strong> I agree with DebanjanB, PageLoad strategy with None, without download additional files (images, CSS, js, etc) is not a good idea while performing testing. I did search for all issues about it and try to find a valid solution. I tried the below options as sometimes at some point it was able to resolve this issue.</p>
<pre><code>    options.addArguments(&quot;start-maximized&quot;); 
    options.addArguments(&quot;enable-automation&quot;); 
    options.addArguments(&quot;--no-sandbox&quot;); 
    options.addArguments(&quot;--disable-infobars&quot;); 
    options.addArguments(&quot;--disable-dev-shm-usage&quot;); 
    options.addArguments(&quot;--disable-browser-side-navigation&quot;); 
    options.addArguments(&quot;--disable-gpu&quot;);
</code></pre>
<p>None of them helped But I found one solution again with the Page load strategy. This time we are downloading all subresources but we are waiting for the <strong>DOMContentLoaded</strong> event. This strategy called <strong>Eager</strong>. A small definition of available all 3 pageload strategies</p>
<p><strong>1. normal:</strong>
This strategy causes Selenium to wait for the full page loading (HTML content and sub-resources downloaded and parsed).</p>
<p><strong>2. eager:</strong>
This strategy causes Selenium to wait for the DOMContentLoaded event (HTML content downloaded and parsed only).</p>
<p><strong>3. none :</strong>
This strategy causes Selenium to return immediately after the initial page content
is fully received (HTML content downloaded).</p>
<p><strong>NOTE:</strong> By default, when Selenium loads a page, it follows the normal pageLoadStrategy.</p>
<p><strong>Code snippet without using Pageload strategy (Or Normal as used by selenium by default)</strong></p>
<pre><code>System.setProperty(&quot;webdriver.chrome.driver&quot;, &quot;C:\\Users\\...\\LatestDriver\\chromedriver.exe&quot;);   
WebDriver driver=new ChromeDriver();
driver.get(&quot;http://www.google.com&quot;);
driver.manage().window().maximize();
WebDriverWait wait = new WebDriverWait(driver, 20);
WebElement el = wait.until(ExpectedConditions.elementToBeClickable(By.name(&quot;q&quot;)));
el.click();
List &lt;WebElement&gt; allLinks = driver.findElements(By.tagName(&quot;a&quot;));
System.out.println(allLinks.size());
driver.quit();
</code></pre>
<p><strong>Console Output:</strong></p>
<blockquote>
<p>Starting ChromeDriver 80.0.3987.16
(320f6526c1632ad4f205ebce69b99a062ed78647-refs/branch-heads/3987@{#185})
on port 41540
Only local connections are allowed.
Please protect ports used by ChromeDriver and related test frameworks to prevent access by malicious code.
Feb 11, 2020 10:22:12 AM org.openqa.selenium.remote.ProtocolHandshake createSession
INFO: Detected dialect: W3C
[1581412933.937][SEVERE]: Timed out receiving message from renderer: 0.100
[1581412934.066][SEVERE]: Timed out receiving message from renderer: 0.100
[1581412934.168][SEVERE]: Timed out receiving message from renderer: 0.100
[1581412934.360][SEVERE]: Timed out receiving message from renderer: 0.100
[1581412934.461][SEVERE]: Timed out receiving message from renderer: 0.100
[1581412934.618][SEVERE]: Timed out receiving message from renderer: 0.100
[1581412934.719][SEVERE]: Timed out receiving message from renderer: 0.100
[1581412934.820][SEVERE]: Timed out receiving message from renderer: 0.100
[1581412934.922][SEVERE]: Timed out receiving message from renderer: 0.100
[1581412935.097][SEVERE]: Timed out receiving message from renderer: 0.100
21</p>
</blockquote>
<p><strong>With PageLoad Strategy - Eager :</strong></p>
<p><strong>Code Snippet:</strong></p>
<pre><code>System.setProperty(&quot;webdriver.chrome.driver&quot;, &quot;C:\\Users\\...\\LatestDriver\\chromedriver.exe&quot;);
ChromeOptions options = new ChromeOptions();
options.setPageLoadStrategy(PageLoadStrategy.EAGER);
WebDriver driver=new ChromeDriver(options);
driver.get(&quot;http://www.google.com&quot;);
driver.manage().window().maximize();
WebDriverWait wait = new WebDriverWait(driver, 20);
WebElement el = wait.until(ExpectedConditions.elementToBeClickable(By.name(&quot;q&quot;)));
el.click();
List &lt;WebElement&gt; allLinks = driver.findElements(By.tagName(&quot;a&quot;));
System.out.println(allLinks.size());
driver.quit();
</code></pre>
<p><strong>Console Output:</strong></p>
<blockquote>
<p>Starting ChromeDriver 80.0.3987.16
(320f6526c1632ad4f205ebce69b99a062ed78647-refs/branch-heads/3987@{#185})
on port 1175 Only local connections are allowed. Please protect ports
used by ChromeDriver and related test frameworks to prevent access by
malicious code. Feb 11, 2020 10:29:05 AM
org.openqa.selenium.remote.ProtocolHandshake createSession INFO:
Detected dialect: W3C<br />
21</p>
</blockquote>
","10091597","","10893827","","2021-01-14 17:12:27","2021-01-14 17:12:27","","","","4","","","","CC BY-SA 4.0"
"60212603","2","","60079472","2020-02-13 16:33:45","","2","","<ol>
<li>Make sure the intent you broadcast is explicit and has the <code>Intent.FLAG_RECEIVER_FOREGROUND</code> flag.</li>
</ol>

<p><a href=""https://developer.android.com/about/versions/oreo/background#broadcasts"" rel=""nofollow noreferrer"">https://developer.android.com/about/versions/oreo/background#broadcasts</a></p>

<pre><code>Intent intent = new Intent(context, Receiver.class);
intent.setAction(action);
...
intent.addFlags(Intent.FLAG_RECEIVER_FOREGROUND);

PendingIntent operation = PendingIntent.getBroadcast(context, 0, intent, flags);
</code></pre>

<ol start=""2"">
<li>Use <code>setExactAndAllowWhileIdle()</code> when targeting API 23+.</li>
</ol>

<pre><code>if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.M) {
    alarmManager.setExactAndAllowWhileIdle(AlarmManager.RTC_WAKEUP, time, operation);
} else if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.KITKAT) {
    alarmManager.setExact(AlarmManager.RTC_WAKEUP, time, operation);
} else {
    alarmManager.set(AlarmManager.RTC_WAKEUP, time, operation);
}
</code></pre>

<ol start=""3"">
<li>Start your alarm as a Foreground Service:</li>
</ol>

<p><a href=""https://developer.android.com/about/versions/oreo/background#migration"" rel=""nofollow noreferrer"">https://developer.android.com/about/versions/oreo/background#migration</a></p>

<pre><code>if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.O) {
    context.startForegroundService(intent);
} else {
    context.startService(intent);
}
</code></pre>

<ol start=""4"">
<li>And don't forget permissions:</li>
</ol>

<pre><code>&lt;uses-permission android:name=""android.permission.FOREGROUND_SERVICE"" /&gt;
</code></pre>
","2836371","","2836371","","2020-02-14 11:05:25","2020-02-14 11:05:25","","","","3","","","","CC BY-SA 4.0"
"60305617","2","","60079472","2020-02-19 17:03:18","","6","","<p><strong>We Don't have anything to do.</strong></p>

<p>Once your app is not whitelisted it will be always killed once removed from recent-apps.</p>

<p>Because <a href=""https://issuetracker.google.com/issues/122098785"" rel=""noreferrer"">Original Equipment Manufacturer (OMEs) constantly violating Android compliance</a>.</p>

<p>So If your app is not whitelisted from the device Manufacture it won't fire any background work <a href=""https://issuetracker.google.com/issues/148171173"" rel=""noreferrer"">even alarms</a> - in case your app is removed from recent-apps.</p>

<p>You can find a list of devices with that behavior <a href=""https://dontkillmyapp.com/"" rel=""noreferrer"">here</a> ALSO you might find a side-solution, However, it won't work well.</p>
","11161537","","","","","2020-02-19 17:03:18","","","","3","","","","CC BY-SA 4.0"
"60323379","2","","60079472","2020-02-20 15:29:58","","8","","<p>Found a weird workaround (sample <a href=""https://issuetracker.google.com/issues/149556385#comment6"" rel=""nofollow noreferrer""><strong>here</strong></a>) that seems to work for all versions, including even Android R:</p>
<ol>
<li>Have the permission SAW permission declared in the manifest:</li>
</ol>
<pre><code>      &lt;uses-permission android:name=&quot;android.permission.SYSTEM_ALERT_WINDOW&quot; /&gt;
</code></pre>
<p>On Android R you will have to also have it granted. On before, doesn't seem like it's needed to be granted, just declared. Not sure why this changed on R, but I can say that SAW could be required as a possible solution to start things in the background, as written <a href=""https://developer.android.com/guide/components/activities/background-starts#exceptions"" rel=""nofollow noreferrer""><strong>here</strong></a> for Android 10.</p>
<p>EDIT: Here is a <a href=""https://riptutorial.com/android/example/24633/granting-system-alert-window-permission-on-android-6-0-and-above"" rel=""nofollow noreferrer""><strong>guide</strong></a> on how to request it.</p>
<ol start=""2"">
<li>Have a service that will detect when the tasks was removed, and when it does, open a fake Activity that all it does is to close itself:</li>
</ol>
<pre><code>class OnTaskRemovedDetectorService : Service() {
    override fun onBind(intent: Intent?) = null

    override fun onStartCommand(intent: Intent?, flags: Int, startId: Int) = START_STICKY

    override fun onTaskRemoved(rootIntent: Intent?) {
        super.onTaskRemoved(rootIntent)
        Log.e(&quot;AppLog&quot;, &quot;onTaskRemoved&quot;)
        applicationContext.startActivity(Intent(this, FakeActivity::class.java).addFlags(Intent.FLAG_ACTIVITY_NEW_TASK))
        stopSelf()
    }

}
</code></pre>
<p><strong>FakeActivity.kt</strong></p>
<pre><code>class FakeActivity : AppCompatActivity() {
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        Log.d(&quot;AppLog&quot;, &quot;FakeActivity&quot;)
        finish()
    }
}
</code></pre>
<p>You can also make this Activity almost invisible to the user using this theme:</p>
<pre class=""lang-xml prettyprint-override""><code>    &lt;style name=&quot;AppTheme.Translucent&quot; parent=&quot;@style/Theme.AppCompat.NoActionBar&quot;&gt;
        &lt;item name=&quot;android:windowBackground&quot;&gt;@android:color/transparent&lt;/item&gt;
        &lt;item name=&quot;android:colorBackgroundCacheHint&quot;&gt;@null&lt;/item&gt;
        &lt;item name=&quot;android:windowIsTranslucent&quot;&gt;true&lt;/item&gt;
    &lt;/style&gt;
</code></pre>
<p>Sadly, this is a weird workaround. I hope to find a nicer workaround to this.</p>
<p>The restriction talks about starting Activity, so my current idea is that maybe if I start a foreground service for a split of a second it will also help, and for this I won't even need SAW permission.</p>
<p>EDIT: OK I tried with a foreground service (sample <a href=""https://issuetracker.google.com/issues/149556385#comment7"" rel=""nofollow noreferrer""><strong>here</strong></a>), and it didn't work. No idea why an Activity is working but not a service. I even tried to re-schedule the alarm there and tried to let the service stay for a bit, even after re-schedule. Also tried a normal service but of course it closed right away, as the task was removed, and it didn't work at all (even if I created a thread to run in the background).</p>
<p>Another possible solution that I didn't try is to have a foreground service forever, or at least till the task is removed, but this is a bit weird and I don't see the apps I've mentioned using it.</p>
<p>EDIT: tried to have a foreground service running before removal of the app's task, and for a bit afterwards, and the alarm still worked. Also tried to have this service to be the one in charge of task-removed event, and to close itself right away when it occurs, and it still worked (sample <a href=""https://issuetracker.google.com/issues/149556385#comment8"" rel=""nofollow noreferrer""><strong>here</strong></a>). The advantage of this workaround is that you don't have to have the SAW permission at all. The disadvantage is that you have a service with a notification while the app is already visible to the user. I wonder if it's possible to hide the notification while the app is already in the foreground via the Activity.</p>
<hr />
<p>EDIT: Seems it's a bug on Android Studio (reported <a href=""https://issuetracker.google.com/issues/150080941#comment5"" rel=""nofollow noreferrer"">here</a>, including videos comparing versions).
When you launch the app from the problematic version I tried, it could cause the alarms to be cleared.</p>
<p>If you launch the app from the launcher, it works fine.</p>
<p>This is the current code to set the alarm:</p>
<pre><code>        val timeToTrigger = System.currentTimeMillis() + 10 * 1000
        val pendingShowList = PendingIntent.getActivity(this, 1, Intent(this, SomeActivity::class.java), PendingIntent.FLAG_UPDATE_CURRENT)
        val pendingIntent = PendingIntent.getBroadcast(this, 1, Intent(this, AlarmReceiver::class.java), PendingIntent.FLAG_UPDATE_CURRENT)
        manager.setAlarmClock(AlarmManager.AlarmClockInfo(timeToTrigger, pendingShowList), pendingIntent)
</code></pre>
<p>I don't even have to use &quot;pendingShowList&quot;. Using null is also ok.</p>
","878126","","10702002","","2021-10-19 08:44:45","2021-10-19 08:44:45","","","","11","","","","CC BY-SA 4.0"
"60355950","2","","60079472","2020-02-22 19:25:46","","0","","<p>I know this isn't efficient but might be more consistent with an accuracy of 60 seconds.</p>

<p><a href=""https://developer.android.com/reference/android/content/Intent#ACTION_TIME_TICK"" rel=""nofollow noreferrer"">https://developer.android.com/reference/android/content/Intent#ACTION_TIME_TICK</a></p>

<p>if this broadcast receiver is used inside a foreground service , you can check the time every minute and make decision on taking an action. </p>
","8565380","","","","","2020-02-22 19:25:46","","","","1","","","","CC BY-SA 4.0"
"61905780","2","","60114639","2020-05-20 05:32:59","","-3","","<p>I used to have the same problem with the chrome driver in version 81.0.4044.13800 used in a C# project in combination with selenium. Updates to a newer version of the driver did not work for me as well as further startup arguments.</p>

<p>But since this is a logging problem, here is the final solution which works for me as described <strong><a href=""https://groups.google.com/d/msg/selenium-users/JPthly3xsOI/2uEKzE8o2aYJ"" rel=""nofollow noreferrer"">here</a></strong>:</p>

<pre><code>ChromeOptions chromeOptions = new ChromeOptions();
chromeOptions.AddArguments(new List&lt;string&gt;() 
{ 
  ""no-sandbox"", 
  ""headless"", 
  ""disable-gpu"" 
});

ChromeDriverService service = ChromeDriverService.CreateDefaultService();
service.SuppressInitialDiagnosticInformation = true;

var driver = new ChromeDriver(service, chromeOptions);
</code></pre>
","9906898","","","","","2020-05-20 05:32:59","","","","1","","","","CC BY-SA 4.0"
"62747963","2","","62738704","2020-07-06 01:17:38","","4","","<h2>Leverage the Outer Scope of the Closures</h2>
<p>If I understand your question correctly, leveraging the outer scope of the closure may do what you want. This is admittedly a very contrived example that registers your nested Proc objects in an Array. The second Proc isn't created until the first one is called, but they both retain their bindings to the outer scope.</p>
<pre><code>@procs = []
@foo   = 1

@procs &lt;&lt; proc do
  # Don't keep re-registering the nested Proc on
  # subsequent invocations.
  @procs &lt;&lt; proc { @foo + 1 } unless @procs.count == 2
  @foo
end

@procs.map &amp;:call
#=&gt; [1, 2]

@foo = 3
@procs.map &amp;:call
#=&gt; [3, 4]
</code></pre>
","1301972","","","","","2020-07-06 01:17:38","","","","2","","","","CC BY-SA 4.0"
"62750205","2","","62738704","2020-07-06 06:12:15","","3","","<p>Ok, <em>now</em> I think I understand what you mean. As I mentioned in the comments, it can be done by nesting closures. Because Procs/lambdas are anonymous, the closure nesting provides a way for the lambda to receive a dynamic reference to itself, thereby allowing it to <code>instance_eval</code> code in the context of <code>self</code>.</p>
<pre class=""lang-rb prettyprint-override""><code>wrapped_dispatch = -&gt;(f) { f[f] }

proc_wrapped = lambda do |myself|
  lambda do |n|
    myself.instance_eval do
      # in context of self
      bar(n)
    end
  end
end

def proc_wrapped.bar(n)
  p &quot;bar #{n}&quot;
end

wrapped_dispatch[proc_wrapped].call(123)
# =&gt; &quot;bar 123&quot;

# can also save it &quot;unwrapped&quot;
prc = wrapped_dispatch[proc_wrapped]

prc.call(123)
# =&gt; &quot;bar 123&quot;

# Very late binding to dynamic receiver
def proc_wrapped.bar(n)
  p &quot;BAR #{n}&quot;
end
prc.call(123)
# =&gt; &quot;BAR 123&quot;

# and if the &quot;wrapped-ness&quot; bothers you, link them together and delegate
proc_wrapped.define_singleton_method(:call) do |n|
  prc.call(n)
end

def proc_wrapped.bar(n)
  p &quot;BBBBAAAARRRRR&quot;
end
proc_wrapped.call(123)
# =&gt; &quot;BBBBAAAARRRRR&quot;

other_proc_wrapped = proc_wrapped.clone
wrapped_dispatch[other_proc_wrapped].call(123)
# =&gt; &quot;BBBBAAAARRRRR&quot;

def other_proc_wrapped.bar(n)
  p &quot;foo #{n}&quot;
end

wrapped_dispatch[other_proc_wrapped].call(123)
# =&gt; &quot;foo 123&quot;
proc_wrapped.call(123)
# =&gt; &quot;BBBBAAAARRRRR&quot;
</code></pre>
<p>I'm noticing this behavior is very similar to a class's instances (<code>Foo.new</code>) vs a class's singleton class (<code>Foo.singleton_class</code>), which makes sense since <a href=""https://wiki.c2.com/?ClosuresAndObjectsAreEquivalent"" rel=""nofollow noreferrer"">closures and objects are equivalent</a>. This means if you really want behavior like this, you ought to just use a class, its singleton class, and its instances, as is idiomatic in Ruby.</p>
","234593","","234593","","2020-07-08 03:33:30","2020-07-08 03:33:30","","","","6","","","","CC BY-SA 4.0"
"62790616","2","","62738704","2020-07-08 08:29:20","","6","","<p>Disclaimer: I'm answering my own question</p>
<hr />
<p>The solution is surprisingly simple. Just override <code>call</code> to invoke the proc via <a href=""https://ruby-doc.org/core-2.7.1/BasicObject.html#instance_exec-method"" rel=""noreferrer""><code>instance_exec</code></a>:</p>
<blockquote>
<p>Executes the given block within the context of the receiver <em>(obj)</em>. In order to set the context, the variable <code>self</code> is set to <em>obj</em> while the code is executing, giving the code access to <em>obj</em>'s instance variables. Arguments are passed as block parameters.</p>
</blockquote>
<pre><code>prc = proc { |arg|
  @a ||= 0
  @a += 1
  p self: self, arg: arg, '@a': @a
}

def prc.call(*args)
  instance_exec(*args, &amp;self)
end
</code></pre>
<p>Here, the receiver is the proc itself and the &quot;given block&quot; is also the proc itself. <code>instance_exec</code> will therefore invoke the proc in the context of its own instance. And it will even pass any additional arguments!</p>
<p>Using the above:</p>
<pre><code>prc
#=&gt; #&lt;Proc:0x00007f84d29dcbb0&gt;

prc.call(:foo)
#=&gt; {:self=&gt;#&lt;Proc:0x00007f84d29dcbb0&gt;, :arg=&gt;:foo, :@a=&gt;1}
#           ^^^^^^^^^^^^^^^^^^^^^^^^^^        ^^^^
#                  correct object          passes args

prc.call(:bar)
#=&gt; {:self=&gt;#&lt;Proc:0x00007f84d29dcbb0&gt;, :arg=&gt;:bar, :@a=&gt;2}
#                                                   ^^^^^^
#                                               preserves ivars

prc.instance_variable_get(:@a)
#=&gt; 2 &lt;- actually stores ivars in the proc instance

other_prc = prc.clone
#=&gt; #&lt;Proc:0x00007f84d29dc598&gt;
#          ^^^^^^^^^^^^^^^^^^
#           different object

other_prc.call(:baz)
#=&gt; {:self=&gt;#&lt;Proc:0x00007f84d29dc598&gt;, :arg=&gt;:baz, :@a=&gt;3}
#                                                   ^^^^^^
#                                               ivars are cloned

other_prc.call(:qux)
#=&gt; {:self=&gt;#&lt;Proc:0x00007f84d29dc598&gt;, :arg=&gt;:qux, :@a=&gt;4}

prc.call(:quux)
#=&gt; {:self=&gt;#&lt;Proc:0x00007f84d29dcbb0&gt;, :arg=&gt;:quux, :@a=&gt;3}
#                                                    ^^^^^^
#                              both instances have separate ivars
</code></pre>
","477037","","477037","","2020-07-08 08:38:52","2020-07-08 08:38:52","","","","7","","","","CC BY-SA 4.0"
"67058237","2","","62969917","2021-04-12 12:18:55","","0","","<p>Update your Gradle version to 4.0.1 or later.</p>
<p>File <em>android/gradle/wrapper/gradle-wrapper.properties</em>: update the distribution URL to:</p>
<p>distributionUrl=https://services.gradle.org/distributions/gradle-6.7-all.zip</p>
<p>File <em>android/build.gradle</em>: update the <a href=""https://en.wikipedia.org/wiki/Gradle"" rel=""nofollow noreferrer"">Gradle</a> plugin:</p>
<p>classpath 'com.android.tools.build:gradle:4.1.2'</p>
<p>to 4.0.1 or later. Here it is 4.1.2 with Gradle version to 6.5 or later.</p>
<p>You can see the distribution chart at <em><a href=""https://stackoverflow.com/questions/17727645/how-to-update-gradle-in-android-studio/35272475#35272475"">How to update gradle in android studio?</a></em></p>
","10184868","","63550","","2022-08-19 15:39:21","2022-08-19 15:39:21","","","","0","","","","CC BY-SA 4.0"
"67158711","2","","62969917","2021-04-19 08:41:49","","1","","<p>Due to the new default settings and features for <strong>package visibility</strong> in <a href=""https://en.wikipedia.org/wiki/Android_11"" rel=""nofollow noreferrer"">Android 11</a> that need to add <code>&lt;queries&gt;</code>, you must update your Android <a href=""https://en.wikipedia.org/wiki/Gradle"" rel=""nofollow noreferrer"">Gradle</a> plugin.</p>
<p>Google has added some patches to current versions listed in <em><a href=""https://developer.android.com/studio/releases/gradle-plugin.html?buildsystem=cmake#4-0-0"" rel=""nofollow noreferrer"">Android Gradle plugin release notes, 4.0.0 (April 2020)</a></em>.</p>
<p>If you want to use a newer version of Android Gradle, you should search for a compatible wrapper from <em><a href=""https://developer.android.com/studio/releases/gradle-plugin.html?buildsystem=cmake#updating-gradle"" rel=""nofollow noreferrer"">Android Gradle plugin release notes, Update Gradle</a></em>.</p>
","4965949","","63550","","2022-08-19 15:42:46","2022-08-19 15:42:46","","","","0","","","","CC BY-SA 4.0"
"61590855","2","","61590721","2020-05-04 11:11:21","","30","","<p>This is still guaranteed by <a href=""https://timsong-cpp.github.io/cppwp/expr.rel#4.2"" rel=""noreferrer"">[expr.rel]/(4.2)</a>, describing the behavior of built-in <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, and <code>&gt;=</code> expressions on pointer values.</p>

<blockquote>
  <p>If two pointers point to different non-static data members of the same object, or to subobjects of such members, recursively, the pointer to the later declared member is required to compare greater provided the two members have the same access control ([class.access]), neither member is a subobject of zero size, and their class is not a union.</p>
</blockquote>
","459640","","","","","2020-05-04 11:11:21","","","","3","","","","CC BY-SA 4.0"
"64545863","2","","64545862","2020-10-26 22:30:28","","143","","<p>In version <a href=""https://firebase.google.com/support/release-notes/js#version_800_-_october_26_2020"" rel=""noreferrer"">8.0.0</a>, the Firebase SDK had a breaking change in the way it handles exports:</p>
<blockquote>
<p>Breaking change: <code>browser</code> fields in package.json files now point to ESM
bundles instead of CJS bundles. Users who are using ESM imports must
now use the default import instead of a namespace import.</p>
<p>Before 8.0.0</p>
<pre><code>import * as firebase from 'firebase/app'
</code></pre>
<p>After 8.0.0</p>
<pre><code>import firebase from 'firebase/app'
</code></pre>
<p>Code that uses <code>require('firebase/app')</code> or <code>require('firebase')</code> will
still work, but in order to get proper typings (for code completion,
for example) users should change these require calls to
<code>require('firebase/app').default</code> or <code>require('firebase').default</code>. This
is because the SDK now uses typings for the ESM bundle, and the
different bundles share one typings file.</p>
</blockquote>
<p>So, you will have to use the new ESM bundle default export:</p>
<pre class=""lang-js prettyprint-override""><code>import firebase from &quot;firebase/app&quot;
firebase.initializeApp({ ... })
</code></pre>
<p>If you are working with <a href=""https://firebase.google.com/support/release-notes/js#version_900_-_august_25_2021"" rel=""noreferrer"">SDK version 9.0</a>, read this question instead:</p>
<ul>
<li><a href=""https://stackoverflow.com/q/68946446/807126"">How do I fix a Firebase 9.0 import error? &quot;Attempted import error: &#39;firebase/app&#39; does not contain a default export (imported as &#39;firebase&#39;).&quot;</a></li>
</ul>
","807126","","807126","","2021-08-31 14:40:36","2021-08-31 14:40:36","","","","5","","","","CC BY-SA 4.0"
"60151304","2","","60150749","2020-02-10 13:18:07","","23","","<p>For clang and gcc you can compile with <code>-Werror=missing-field-initializers</code> that turns the warning on missing field initializers to an error. <a href=""https://godbolt.org/z/g_ZnLC"" rel=""noreferrer"">godbolt</a></p>

<p><strong>Edit:</strong> For MSVC, there seems to be no warning emitted even at level <code>/Wall</code>, so I don't think it is possible to warn on missing initializers with this compiler. <a href=""https://godbolt.org/z/E3fB99"" rel=""noreferrer"">godbolt</a></p>
","12345656","","12345656","","2020-02-10 13:31:07","2020-02-10 13:31:07","","","","0","","","","CC BY-SA 4.0"
"60151516","2","","60150749","2020-02-10 13:30:57","","4","","<p>For <a href=""https://learn.microsoft.com/en-us/visualstudio/code-quality/using-the-cpp-core-guidelines-checkers?view=vs-2019"" rel=""nofollow noreferrer"">CppCoreCheck</a> there's a rule for checking exactly that, if all members have been initialized and that can be turned from warning into an error - that is usually program-wide of course.</p>

<p>Update:</p>

<p>The rule you want to check is part of typesafety <code>Type.6</code>:</p>

<blockquote>
  <p>Type.6: Always initialize a member variable: always initialize,
  possibly using default constructors or default member initializers.</p>
</blockquote>
","2261538","","2261538","","2020-02-10 13:36:10","2020-02-10 13:36:10","","","","0","","","","CC BY-SA 4.0"
"60152521","2","","60150749","2020-02-10 14:30:00","","6","","<p>Not an elegant and handy solution, I suppose... but should works also with C++11 and give a compile-time (not link-time) error.</p>

<p>The idea is to add in your struct an additional member, in the last position, of a type without default initialization (and that cannot initialize with a value of type <code>VariablePtr</code> (or whatever is the type of preceding values)</p>

<p>By example</p>

<pre><code>struct bar
 {
   bar () = delete;

   template &lt;typename T&gt; 
   bar (T const &amp;) = delete;

   bar (int) 
    { }
 };

struct foo
 {
   char a;
   char b;
   char c;

   bar sentinel;
 };
</code></pre>

<p>This way you're forced to add all elements in your aggregate initialization list, included the value to explicit initialize the last value (an integer for <code>sentinel</code>, in the example) or you get a ""call to deleted constructor of 'bar'"" error.</p>

<p>So  </p>

<pre><code>foo f1 {'a', 'b', 'c', 1};
</code></pre>

<p>compile and</p>

<pre><code>foo f2 {'a', 'b'};  // ERROR
</code></pre>

<p>doesn't.</p>

<p>Unfortunately also</p>

<pre><code>foo f3 {'a', 'b', 'c'};  // ERROR
</code></pre>

<p>doesn't compile.</p>

<p><strong>-- EDIT --</strong> </p>

<p>As pointed by MSalters (thanks) there is a defect (another defect) in my original example: a <code>bar</code> value could be initialized with a <code>char</code> value (that is convertible to <code>int</code>), so works the following initialization</p>

<pre><code>foo f4 {'a', 'b', 'c', 'd'};
</code></pre>

<p>and this can be highly confusing.</p>

<p>To avoid this problem, I've added the following deleted template constructor</p>

<pre><code> template &lt;typename T&gt; 
 bar (T const &amp;) = delete;
</code></pre>

<p>so the preceding <code>f4</code> declaration gives a compilation error because the <code>d</code> value is intercepted by the template constructor that is deleted </p>
","6022656","","12998751","","2020-03-09 16:12:21","2020-03-09 16:12:21","","","","13","","","","CC BY-SA 4.0"
"60154504","2","","60150749","2020-02-10 16:28:31","","2","","<p>The simplest way is not to give the type of the members a no-arg constructor:</p>

<pre><code>struct B
{
    B(int x) {}
};
struct A
{
    B a;
    B b;
    B c;
};

int main() {

        // A a1{ 1, 2 }; // will not compile 
        A a1{ 1, 2, 3 }; // will compile 
</code></pre>

<p>Another option: If your members are const &amp; , you have to initialize all of them:</p>

<pre><code>struct A {    const int&amp; x;    const int&amp; y;    const int&amp; z; };

int main() {

//A a1{ 1,2 };  // will not compile 
A a2{ 1,2, 3 }; // compiles OK
</code></pre>

<p>If you can live with one dummy const &amp; member, you can combine that with @max66's idea of a sentinel.</p>

<pre><code>struct end_of_init_list {};

struct A {
    int x;
    int y;
    int z;
    const end_of_init_list&amp; dummy;
};

    int main() {

    //A a1{ 1,2 };  // will not compile
    //A a2{ 1,2, 3 }; // will not compile
    A a3{ 1,2, 3,end_of_init_list() }; // will compile
</code></pre>

<p>From cppreference <a href=""https://en.cppreference.com/w/cpp/language/aggregate_initialization"" rel=""nofollow noreferrer"">https://en.cppreference.com/w/cpp/language/aggregate_initialization</a></p>

<blockquote>
  <p>If the number of initializer clauses is less than the number of
  members or initializer list is completely empty, the remaining members
  are value-initialized. If a member of a reference type is one of these
  remaining members, the program is ill-formed.</p>
</blockquote>

<p>Another option is to take max66's sentinel idea and add some syntactic sugar for readability </p>

<pre><code>struct init_list_guard
{
    struct ender {

    } static const end;
    init_list_guard() = delete;

    init_list_guard(ender e){ }
};

struct A
{
    char a;
    char b;
    char c;

    init_list_guard guard;
};

int main() {
   // A a1{ 1, 2 }; // will not compile 
   // A a2{ 1, init_list_guard::end }; // will not compile 
   A a3{ 1,2,3,init_list_guard::end }; // compiles OK
</code></pre>
","889742","","889742","","2020-02-13 08:44:09","2020-02-13 08:44:09","","","","4","","","","CC BY-SA 4.0"
"61958215","2","","60114639","2020-05-22 15:16:05","","0","","<p>Use this line of code keep the code first statement </p>

<pre><code>System.setProperty(ChromeDriverService.CHROME_DRIVER_SILENT_OUTPUT_PROPERTY, ""true"");
</code></pre>

<p>If you don't go for Leanthy</p>

<pre><code>System.setProperty(""webdriver.chrome.silentOutput"", ""true"");
</code></pre>
","12883411","","10608621","","2020-05-22 16:48:46","2020-05-22 16:48:46","","","","0","","","","CC BY-SA 4.0"
"59869487","2","","59869486","2020-01-22 23:04:58","","10","","<h1>tl;dr</h1>
<p><strong>Just cast</strong>, no need to convert.</p>
<p>Cast <code>Stream&lt;String&gt;::iterator</code> to <code>Iterable&lt;String&gt;</code>.</p>
<h1>Details</h1>
<p><strong>CAUTION</strong> See Answer by Holger explaining dangers of using a stream-backed <code>Iterable</code>.</p>
<p>Yes, you can make an <a href=""https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/Iterable.html"" rel=""noreferrer""><code>Iterable</code></a> from a <a href=""https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/stream/Stream.html"" rel=""noreferrer""><code>Stream</code></a>.</p>
<p>The solution is simple, but not obvious. See <a href=""http://www.lambdafaq.org/how-do-i-turn-a-stream-into-an-iterable/"" rel=""noreferrer"">this post</a> on <a href=""http://www.lambdafaq.org/"" rel=""noreferrer""><em>Maurice Naftalin's Lambda FAQ</em></a>.</p>
<p>The signature of the <a href=""https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/stream/BaseStream.html#iterator()"" rel=""noreferrer""><code>iterator</code></a> method of <a href=""https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/stream/BaseStream.html"" rel=""noreferrer""><code>BaseStream</code></a> (superclass of <a href=""https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/stream/Stream.html"" rel=""noreferrer""><code>Stream</code></a>) returning a <a href=""https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Iterator.html"" rel=""noreferrer""><code>Iterator</code></a> matches the only method of the functional interface <a href=""https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/Iterable.html"" rel=""noreferrer""><code>Iterable</code></a>, so the method reference <code>Stream&lt;T&gt;::iterator</code> can be used as an instance of <code>Iterable&lt;T&gt;</code>. (The fact that both methods have the same name is coincidental.)</p>
<p>Make your input.</p>
<pre><code>String input = &quot;this\n&quot; +
        &quot;that\n&quot; +
        &quot;the_other&quot;;
Stream&lt;String&gt; stream = input.lines() ;
</code></pre>
<p>Use the method reference to generate a <code>Iterable&lt;String&gt;</code>.</p>
<pre><code>Iterable&lt; String &gt; iterable = stream::iterator;
</code></pre>
<p>Test the results.</p>
<pre><code>for ( String s : iterable ) 
{
    System.out.println( &quot;s = &quot; + s );
}
</code></pre>
<p>See this <a href=""https://ideone.com/66zqAD"" rel=""noreferrer"">code run live at IdeOne.com</a>.</p>
<blockquote>
<p>s = this</p>
</blockquote>
<blockquote>
<p>s = that</p>
</blockquote>
<blockquote>
<p>s = the_other</p>
</blockquote>
<p><strong>CAVEAT</strong> Beware of the risk of stream-backed <code>Iterable</code>. Explained in the correct <a href=""https://stackoverflow.com/a/59873914/642706"">Answer by Holger</a>.</p>
","642706","","2684196","","2021-06-15 15:01:56","2021-06-15 15:01:56","","","","9","","","","CC BY-SA 4.0"
"59873914","2","","59869486","2020-01-23 08:04:07","","38","","<p>As explained in <a href=""https://stackoverflow.com/q/20129762/2711488"">Why does Stream&lt;T&gt; not implement Iterable&lt;T&gt;?</a>, an <code>Iterable</code> bears the expectation to be able to provide an <code>Iterator</code> more than once, which a <code>Stream</code> can’t fulfill. So while you can create an <code>Iterable</code> out of a <code>Stream</code> for an ad-hoc use, you have to be careful about whether attempts to iterate it multiple times could exist.</p>

<p>Since you said, “<em>I need to pass those parts of string as an <code>Iterable</code> to a specific library</em>”, there is no general solution as the code using the <code>Iterable</code> is outside your control.</p>

<p>But if you are the one who creates the stream, it is possible to create a valid <code>Iterable</code> which will simply repeat the stream construction every time an <code>Iterator</code> is requested:</p>

<pre><code>Iterable&lt;String&gt; lines = () -&gt; ""this\nthat\nthe_other"".lines().iterator();
</code></pre>

<p>This fulfills the expectation of supporting an arbitrary number of iterations, while not consuming more resources than a single stream when being traversed only once.</p>

<pre><code>for(var s: lines) System.out.println(s);
lines.forEach(System.out::println);
System.out.println(String.join(""\n"", lines));
</code></pre>
","2711488","","2711488","","2020-01-23 09:07:03","2020-01-23 09:07:03","","","","7","","","","CC BY-SA 4.0"
"62856104","2","","62738704","2020-07-12 01:05:55","","5","","<p>A general approach that is typically used in DSLs is referred to as the Clean Room pattern - an object you build for the purpose of evaluating blocks of DSL code. It is used to restrict the DSL from accessing undesired methods, as well as to define the underlying data the DSL works on.</p>
<p>The approach looks something like this:</p>
<pre class=""lang-rb prettyprint-override""><code># Using struct for simplicity.
# The clean room can be a full-blown class. 
first_clean_room = Struct.new(:foo).new(123)
second_clean_room = Struct.new(:foo).new(321)

prc = Proc.new do
  foo
end

first_clean_room.instance_exec(&amp;prc)
# =&gt; 123

second_clean_room.instance_exec(&amp;prc)
# =&gt; 321
</code></pre>
<p>It appears that what you are looking for is to have the Proc object itself serve as both the block and the clean room. This is a bit unusual, since the block of code is what you typically want to have reused on different underlying data. I suggest you consider first whether the original pattern might be a better fit for your application.</p>
<p>Nevertheless, having the Proc object serve as the clean room can indeed be done, and the code looks very similar to the pattern above (the code also looks similar to the approach you posted in your answer):</p>
<pre class=""lang-rb prettyprint-override""><code>prc = Proc.new do 
  foo
end

other = prc.clone

# Define the attributes in each clean room

def prc.foo
  123
end

def other.foo
  321
end

prc.instance_exec(&amp;prc)
# =&gt; 123

other.instance_exec(&amp;other)
# =&gt; 321
</code></pre>
<p>You could also consider making the approach more convenient to run by creating a new class that inherits from Proc instead of overriding the native <code>call</code> method. It's not wrong per-se to override it, but you might need the flexibility to attach it to a different receiver, so this approach lets you have both:</p>
<pre class=""lang-rb prettyprint-override""><code>class CleanRoomProc &lt; Proc
  def run(*args)
    instance_exec(*args, &amp;self)
  end
end

code = CleanRoomProc.new do 
  foo
end

prc = code.clone
other = code.clone

def prc.foo
  123
end

def other.foo
  321
end

prc.run
# =&gt; 123

other.run
# =&gt; 321
</code></pre>
<p>And if you cannot use a new class for some reason, e.g. you are getting a Proc object from a gem, you could consider extending the Proc object using a module:</p>
<pre class=""lang-rb prettyprint-override""><code>module SelfCleanRoom
  def run(*args)
    instance_exec(*args, &amp;self)
  end
end

code = Proc.new do 
  foo
end

code.extend(SelfCleanRoom)

prc = code.clone
other = code.clone

# ...
</code></pre>
","455826","","455826","","2020-07-12 01:41:26","2020-07-12 01:41:26","","","","1","","","","CC BY-SA 4.0"
"63091539","2","","63075418","2020-07-25 17:42:30","","20","","<p><strong>Edit</strong> I have now published a series of articles on this topic, starting with <a href=""https://www.biteinteractive.com/cell-content-configuration-in-ios-14/"" rel=""noreferrer"">https://www.biteinteractive.com/cell-content-configuration-in-ios-14/</a>.</p>
<hr />
<p>The key here — and I don't think that Apple has made this clear at all in the videos — is that the way these cell configurations work is by literally ripping out the cell's <code>contentView</code> and replacing it with the view supplied by the configuration as the output of its <code>makeContentView</code>.</p>
<p>So all you have to do is build the entire content view by hand, and the runtime will put it in the cell for you.</p>
<p>Here's an example. We need to supply our own configuration type that adopts UIContentConfiguration, so that we can define our own properties; it must also implement <code>makeContentView()</code> and <code>updated(for:)</code>. So pretend we have four texts to display in the cell:</p>
<pre><code>struct Configuration : UIContentConfiguration {
    let text1: String
    let text2: String
    let text3: String
    let text4: String
    func makeContentView() -&gt; UIView &amp; UIContentView {
        let c = MyContentView(configuration: self)
        return c
    }
    func updated(for state: UIConfigurationState) -&gt; MyCell.Configuration {
        return self
    }
}
</code></pre>
<p>In real life, we might respond to a change in state by changing returning a version of this configuration with some property changed, but in this case there is nothing to do, so we just return <code>self</code>.</p>
<p>We have posited the existence of MyContentView, a UIView subclass that adopts UIContentView, meaning that it has a <code>configuration</code> property. This is where we configure the view's subviews and apply the configuration. In this case, applying the configuration means simply setting the text of four labels. I'll separate those two tasks:</p>
<pre><code>class MyContentView: UIView, UIContentView {
    var configuration: UIContentConfiguration {
        didSet {
            self.configure()
        }
    }
    private let lab1 = UILabel()
    private let lab2 = UILabel()
    private let lab3 = UILabel()
    private let lab4 = UILabel()
    init(configuration: UIContentConfiguration) {
        self.configuration = configuration
        super.init(frame: .zero)
        // ... configure the subviews ...
        // ... and add them as subviews to self ...
        self.configure()
    }
    required init?(coder: NSCoder) {
        fatalError(&quot;init(coder:) has not been implemented&quot;)
    }
    private func configure() {
        guard let config = self.configuration as? Configuration else { return }
        self.lab1.text = config.text1
        self.lab2.text = config.text2
        self.lab3.text = config.text3
        self.lab4.text = config.text4
    }
}
</code></pre>
<p>You can see the point of that architecture. If at some point in the future we are assigned a new <code>configuration</code>, we simply call <code>configure</code> to set the texts of the labels again, with no need to reconstruct the subviews themselves. In real life, we can gain some further efficiency by examining the incoming configuration; if it is identical to the current configuration, there's no need to call <code>self.configure()</code> again.</p>
<p>The upshot is that we can now talk like this in our <code>tableView(_:cellForRowAt:)</code> implementation:</p>
<pre><code>override func tableView(_ tableView: UITableView, 
    cellForRowAt indexPath: IndexPath) -&gt; UITableViewCell {
        let cell = tableView.dequeueReusableCell(
            withIdentifier: self.cellID, for: indexPath) as! MyCell
        let config = MyCell.Configuration(
            text1: &quot;Harpo&quot;,
            text2: &quot;Groucho&quot;,
            text3: &quot;Chico&quot;,
            text4: &quot;Zeppo&quot;
        )
        cell.contentConfiguration = config
        return cell
}
</code></pre>
<p>All of that is very clever, but unfortunately it seems that the content view interface must be created in code — we can't load the cell ready-made from a nib, because the content view loaded from the nib, along with all its subviews, will be replaced by the content view returned from our <code>makeContentView</code> implementation. So Apple's configuration architecture can't be used with a cell that you've designed in the storyboard or a <em>.xib</em> file. That's a pity but I don't see any way around it.</p>
","341994","","341994","","2021-03-29 19:39:53","2021-03-29 19:39:53","","","","5","","","","CC BY-SA 4.0"
"63584516","2","","63075418","2020-08-25 17:50:57","","1","","<p><a href=""https://github.com/nostradupus/eu-capital-cities"" rel=""nofollow noreferrer"">Project on GitHub</a></p>
<p>From Xcode 12, iOS 14
Table View Cell Configuration:</p>
<pre><code>struct CityCellConfiguration: UIContentConfiguration, Hashable {
var image: UIImage? = nil
var cityName: String? = nil
var fafourited: Bool? = false

func makeContentView() -&gt; UIView &amp; UIContentView {
    return CustomContentView(configuration: self)
}

func updated(for state: UIConfigurationState) -&gt; Self {
    guard let state = state as? UICellConfigurationState else { return self }
    let updatedConfig = self

    return updatedConfig
}}
</code></pre>
<p>Apply configuration:</p>
<pre><code>private func apply(configuration: CityCellConfiguration) {
    guard appliedConfiguration != configuration else { return }
    appliedConfiguration = configuration
    
    imageView.isHidden = configuration.image == nil
    imageView.image = configuration.image
    textLabel.isHidden = configuration.cityName == nil
    textLabel.text = configuration.cityName
    favouriteButton.isFavourited = configuration.fafourited ?? false
}
</code></pre>
<p>Update configuration inside cell:</p>
<pre><code>override func updateConfiguration(using state: UICellConfigurationState) {
    var content = CityCellConfiguration().updated(for: state)
    content.image = &quot;🏢&quot;.image()
    if let item = state.item {
        content.cityName = item.name
        if let data = item.imageData {
            content.image = UIImage(data: data)
        }
    }
    contentConfiguration = content
}
</code></pre>
<p>Implement Table View Data Source:</p>
<pre><code>extension ViewController: UITableViewDataSource {
func tableView(_ tableView: UITableView, numberOfRowsInSection section: Int) -&gt; Int {
    return cities.count
}

func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -&gt; UITableViewCell {
    guard let cell = (tableView.dequeueReusableCell(withIdentifier: Configuration.cellReuseIdentifier) ?? CityTableViewCell(style: .value1, reuseIdentifier: Configuration.cellReuseIdentifier)) as? CityTableViewCell else {
        return UITableViewCell(style: .value1, reuseIdentifier: Configuration.cellReuseIdentifier)
    }
    
    let city = cities[indexPath.row]
    cell.updateWithItem(city)

    return cell
}}
</code></pre>
","5449670","","","","","2020-08-25 17:50:57","","","","0","","","","CC BY-SA 4.0"
"62413077","2","","61122378","2020-06-16 16:18:57","","-4","","<p>Using the keyboard shortcut can activate the new Siri voice (noraSiri)</p>
","13441976","","","","","2020-06-16 16:18:57","","","","1","","","","CC BY-SA 4.0"
"62680596","2","","61122378","2020-07-01 15:48:51","","10","","<p>In a WWDC20 talk, Apple says Siri voices are not available in AVSpeechSynthesizer.</p>
<p>The talk is called &quot;<a href=""https://developer.apple.com/videos/play/wwdc2020/10022/"" rel=""noreferrer"">Create a seamless speech experience in your apps</a>.&quot; Apparently this applies to Catalina as well.</p>
<p>Here's the relevant slide:</p>
<p><img src=""https://i.stack.imgur.com/GzRY4.jpg"" alt=""WWDC20 Slide"" /></p>
<p>I started a <a href=""https://forums.macrumors.com/threads/wrong-system-voice-speak-text-and-alerts-catalina.2237933/?post=28619208"" rel=""noreferrer"">thread at macrumors</a> regarding similar problems configuring the system voice to speak text.</p>
","5618246","","45375","","2020-07-01 15:57:35","2020-07-01 15:57:35","","","","2","","","","CC BY-SA 4.0"
"64093453","2","","64081701","2020-09-27 21:22:16","","7","","<p>Based on your new example code, I agree, it looks like a bug.  When you add a <code>reloadItems</code> to a snapshot it correctly triggers the datasource closure to request an updated cell, but the <code>IdentifierType</code> item that is passed to the closure is the original, not the new value that was provided with the <code>reloadItems</code> call.</p>
<p>If I changed your <code>UniBool</code> struct to a class so that it is a reference rather than a value type, then things worked as expected (since there is now a single instance of a <code>UniBool</code> rather than a new one with the same identifier).</p>
<p>It seems at the moment there are a couple of possible work-arounds:</p>
<ol>
<li>Use a reference rather than a value type for the <code>IdentifierType</code></li>
<li>Use an additional backing store, such as an array, and access it via <code>indexPath</code> in the datasource closure.</li>
</ol>
<p>I don't think that either of these are ideal.</p>
<p>Interestingly, after I changed <code>UniBool</code> to a class, I tried creating a new instance of <code>UniBool</code> that had the same <code>uuid</code> as the existing instance and reloading that; The code crashed with an exception stating <em>Invalid item identifier specified for reload</em>; This doesn't sound right to me; Only the <code>hashValue</code> should matter, not the actual object reference.  Both the original and the new objects had the same <code>hashValue</code> and <code>==</code> returned <code>true</code>.</p>
<hr />
<h2>Original answer</h2>
<p><code>reloadItems</code> works, but there are two important points:</p>
<ol>
<li><p>You must start with the datasource's current <code>snapshot</code> and call <code>reloadItems</code> on that. You can't create a new snapshot.</p>
</li>
<li><p>You can't rely on the <code>item</code> passed to the <code>CellProvider</code> closure <em>for anything other than the <code>identifier</code></em> - It doesn't represent the most recent data from your backing model (array).</p>
</li>
</ol>
<p>Point 2 means that you need to use the provided <code>indexPath</code> or <code>item.id</code> to obtain your updated object from your model.</p>
<p>I created a simple <a href=""https://gist.github.com/paulw11/9b89cc36ed33060497a66e42c7390e3b"" rel=""noreferrer"">example</a> that displays the current time in a table row; This is the data source struct:</p>
<pre><code>struct RowData: Hashable {
    var id: UUID = UUID()
    var name: String
    private let possibleColors: [UIColor] = [.yellow,.orange,.cyan]
    var timeStamp = Date()
    
    func hash(into hasher: inout Hasher) {
        hasher.combine(self.id)
    }
    
    static func ==(lhs: RowData, rhs: RowData) -&gt; Bool {
        return lhs.id == rhs.id
    }
}
</code></pre>
<p>Note that despite the <code>hash</code> function only using the <code>id</code> property it is also necessary to override <code>==</code> or you will get a crash with an invalid identifier when you attempt to reload the row.</p>
<p>Each second a random selection of rows are reloaded.  When you run the code you see that the time is updated on those randomly selected rows.</p>
<p>This is the code that uses <code>reloadItems</code>:</p>
<pre><code>self.timer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { (timer) in
    guard let datasource = self.tableview.dataSource as? UITableViewDiffableDataSource&lt;Section,RowData&gt; else {
        return
    }
    var snapshot = datasource.snapshot()
    var rowIdentifers = Set&lt;RowData&gt;()
    for _ in 0...Int.random(in: 1...self.arrItems.count) {
        let randomIndex = Int.random(in: 0...self.arrItems.count-1)
        self.arrItems[randomIndex].timeStamp = Date()
        rowIdentifers.insert(self.arrItems[randomIndex])
    }

    snapshot.reloadItems(Array(rowIdentifers))
    datasource.apply(snapshot)
}
</code></pre>
","3418066","","3418066","","2020-09-30 21:12:19","2020-09-30 21:12:19","","","","10","","","","CC BY-SA 4.0"
"64780900","2","","64545862","2020-11-11 05:21:10","","4","","<p>If you are using auth you need to import seperately as:
import 'firebase/auth';
As you are not importing everything like '* as firebase'.</p>
","12485176","","","","","2020-11-11 05:21:10","","","","0","","","","CC BY-SA 4.0"
"65750427","2","","64545862","2021-01-16 13:52:53","","13","","<p>old way to import firebase :  import * as firebase from &quot;firebase/app&quot;;</p>
<p>New way to import in 8.0.0 version : import firebase from &quot;firebase/app&quot;</p>
<p>eg: the way i did it. Only the first 2 lines are relevant, the other lines are only added as apart of my code but its quite general tbh!</p>
<pre><code>import firebase from &quot;firebase/app&quot;
import &quot;firebase/auth&quot;

const firebaseConfig = {
  apiKey: XXXX,
  authDomain: XXX,
  projectId: XXXX,
  storageBucket: XXXX,
  messagingSenderId: XXXX,
  appId: XXXX,
}


if (!firebase.apps.length) {
  firebase.initializeApp(firebaseConfig)
}


export const auth = firebase.auth() 
export const googleAuthProvider = new firebase.auth.GoogleAuthProvider()
</code></pre>
<p>replace XXXX by ur data, just being clear :)</p>
","11355290","","","","","2021-01-16 13:52:53","","","","0","","","","CC BY-SA 4.0"
"66708573","2","","64545862","2021-03-19 12:52:50","","3","","<p>Its an update issue, while you can fix how you import firebase, you can't fix how it's imported imported in libraries you use, you'll have wait for those library to be updated</p>
<p>Before 8.0.0
import * as firebase from 'firebase/app'</p>
<p>After 8.0.0
import firebase from 'firebase/app'</p>
<p>Library's like FirebaseUI authentication have not been updated, and I've been waiting for FirebaseUI update since april</p>
<p><a href=""https://stackoverflow.com/a/66708552/12490386"">https://stackoverflow.com/a/66708552/12490386</a></p>
","12490386","","12490386","","2021-04-17 12:36:17","2021-04-17 12:36:17","","","","0","","","","CC BY-SA 4.0"
"67383641","2","","62969917","2021-05-04 11:11:24","","78","","<p>I also suddenly had the same issue two days ago in Android Studio 4.1.1. I solved the issue by upgrading the build Gradle version.</p>
<p>Previous setting in the <em>build.gradle</em> file of the project was:</p>
<pre><code>classpath(&quot;com.android.tools.build:gradle:3.5.3&quot;)
</code></pre>
<p>Current setting:</p>
<pre><code>classpath(&quot;com.android.tools.build:gradle:3.5.4&quot;)
</code></pre>
<p>The issue was gone immediately. :)</p>
","4377672","","63550","","2022-08-19 15:59:43","2022-08-19 15:59:43","","","","5","","","","CC BY-SA 4.0"
"69378338","2","","62969917","2021-09-29 14:27:01","","15","","<p>I had this error in the <code>react-native-image-crop-picker</code> library, and I solved this problem by updating the Gradle version as mentioned in previous answers.</p>
<p>It was:</p>
<pre class=""lang-java prettyprint-override""><code>classpath(&quot;com.android.tools.build:gradle:3.5.3&quot;)
</code></pre>
<p>Updated to:</p>
<pre class=""lang-java prettyprint-override""><code>classpath(&quot;com.android.tools.build:gradle:3.5.4&quot;)
</code></pre>
<p>And I ran a:</p>
<pre class=""lang-none prettyprint-override""><code>cd android &amp;&amp; ./gradlew clean &amp;&amp; cd .. &amp;&amp; npx react-native run-android
</code></pre>
<p>Then it worked OK.</p>
","15228036","","63550","","2022-08-19 15:57:56","2022-08-19 15:57:56","","","","0","","","","CC BY-SA 4.0"
"61536204","2","","61536203","2020-05-01 03:05:29","","31","","<h1>TL;DR</h1>

<p>I tested these cases:</p>

<ol>
<li><p>Increment a value with a <code>transaction</code> call:</p>

<pre><code>ref.transaction(function(value) {
  return (value || 0) + 1;
});
</code></pre></li>
<li><p>Increment a value with the new <code>increment</code> operator:</p>

<pre><code>ref.set(admin.database.ServerValue.increment(1));
</code></pre></li>
</ol>

<p>The fact that increment is faster won't be a surprise, but... by how much?</p>

<p>Results:</p>

<ul>
<li>With transactions I was able to increment a value about 60-70 times per second. </li>
<li>With the <code>increment</code> operator, I was able to increment a value about 200-300 times per second.</li>
</ul>

<hr>

<h3>How I performed the test and got these numbers</h3>

<p>I've run the test on my 2016 model macBook pro, and wrapping the above in a simple Node.js script that uses the <a href=""https://firebase.google.com/docs/reference/node/firebase"" rel=""noreferrer"">client-side Node SDK</a>. The wrapping script for the operations was really basic as well:</p>

<pre><code>timer = setInterval(function() {
    ... the increment or transaction from above ...
}, 100);

setTimeout(function() {
  clearInterval(timer);
  process.exit(1);
}, 60000)
</code></pre>

<p>So: increment the value 10 times per second, and stop doing that after 1 minute. I then spawned instances of this process with this script:</p>

<pre><code>for instance in {1..10}
do
  node increment.js &amp;
done
</code></pre>

<p>So this would run 10 parallel processes with the <code>increment</code> operator, each increasing the value 10 times per second, for a total of 100 increments per second. I then changed the number of instances until the ""increments per second"" reached a peak.</p>

<p>I then wrote a small <a href=""https://jsbin.com/xurofiq/edit?html,js,output"" rel=""noreferrer"">script on jsbin</a> to listen for the value, and determine the number of increments per second by a simple low pass, moving average filter. I had some trouble here, so am not sure if the calculations are completely correct. Given my test results they were close close enough, but if anyone feels like writing a better observer: be my guest. :)</p>

<p>Things to note about the tests:</p>

<ol>
<li><p>I kept increasing the number of processes, until the ""increments per second"" seemed to max out, but I noticed that this coincided with my laptop fans going full-speed. So it's likely that I didn't find the true maximum throughput of the server-side operation, but a combination of my test environment and the server. So it is quite possible (and in fact likely) you may get different results when you try to reproduce this test, although of course the <code>increment</code> throughput should always be significantly higher than the <code>transaction</code>. No matter what results you get: please share them. :)</p></li>
<li><p>I've used the client-side Node.js SDK, as it was easiest to get working. Using different SDKs may give slightly different results, although I expect the primary SDKs (iOS, Android, and Web) to be quite close to what I got.</p></li>
<li><p>Two different team mates immediately asked whether I'd run this on a single node, or if I was incrementing multiple values in parallel. Incrementing multiple values in parallel might show if there's a system-wide throughput bottleneck in or if it is node-specific (which I expect).</p></li>
<li><p>As said already: my test harness is nothing special, but my jsbin observer code is especially suspect. Kudos if anyone feels like coding up a better observer on the same data.</p></li>
</ol>

<hr>

<h2>How the transaction and increment operator work under the hood</h2>

<p>To understand the performance difference between <code>transaction</code> and <code>increment</code> it really helps to know how these operations work under the hood. For the Firebase Realtime Database ""under the hood"" means, the commands and responses that are sent between the clients and server over the Web Socket connection.</p>

<p><strong>Transactions</strong> in Firebase use a compare-and-set approach. Whenever we start transaction like above, the client takes a guess at the current value of the node. If it's never see the node before that guess is <code>null</code>. It calls our transaction handler with that guess, and our code then returns the new value. The client send the guess and the new value to the server, which performs a compare-and-set operation: if the guess is correct, set the new value. If the guess is wrong, the server rejects the operation and returns the actual current value to the client.</p>

<p>In a perfect scenario, the initial guess is correct, and the value is immediately written to disk on the server (and after that, sent out to all listeners). In a flow chart that'd look like this:</p>

<pre><code>            Client            Server

               +                   +
 transaction() |                   |
               |                   |
        null   |                   |
     +---&lt;-----+                   |
     |         |                   |
     +---&gt;-----+                   |
         1     |     (null, 1)     |
               +---------&gt;---------+
               |                   |
               +---------&lt;---------+
               |     (ack, 3)      |
               |                   |
               v                   v
</code></pre>

<p>But if the node already has a value on the server, it rejects the write, sends back the actual value, and the client tries again:</p>

<pre><code>            Client            Server

               +                   +
 transaction() |                   |
               |                   |
        null   |                   |
     +---&lt;-----+                   |
     |         |                   |
     +---&gt;-----+                   |
         1     |                   |
               |     (null, 1)     |
               +---------&gt;---------+
               |                   |
               +---------&lt;---------+
               |     (nack, 2)     |
               |                   |
         2     |                   |
     +---&lt;-----+                   |
     |         |                   |
     +---&gt;-----+                   |
         3     |      (2, 3)       |
               +---------&gt;---------+
               |                   |
               +---------&lt;---------+
               |      (ack, 3)     |
               |                   |
               |                   |
               v                   v
</code></pre>

<p>This isn't too bad, one extra roundtrip. Even if Firebase would've used pessimistic locking, it  would have needed that roundtrip, so we didn't lose anything.</p>

<p>The problem starts if multiple clients are modifying the same value concurrently. This introduces so-called contention on the node, which looks like this:</p>

<pre><code>            Client            Server                Client
               +                   +                   +
 transaction() |                   |                   |
               |                   |                   | transaction()
        null   |                   |                   |
     +---&lt;-----+                   |                   |  null
     |         |                   |                   +---&gt;----+
     +---&gt;-----+                   |                   |        |
         1     |                   |                   +---&lt;----+ 
               |     (null, 1)     |                   |   1
               +---------&gt;---------+    (null, 1)      |
               |                   |---------&lt;---------+
               +---------&lt;---------+                   |
               |     (nack, 2)     |---------&gt;---------+
               |                   |     (nack, 2)     |
         2     |                   |                   |
     +---&lt;-----+                   |                   |   2
     |         |                   |                   |---&gt;----+
     +---&gt;-----+                   |                   |        |
         3     |      (2, 3)       |                   |---&lt;----+ 
               +---------&gt;---------+                   |   3
               |                   |                   |
               +---------&lt;---------+                   |
               |      (ack, 3)     |       (2, 3)      |
               |                   |---------&lt;---------+
               |                   |                   |
               |                   |---------&gt;---------+
               |                   |    (nack, 3)      |
               |                   |                   |   3
               |                   |                   |---&gt;----+
               |                   |                   |        |
               |                   |                   |---&lt;----+ 
               |                   |                   |   4
               |                   |       (3, 4)      |
               |                   |---------&lt;---------+
               |                   |                   |
               |                   |---------&gt;---------+
               |                   |     (ack, 4)      |
               |                   |                   |
               v                   v                   v
</code></pre>

<p><em>TODO: Update the above chart so that the operations on the server don't overlap.</em></p>

<p>The second client had to do another retry for its operation, because the server-side value had been modified between its first and second try. The more clients we have writing to this location, the more likely it is that you'll see retries. And the Firebase client performs those retries automatically, but after a number of retries it will give up and raise an <code>Error: maxretry</code> exception to the application.</p>

<p>This is the reason I could only increment a counter about 60-70 times per second: with more writes than that, there was too much contention on the node.</p>

<p>An <strong>increment</strong> operation is atomic by nature. You're telling the database: whatever the current value is, make it <code>x</code> higher. This means that the client never has to know the current value of the node, and so it also can't guess wrong. It simply tells the server what to do. </p>

<p>Our flow chart with multiple clients looks like this when using <code>increment</code>:</p>

<pre><code>            Client            Server                Client

               +                   +                   +
  increment(1) |                   |                   |
               |                   |                   | increment(1)
               |  (increment, 1)   |                   |
               +---------&gt;---------+   (increment, 1)  |
               |                   |---------&lt;---------+
               +---------&lt;---------+                   |
               |      (ack, 2)     |---------&gt;---------+
               |                   |     (ack, 3)      |
               |                   |                   |
               v                   v                   v
</code></pre>

<p>The length of these last two flow charts alone already goes a long way to explain why <code>increment</code> is so much faster in this scenario: the <code>increment</code> operation is made for this, so the wire protocol much more closely represents what we're trying to accomplish. And that simplicity leads to a 3x-4x performance difference in my simple test alone, and probably even more in production scenarios.</p>

<p>Of course transactions are still useful, as there are many more atomic operations than just increments/decrements.</p>
","209103","","209103","","2020-05-01 03:15:36","2020-05-01 03:15:36","","","","8","","","","CC BY-SA 4.0"
"63421649","2","","63421086","2020-08-15 01:01:03","","48","","<h2>Update (thanks to <a href=""https://stackoverflow.com/users/5774070/vishal-kharde"">Vishal Kharde</a>)</h2>
<p>The documentation now suggests:</p>
<pre><code>pip install webdriver-manager
</code></pre>
<hr />
<p><strong>Solution:</strong></p>
<p>Install it like that:</p>
<pre><code>pip install webdriver_manager
</code></pre>
<p>instead of <code>pip install webdrivermanager</code>.</p>
<p><strong>Requirements:</strong></p>
<p>The newest version, according to the documentation supports python 3.6 or newer versions:</p>
<p><a href=""https://i.stack.imgur.com/V42kY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/V42kY.png"" alt=""enter image description here"" /></a></p>
<p><strong>Reference:</strong>
<a href=""https://pypi.org/project/webdriver-manager/"" rel=""noreferrer"">https://pypi.org/project/webdriver-manager/</a></p>
","11225291","","11225291","","2021-03-24 16:04:32","2021-03-24 16:04:32","","","","0","","","","CC BY-SA 4.0"
"60356012","2","","60079472","2020-02-22 19:32:41","","0","","<p>I think you can ask for the user to set the permission so it disables the energy-saving mode, and warn the user that if he does not use it, exact times won't be achieved.</p>

<p>Here's the code to request it:</p>

<pre><code>PowerManager powerManager = (PowerManager) getApplicationContext().getSystemService(POWER_SERVICE);
            String packageName = ""your Package name"";
            if(Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.M) {
                Intent i = new Intent();
                if (!powerManager.isIgnoringBatteryOptimizations(packageName)) {
                    i.setAction(Settings.ACTION_REQUEST_IGNORE_BATTERY_OPTIMIZATIONS);
                    i.setData(Uri.parse(""package:"" + packageName));
                    startActivity(i);
</code></pre>
","2638180","","","","","2020-02-22 19:32:41","","","","1","","","","CC BY-SA 4.0"
"60442328","2","","60442205","2020-02-27 21:57:30","","26","","<p>Per recent CWG reflector discussion as a result of <a href=""https://github.com/cplusplus/draft/issues/3178"" rel=""noreferrer"">editorial issue 3178</a>, <code>new int[0]</code> produces what is currently called a <a href=""http://eel.is/c++draft/basic.compound#3.2"" rel=""noreferrer"">""past-the-end"" pointer value</a>.</p>

<p>It follows that <code>a</code> cannot be null, and <code>a + 1</code> is undefined by <a href=""http://wg21.link/expr.add#4"" rel=""noreferrer"">[expr.add]/4</a>.</p>
","2756719","","","","","2020-02-27 21:57:30","","","","6","","","","CC BY-SA 4.0"
"60477054","2","","60079472","2020-03-01 16:12:25","","1","","<p>I am the author of the open source project you have mentioned in your question (<a href=""https://github.com/yuriykulikov/AlarmClock"" rel=""nofollow noreferrer"">simple alarm clock)</a>. </p>

<p>I am surprised that using AlarmManager.setAlarmClock did not work for you, because my app does exactly that. The code is in the file AlarmSetter.kt. Here is a snippet:</p>

<pre><code>  val pendingAlarm = Intent(ACTION_FIRED)
                .apply {
                    setClass(mContext, AlarmsReceiver::class.java)
                    putExtra(EXTRA_ID, id)
                    putExtra(EXTRA_TYPE, typeName)
                }
                .let { PendingIntent.getBroadcast(mContext, pendingAlarmRequestCode, it, PendingIntent.FLAG_UPDATE_CURRENT) }

            val pendingShowList = PendingIntent.getActivity(
                    mContext,
                    100500,
                    Intent(mContext, AlarmsListActivity::class.java),
                    PendingIntent.FLAG_UPDATE_CURRENT
            )

            am.setAlarmClock(AlarmManager.AlarmClockInfo(calendar.timeInMillis, pendingShowList), pendingAlarm)
</code></pre>

<p>Basically it is nothing special, just make sure that intent has an action and a target class, which is a broadcast receiver in my case.</p>
","1101963","","","","","2020-03-01 16:12:25","","","","4","","","","CC BY-SA 4.0"
"60680071","2","","60442205","2020-03-14 05:40:58","","7","","<blockquote>
<pre><code>    auto a = new int[0];
</code></pre>
</blockquote>

<p>According to <a href=""http://eel.is/c++draft/basic.compound#3"" rel=""noreferrer"">[basic.compound.3]</a>, the value stored in <code>a</code> must be one of the following:</p>

<ol>
<li>A pointer to an object (of type <code>int</code>)</li>
<li>A pointer past the end of an object</li>
<li>Null</li>
<li>Invalid</li>
</ol>

<p>We can rule out the first possibility since there were no objects of type <code>int</code> constructed. The third possibility is ruled out since C++ requires a non-null pointer to be returned (see <a href=""http://eel.is/c++draft/basic.stc.dynamic.allocation#2"" rel=""noreferrer"">[basic.stc.dynamic.allocation.2]</a>). Thus we are left with two possibilities: a pointer past the end of an object or an invalid pointer.</p>

<p><em>I would be inclined to view <code>a</code> as a past-the-end pointer, but I don't have a reputable reference to definitively establish that. (There is, though, a strong implication of this in <a href=""http://eel.is/c++draft/basic.stc#4"" rel=""noreferrer"">[basic.stc]</a>, seeing how you can <code>delete</code> this pointer.) So I'll entertain both possibilities in this answer.</em></p>

<blockquote>
  <p>Between the copy initialisation and deletion, are you allowed to read the pointer at <code>a + 1</code>?</p>
</blockquote>

<p>The behavior is undefined, as dictated by <a href=""http://eel.is/c++draft/expr.add#4"" rel=""noreferrer"">[expr.add.4]</a>, regardless of which possibility from above applies.</p>

<p>If <code>a</code> is a past-the-end pointer, then it is considered to point to the hypothetical element at index <code>0</code> of an array with no elements. Adding the integer <code>j</code> to <code>a</code> is defined only when <code>0≤0+j≤n</code>, where <code>n</code> is the size of the array. In our case, <code>n</code> is zero, so the sum <code>a+j</code> is defined only when <code>j</code> is <code>0</code>. In particular, adding <code>1</code> is undefined.</p>

<p>If <code>a</code> is invalid, then we cleanly fall into ""Otherwise, the behavior is undefined."" (Not surprisingly, the cases that are defined cover only valid pointer values.)</p>

<blockquote>
  <p>Furthermore, does the language permit the compiler to set <code>a</code> to <code>nullptr</code>?</p>
</blockquote>

<p>No. From the above-mentioned <a href=""http://eel.is/c++draft/basic.stc.dynamic.allocation#2"" rel=""noreferrer"">[basic.stc.dynamic.allocation.2]</a>: <em>""If the request succeeds, the value returned by a replaceable allocation function is a non-null pointer value""</em>. There is also <a href=""http://eel.is/c++draft/basic.stc.dynamic.allocation#footnote-32"" rel=""noreferrer"">a footnote</a> calling out that C++ (but not C) requires a non-null pointer in response to a zero request.</p>
","9837301","","9837301","","2020-03-17 22:11:13","2020-03-17 22:11:13","","","","2","","","","CC BY-SA 4.0"
"65621326","2","","65621325","2021-01-07 23:20:21","","14","","<p>While on the surface this seems to be a simple question with an obvious answer it actually is not because of 2 factors:</p>
<ol>
<li>The word <code>pattern</code> is ambiguous - we don't know if the OP wants to do a regexp match or a string match, and</li>
<li>The word <code>match</code> is ambiguous - we don't know if the OP wants to do a full match on each line (consider line and record synonymous for simplicity of this answer) or a full match on specific substrings (e.g. &quot;words&quot; or fields) on a line or a partial match on part of each line or something else.</li>
</ol>
<p>Either of these would produce the expected output from the posted sample input:</p>
<ol>
<li><code>awk '/o.b/' file</code></li>
<li><code>awk '/^o.b$/' file</code></li>
<li><code>awk 'index($0,&quot;o.b&quot;)' file</code></li>
<li><code>awk '$0 == &quot;o.b&quot;' file</code></li>
</ol>
<p>but we don't know which is correct, if any, all we know is that they produce the expected output from the specific sample input in the question.</p>
<p>Consider how each would behave if the OPs real data contains additional strings like this rather than just the minimal example shown in the question:</p>
<pre><code>$ cat file
foo
foo.bar
foobar
o.b
orb
bar
</code></pre>
<p>then here are 4 possible answers that will all produce the expected output given the sample input from the question but will produce very different output given just slightly different input and we just have no way of knowing from the question as asked which output would be correct for the OPs needs:</p>
<ol>
<li>Partial regexp match:</li>
</ol>
<pre><code>$ awk '/o.b/' file
foo.bar
foobar
o.b
orb
</code></pre>
<ol start=""2"">
<li>Full-line regexp match:</li>
</ol>
<pre><code>$ awk '/^o.b$/' file
o.b
orb
</code></pre>
<ol start=""3"">
<li>Partial string match:</li>
</ol>
<pre><code>$ awk 'index($0,&quot;o.b&quot;)' file
foo.bar
o.b
</code></pre>
<ol start=""4"">
<li>Full-line string match:</li>
</ol>
<pre><code>$ awk '$0 == &quot;o.b&quot;' file
o.b
</code></pre>
<p>There are various other possibilities that might also be the correct answer when you consider full-word, full-field, and other types of matching against specific substrings on each line.</p>
<p>So whenever you ask a question about matching some text against other text:</p>
<ol>
<li>Never use the word <code>pattern</code> but instead use <code>string</code> or <code>regexp</code>, whichever it is you mean, and</li>
<li>Always state whether you want the match to be on a full line or part of a line or full substring (e.g. word or field) or part of a substring of a line.</li>
</ol>
<p>Otherwise you may end up with a solution to a problem that you don't have which could be inefficient and/or simply wrong and even if it produces the expected output for some specific input set you run it against now, it may well come back to bite you when run against some other input set later.</p>
<p>Also see <a href=""https://unix.stackexchange.com/a/631532/133219"">https://unix.stackexchange.com/a/631532/133219</a> for more examples of this issue.</p>
","1745001","","1745001","","2021-01-28 22:22:13","2021-01-28 22:22:13","","","","1","","","","CC BY-SA 4.0"
"65626792","2","","65614890","2021-01-08 09:54:37","","17","","<p>The main reason to use such a construct would be backward compatibility.</p>
<p>Prior to Java 8, there were no type annotations, so method annotations were often used to actually described the return type of a method like</p>
<pre class=""lang-java prettyprint-override""><code>@Target(ElementType.METHOD)
public @interface NotNull { }

@Target(ElementType.METHOD)
public @interface Other { }

public static @NotNull @Other My.Builder createBuilder() {
    return new My.Builder();
}
</code></pre>
<p>Starting with Java 8, you can annotate the return type itself and that’s what you normally would do. But to support old tools still looking for method annotations, you can keep the <code>@Target</code> <code>METHOD</code>. For return types consisting of a simple name, the code location for method annotations and return type annotations is the same, so you can create a method annotation and a return type annotation at the same time with a single occurrence, i.e.</p>
<pre class=""lang-java prettyprint-override""><code>@MethodAndTypeAnnotation ReturnType method() …
</code></pre>
<p>However, for qualified names, the syntax is different, as type annotation must be placed immediately prior to the simple name of the annotated element, i.e.</p>
<pre class=""lang-java prettyprint-override""><code>@Target(ElementType.TYPE_USE)
public @interface NotNull { }

@Target(ElementType.TYPE_USE)
public @interface Other { }

public static My.@NotNull @Other Builder createBuilder() {
    return new My.Builder();
}
</code></pre>
<p>For a pure type annotation using <code>public static @NotNull @Other My.Builder createBuilder()</code> would cause a compiler error, as it would be an attempt to annotate <code>My</code> which only serves as a qualifier here, not an actual type use. Note that if <code>Builder</code> was an inner class rather than a nested class (i.e. not <code>static</code>), it would be legal to annotate the outer type, though unlikely to be desired.</p>
<p>So in your case</p>
<pre class=""lang-java prettyprint-override""><code>@Target({ElementType.METHOD, ElementType.TYPE_USE})
public @interface NotNull { }

@Target({ElementType.METHOD, ElementType.TYPE_USE})
public @interface Other { }

//            method annotation    type annotation
public static @NotNull @Other   My.@NotNull @Other Builder createBuilder() {
    return new My.Builder();
}
</code></pre>
<p>both occurrences are required to annotate the method and the return type. As said, if the <code>Builder</code> was an inner class, the first occurrence would be legal to annotate the outer type and it would annotate it whether you want or not.</p>
<p>So in general, it’s not recommended to mix the “type use” annotation scope with others but to update code processing tools still requiring method or field annotations for tasks that are actually a type annotation’s job.</p>
<hr />
<p>As said, for simple names you can annotate the method and return type at once, which also works for nested types when you use an <code>import</code> statement. But this requires the top level class to be in a package:</p>
<pre class=""lang-java prettyprint-override""><code>package example;

import example.A.My.Builder;

public class A {
    static class My {
        static class Builder {
            public My build() {
                return new My(); } } }

    @Target({ElementType.METHOD, ElementType.TYPE_USE})
    public @interface NotNull { }

    @Target({ElementType.METHOD, ElementType.TYPE_USE})
    public @interface Other { }

    public static @NotNull @Other Builder createBuilder() {
        return new My.Builder();
    }
}
</code></pre>
","2711488","","2711488","","2021-01-08 09:59:41","2021-01-08 09:59:41","","","","0","","","","CC BY-SA 4.0"
"64164508","2","","64081701","2020-10-01 23:41:46","","11","","<p>(I've filed a bug on the behavior demonstrated in the question, because I don't think it's good behavior. But, as things stand, I think I can provide a guess as to what the idea is intended to be.)</p>
<hr />
<p>When you tell a snapshot to <code>reload</code> a certain item, it does <em>not</em> read in the data of the item you supply! It simply <em>looks</em> at the item, as a way of identifying <em>what</em> item, <em>already</em> in the data source, you are asking to reload.</p>
<p>(So, if the item you supply is Equatable to but not 100% identical to the item already in the data source, the &quot;difference&quot; between the item you supply and the item already in the data source will <strong>not matter at all</strong>; the data source will never be told that anything is different.)</p>
<p>When you then <code>apply</code> that snapshot to the data source, the data source tells the table view to reload the corresponding cell. This results in the data source's <em>cell provider function</em> being called again.</p>
<p>OK, so the data source's cell provider function is called, with the usual three parameters — the table view, the index path, and the data from the data source. But we've just said that the data from the data source <em>has not changed.</em> So what is the point of reloading at all?</p>
<p>The answer is, apparently, that the cell provider function is expected to look <em>elsewhere</em> to get (at least some of) the new data to be displayed in the newly dequeued cell. You are expected to have some sort of &quot;backing store&quot; that the cell provider looks at. For example, you might be maintaining a dictionary where the key is the cell identifier type and the value is the extra information that might be reloaded.</p>
<p>This must be legal, because by definition the cell identifier type is Hashable and can therefore serve as a dictionary key, and moreover the cell identifiers must be unique within the data, or the data source would reject the data (by crashing). And the lookup will be instant, because this is a dictionary.</p>
<hr />
<p>Here's a complete working example you can just copy and paste right into a project. The table portrays three names along with a star that the user can tap to make star be filled or empty, indicating favorite or not-favorite. The names are stored in the diffable data source, but the favorite status is stored in the external backing store.</p>
<pre><code>extension UIResponder {
    func next&lt;T:UIResponder&gt;(ofType: T.Type) -&gt; T? {
        let r = self.next
        if let r = r as? T ?? r?.next(ofType: T.self) {
            return r
        } else {
            return nil
        }
    }
}
class TableViewController: UITableViewController {
    var backingStore = [String:Bool]()
    var datasource : UITableViewDiffableDataSource&lt;String,String&gt;!
    override func viewDidLoad() {
        super.viewDidLoad()
        let cellID = &quot;cell&quot;
        self.tableView.register(UITableViewCell.self, forCellReuseIdentifier: cellID)
        self.datasource = UITableViewDiffableDataSource&lt;String,String&gt;(tableView:self.tableView) {
            tableView, indexPath, name in
            let cell = tableView.dequeueReusableCell(withIdentifier: cellID, for: indexPath)
            var config = cell.defaultContentConfiguration()
            config.text = name
            cell.contentConfiguration = config
            var accImageView = cell.accessoryView as? UIImageView
            if accImageView == nil {
                let iv = UIImageView()
                iv.isUserInteractionEnabled = true
                let tap = UITapGestureRecognizer(target: self, action: #selector(self.starTapped))
                iv.addGestureRecognizer(tap)
                cell.accessoryView = iv
                accImageView = iv
            }
            let starred = self.backingStore[name, default:false]
            accImageView?.image = UIImage(systemName: starred ? &quot;star.fill&quot; : &quot;star&quot;)
            accImageView?.sizeToFit()
            return cell
        }
        var snap = NSDiffableDataSourceSnapshot&lt;String,String&gt;()
        snap.appendSections([&quot;Dummy&quot;])
        let names = [&quot;Manny&quot;, &quot;Moe&quot;, &quot;Jack&quot;]
        snap.appendItems(names)
        self.datasource.apply(snap, animatingDifferences: false)
        names.forEach {
            self.backingStore[$0] = false
        }
    }
    @objc func starTapped(_ gr:UIGestureRecognizer) {
        guard let cell = gr.view?.next(ofType: UITableViewCell.self) else {return}
        guard let ip = self.tableView.indexPath(for: cell) else {return}
        guard let name = self.datasource.itemIdentifier(for: ip) else {return}
        guard let isFavorite = self.backingStore[name] else {return}
        self.backingStore[name] = !isFavorite
        var snap = self.datasource.snapshot()
        snap.reloadItems([name])
        self.datasource.apply(snap, animatingDifferences: false)
    }
}
</code></pre>
","341994","","341994","","2020-10-02 00:28:04","2020-10-02 00:28:04","","","","5","","","","CC BY-SA 4.0"
"64803438","2","","64081701","2020-11-12 11:53:47","","5","","<p>I posted the <a href=""https://stackoverflow.com/questions/64793532/nsdiffabledatasourcesnapshot-update-item/64803357#64803357"">same question</a>, not realising. I got this working by firstly converting my model to classes. Then calling 'applySnapshot' after calling 'reloadItems'.</p>
<pre><code>func toggleSelectedStateForItem(at indexPath: IndexPath, animate: Bool = true) {
    let item = dataSource.itemIdentifier(for: indexPath)!
    var snapshot = dataSource.snapshot()
    item.isSelected = !item.isSelected
    snapshot.reloadItems([item])
    dataSource.apply(snapshot)
}
</code></pre>
","9400730","","","","","2020-11-12 11:53:47","","","","4","","","","CC BY-SA 4.0"
"68413626","2","","64081701","2021-07-16 18:17:17","","4","","<p>I found (via <a href=""https://swiftsenpai.com/development/modern-ways-reload-cells/"" rel=""nofollow noreferrer"">Swift Senpai</a>) that the way you update these diffabledatasource depends on if your model is a class (pass by reference) or struct (pass by value).  In the pass by reference you can take the item, update it, then reload the item:</p>
<pre><code>// Model is a class compliant with Hasable and Equatable, name String property
guard let selectedItem = dataSource.itemIdentifier(for: indexPath) else { return}
// modify item
selectedItem.name = &quot;new name&quot;
// update the snapshot
var newSnapShot = dataSource.snapshot()
newSnapshot.reloadItems([selectedItem])
dataSource.apply(newSnapshot)
</code></pre>
<p>So the above code will work with a model that is a class (the class needs to explicitly implement hast(into:) and ==(lhs:rhs:)).</p>
<p>On the other hand, a struct requires you to copy the item, update it, then insert the updated item and delete the old item from the snapshot.</p>
<pre><code>// Model is a struct with name String property
guard let selectedItem = dataSource.itemIdentifier(for: indexPath) else { return}
// update the item
var updatedSelectedItem = selectedItem
updatedSelectedItem.name = &quot;new name&quot;
// update snapshot
var newSnapShot = dataSource.snapshot()
newSnapshot.insertItems([updatedSelectedItem], beforeItem: selectedItem)
newSnapshot.deleteItems([selectedItem])
dataSource.apply(newSnapshot)
</code></pre>
<p>These worked for me.</p>
","2390964","","","","","2021-07-16 18:17:17","","","","3","","","","CC BY-SA 4.0"
"59603115","2","","59603086","2020-01-05 18:49:11","","17","","<p>Yes, because <a href=""https://en.cppreference.com/w/cpp/container/map"" rel=""noreferrer""><code>std::map</code></a> default comparison operator is <a href=""https://en.cppreference.com/w/cpp/utility/functional/less"" rel=""noreferrer""><code>std::less</code></a>, which, unlike the standard comparison operator, is completely defined for pointer types. </p>

<blockquote>
  <p><a href=""http://eel.is/c++draft/comparisons#2"" rel=""noreferrer"">[comparisons#2]</a></p>
  
  <p>For templates less, greater, less_­equal, and greater_­equal, the specializations for any pointer type yield a result consistent with the implementation-defined strict total order over pointers (<a href=""http://eel.is/c++draft/defns.order.ptr"" rel=""noreferrer"">[defns.order.ptr]</a>).</p>
</blockquote>

<p>The <em>implementation-defined strict total order over pointers</em> is defined in <a href=""http://eel.is/c++draft/defns.order.ptr"" rel=""noreferrer"">[defns.order.ptr]</a> as:</p>

<blockquote>
  <p>implementation-defined strict total ordering over all pointer values such that the ordering is consistent with the partial order imposed by the builtin operators &lt;, >, &lt;=, >=, and &lt;=></p>
</blockquote>
","2666289","","2666289","","2020-01-05 18:55:03","2020-01-05 18:55:03","","","","8","","","","CC BY-SA 4.0"
"59603120","2","","59603086","2020-01-05 18:49:40","","8","","<p><a href=""https://en.cppreference.com/w/cpp/utility/functional/less"" rel=""nofollow noreferrer"">std::less</a> (default comparer of <code>std::map</code>) has special treatment about pointer allowing that:</p>

<blockquote>
  <p>A specialization of <code>std::less</code> for any pointer type yields a strict total order, even if the built-in <code>operator&lt;</code> does not. </p>
</blockquote>

<p>And about</p>

<blockquote>
  <p>can we say that a map with pointer keys is a <em>dangerous</em> proposition?</p>
</blockquote>

<p>So it is fine in general.</p>

<p>Additional precaution should be taken with <code>const char*</code> key:</p>

<p>We compare pointers and not string content (mostly beginner confusions).</p>

<p>C-string literals with same content have no guaranty to be equals:</p>

<pre><code>""literal"" == ""literal""; // Not guaranteed
""literal"" &lt; ""literal""; // false .. or true
</code></pre>
","2684539","","2684539","","2020-01-05 19:01:05","2020-01-05 19:01:05","","","","1","","","","CC BY-SA 4.0"
"63778277","2","","63778276","2020-09-07 13:10:09","","60","","<p>To target the various parts of the expanded class, use the appropriate attribute target. For instance:</p>
<pre><code>// Target the property, use `property`
record Person(string FirstName, string LastName, [property: JsonIgnore] int Age);

// Target the backing field of the property, use `field`
record Person(string FirstName, string LastName, [field: JsonIgnore] int Age);

// Target the constructor parameter, use `param`
record Person(string FirstName, string LastName, [param: SomeParamAttribute] int Age);
</code></pre>
","23528","","","","","2020-09-07 13:10:09","","","","3","","","","CC BY-SA 4.0"
"67092959","2","","64545862","2021-04-14 13:40:55","","1","","<p>tip from my own mistakes: make sure all spellings are correct, and try using this 😁<code>import firebase from 'firebase'</code></p>
","12387769","","","","","2021-04-14 13:40:55","","","","0","","","","CC BY-SA 4.0"
"68994787","2","","64545862","2021-08-31 07:46:30","","6","","<p>try using this for firebase 9 above</p>
<pre><code>import firebase from 'firebase/compat/app';
import 'firebase/compat/auth';
import 'firebase/compat/firestore';
</code></pre>
<p>or you can read more on: <a href=""https://firebase.google.com/docs/web/modular-upgrade"" rel=""noreferrer"">https://firebase.google.com/docs/web/modular-upgrade</a></p>
","15235854","","","","","2021-08-31 07:46:30","","","","0","","","","CC BY-SA 4.0"
"68996100","2","","64545862","2021-08-31 09:21:53","","1","","<p><strong>This is the new firebase 9 updates :</strong></p>
<pre><code>   import { initializeApp } from &quot;firebase/app&quot;;
   import { getMessaging, getToken } from &quot;firebase/messaging&quot;;
</code></pre>
","13936039","","1839439","","2021-08-31 09:27:51","2021-08-31 09:27:51","","","","0","","","","CC BY-SA 4.0"
"69556669","2","","64545862","2021-10-13 13:42:03","","0","","<p><strong>I had faced a similar problem while trying to use Firebase authentication in an old site.</strong></p>
<p>This solved the problem:</p>
<pre class=""lang-sh prettyprint-override""><code>npm uninstall firebase step
npm install firebase
</code></pre>
","6411407","","10926046","","2021-10-13 14:44:29","2021-10-13 14:44:29","","","","0","","","","CC BY-SA 4.0"
"70048243","2","","64545862","2021-11-20 17:24:39","","0","","<p>I solved similar problem for firebase version &gt; 9, by using in the route:
<code>/compat/</code>
Eg:
<code>import firebase from &quot;firebase/compat/app&quot;;</code></p>
","12421835","","","","","2021-11-20 17:24:39","","","","0","","","","CC BY-SA 4.0"
"70434191","2","","64545862","2021-12-21 10:45:11","","0","","<p>I solved my problem using this kind of 'import' approach in firebase version 9.6.1 :</p>
<pre><code>import &quot;firebase/auth&quot;
import firebase from 'firebase/compat/app';
import 'firebase/compat/auth';
import 'firebase/compat/firestore';

const firebaseConfig = {
 apiKey: &quot;AIzaSyBbaKxbqufRCfrwGpQ3sfuBgIifIhTCP1A&quot;,
 authDomain: &quot;facebook-clone-f4994.firebaseapp.com&quot;,
 projectId: &quot;facebook-clone-f4994&quot;,
 storageBucket: &quot;facebook-clone-f4994.appspot.com&quot;,
 messagingSenderId: &quot;593047789391&quot;,
 appId: &quot;1:593047789391:web:11459d7b291b9465542f3a&quot;,
 measurementId: &quot;G-FNW1K23DBJ&quot;
};


const firebaseApp = firebase.initializeApp(firebaseConfig);
const db = firebaseApp.firestore();
const auth = firebase.auth();
const provider = new firebase.auth.GoogleAuthProvider();


export { auth, provider };
export default db;
</code></pre>
","17260568","","","","","2021-12-21 10:45:11","","","","0","","","","CC BY-SA 4.0"
"70526273","2","","64545862","2021-12-30 00:16:05","","0","","<p><strong>2021 update:</strong></p>
<p>Firebase v9 comes with new API designed to facilitate tree-shaking (removal of unused code). This will make your web app as small and fast as possible.</p>
<p>The <code>/compat</code> packages are created for compatibility and to make the upgrade to the modular API easier. With the downside of not getting the performance perks. To get the performance benefits of the modular design, use <code>getApps</code> instead:</p>
<pre><code>import { getApps, initializeApp } from 'firebase/app';

if (!getApps().length) {
  initializeApp({
    // your config
  });
}
</code></pre>
<p>From the library's JSDoc: <code>getApps</code> return <code>A (read-only) array of all initialized apps.</code>.</p>
<p>There is also a <code>getApp</code> function that <code>When called with no arguments, the default app is returned. When an app name is provided, the app corresponding to that name is returned. An exception is thrown if the app being retrieved has not yet been initialized.</code></p>
","3917580","","3917580","","2022-01-02 09:37:48","2022-01-02 09:37:48","","","","0","","","","CC BY-SA 4.0"
"66107953","2","","66075419","2021-02-08 19:18:15","","2","","<p>Well, I'll just say it after <a href=""https://stackoverflow.com/a/48347198/2711488"">Holger's confirmation and answer</a>: JLS is underspecified (at least) at this location. There are some related JDK bugs that work around the same idea, noticeable <a href=""https://bugs.openjdk.java.net/browse/JDK-8078084"" rel=""nofollow noreferrer"">this one</a>, that directly hits your question via:</p>
<blockquote>
<p>.... Otherwise, map wildcards and type variables to their upper bounds, and then test whether their erasures are related classes or interfaces (that is, one erased type is a subtype of the other)</p>
</blockquote>
<p>Only to immediately start the next sentence with:</p>
<blockquote>
<p>This is unsound...</p>
</blockquote>
<p>So, that bug admits that JLS needs some corrections around this chapter(s).</p>
<p>What I have been struggling with too from your quotes of the JLS are two points:</p>
<ul>
<li><p>One type argument is a type variable or wildcard, with an upper bound <strong>(from capture conversion (§5.1.10), if necessary)</strong>...</p>
<p>I do know what <em>capture conversion</em> is, but I was not aware it might be optional to be performed (via that &quot;if necessary&quot;). I always thought that it is performed at each location, all the time.</p>
</li>
<li><p>What is an <em>upper bound</em> from a <em>captured conversion type</em>?</p>
<p>In your case, is that <em>upper bound</em> <code>List&lt;Number&gt;</code> or <code>List&lt;?&gt;</code>, for example? In my understanding (or lack of precise JLS explanation), this could be understood either way.</p>
</li>
</ul>
<p>All these (+ your great scrape of the JLS) makes me wonder about the correctness of the JLS here, especially since <code>javac</code> is not following these exact same rules.</p>
","1059372","","68587","","2021-02-08 22:35:00","2021-02-08 22:35:00","","","","3","","","","CC BY-SA 4.0"
"66631298","2","","66631288","2021-03-15 01:33:50","","11","","<p>This is a self answer per <a href=""https://stackoverflow.blog/2011/07/01/its-ok-to-ask-and-answer-your-own-questions/"">Answer Your Own Question</a>.</p>
<p>Appending an <code>f</code> makes the constant a <code>float</code> and <em>sometimes</em> makes a value difference.</p>
<hr />
<p><strong>Type</strong></p>
<p>Type difference: <code>double</code> to <code>float</code>.</p>
<p>A well enabled compiler may emit a warning when the <code>f</code> is omitted too.</p>
<pre><code>  float f = 3.1415926535897932;  // May generate a warning
</code></pre>
<blockquote>
<p>warning: conversion from 'double' to 'float' changes value from '3.1415926535897931e+0' to '3.14159274e+0f' [-Wfloat-conversion]</p>
</blockquote>
<hr />
<p><strong>Value</strong></p>
<p>To make a <em>value</em> difference, watch out for potential <a href=""https://en.wikipedia.org/wiki/Rounding#Double_rounding"" rel=""nofollow noreferrer"">double rounding</a> issues.</p>
<p>The first rounding is due to code's text being converted to the floating point type.</p>
<blockquote>
<p>the result is either the nearest representable value, or the larger or smaller representable value immediately adjacent to the nearest representable value, chosen in an implementation-defined manner. C17dr § 6.4.4.2 3</p>
</blockquote>
<p>Given those two choices, a <em>very common</em> implementation-defined manner is to convert the source code text to the closest <code>double</code> (without the <code>f</code>) or to the closest <code>float</code> with the <code>f</code> suffix.  Lesser quality implementations sometimes form the 2nd closest choice.</p>
<p>Assignment of a <code>double</code> FP constant to a <code>float</code> incurs another rounding.</p>
<blockquote>
<p>If the value being converted is in the range of values that can be represented but cannot be represented exactly, the result is either the nearest higher or nearest lower representable value, chosen in an implementation-defined manner. C17dr § 6.3.1.4 2</p>
</blockquote>
<p>A <em>very common</em> implementation-defined manner is to convert the <code>double</code> to the closest <code>float</code> - with ties to even.  (Note: compile time rounding may be affected by various compiler settings.)</p>
<p><strong>Double rounding value change</strong></p>
<p>Consider the case when source code uses a value <em>very close</em> to half-way between 2 <code>float</code> values.</p>
<p>Without an <code>f</code>, the rounding of code to a <code>double</code> may result in a value exactly half-way between 2 <code>float</code>s.  The conversion of the <code>double</code> to <code>float</code> then could differ from &quot;with an <code>f</code>&quot;.</p>
<p>With an <code>f</code>, the conversion results in the closest <code>float</code>.</p>
<p>Example:</p>
<pre><code>#include &lt;math.h&gt;
#include &lt;stdio.h&gt;
int main(void) {
  float f;
  f = 10000000.0f;
  printf(&quot;%.6a  %.3f  10 million\n&quot;, f, f);
  f = nextafterf(f, f + f);
  printf(&quot;%.6a  %.3f  10 million - next float\n&quot;, f, f);
  puts(&quot;&quot;);
  f = 10000000.5000000001;
  printf(&quot;%.6a  %.3f  10000000.5000000001\n&quot;, f, f);
  f = 10000000.5000000001f;
  printf(&quot;%.6a  %.3f  10000000.5000000001f\n&quot;, f, f);
  puts(&quot;&quot;);
  f = 10000001.4999999999;
  printf(&quot;%.6a  %.3f  10000001.4999999999\n&quot;, f, f);
  f = 10000001.4999999999f;
  printf(&quot;%.6a  %.3f  10000001.4999999999f\n&quot;, f, f);
}
</code></pre>
<p>Output</p>
<pre><code>0x1.312d00p+23  10000000.000  10 million
0x1.312d02p+23  10000001.000  10 million - next float

// value        value         source code
0x1.312d00p+23  10000000.000  10000000.5000000001
0x1.312d02p+23  10000001.000  10000000.5000000001f // Different, and better

0x1.312d04p+23  10000002.000  10000001.4999999999
0x1.312d02p+23  10000001.000  10000001.4999999999f // Different, and better
</code></pre>
<p><strong>Rounding mode</strong></p>
<p>The issue about double<sup>1</sup> rounding is less likely when the rounding mode is up, down or towards zero.  Issue arises when the 2nd rounding compounds the direction on half-way cases.</p>
<p><strong>Occurrence rate</strong></p>
<p>Issue occurs when code converts inexactly to a <code>double</code> that is very near half-way between 2 <code>float</code> values - so relatively rare.  Issue applies even if the code constant was in decimal or hexadecimal form.  With random constants: about 1 in 2<sup>30</sup>.</p>
<p><strong>Recommendation</strong></p>
<p>Rarely a major concern, yet an <code>f</code> suffix is better to get the best value for a <code>float</code> and quiet a warning.</p>
<hr />
<p><sup>1</sup> <em>double</em> here refers to doing something twice, not the the type <code>double</code>.</p>
","2410359","","2410359","","2021-10-29 14:29:00","2021-10-29 14:29:00","","","","0","","","","CC BY-SA 4.0"
"66637501","2","","66631288","2021-03-15 11:54:27","","1","","<p>As a small addendum to <a href=""/a/66631298"">chux's answer</a> is an example of something that can be perplexing: we assign a value to a float, and then immediately compare the float to the value and find they are not equal!</p>
<pre><code>#include &lt;stdio.h&gt;

#define DCN 0.7
#define FCN 0.7f

int main(void)
{
    float f = DCN;
    const char* cf = (f == DCN) ? &quot;equal&quot; : (f &gt; DCN) ? &quot;greater&quot; : (f &lt; DCN) ? &quot;less&quot; : &quot;???&quot; ;
    printf(&quot;DCN\t%s\n&quot;, cf);

    float g = FCN;
    const char* cg = (g == FCN) ? &quot;equal&quot; : (g &gt; FCN) ? &quot;greater&quot; : (g &lt; FCN) ? &quot;less&quot; : &quot;???&quot; ;
    printf(&quot;FCN\t%s\n&quot;, cg);
}
</code></pre>
<p>When I run this I get:</p>
<pre class=""lang-none prettyprint-override""><code>DCN less
FCN equal
</code></pre>
<p>On the other hand if the constants are replaced with <code>0.1</code> and <code>0.1f</code> I get:</p>
<pre class=""lang-none prettyprint-override""><code>DCN more
FCN equal
</code></pre>
","2564696","","4850040","","2021-07-30 07:09:57","2021-07-30 07:09:57","","","","1","","","","CC BY-SA 4.0"
"67081775","2","","67081496","2021-04-13 20:12:50","","4","","<p>Another base solution, with a lookup vector:</p>
<pre><code>## Toy example
data = data.frame(
  id = 1:5,
  x = c(&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;),
  stringsAsFactors = F
)

lookup = data.frame(
  old = c(&quot;A&quot;, &quot;D&quot;),
  new = c(&quot;a&quot;, &quot;d&quot;),
  stringsAsFactors = F
)

lv &lt;- structure(lookup$new, names = lookup$old)

safe_lookup &lt;- function(val) {
  new_val &lt;- lv[val]
  unname(ifelse(is.na(new_val), val, new_val))
}

data$x &lt;- safe_lookup(data$x)
</code></pre>
","9216512","","","","","2021-04-13 20:12:50","","","","0","","","","CC BY-SA 4.0"
"67082326","2","","67081496","2021-04-13 21:02:07","","7","","<h2>modify_if</h2>
<p>You could use <code>purrr::modify_if</code> to only apply the named vector to values that exist in it. Though not a specified requirement, it has the benefit of the <code>.else</code> argument, which allows you to apply a different function to values not in your lookup.</p>
<p>I also wanted to include the use of <code>tibble::deframe</code> here to create the named vector. It is slower than <code>setNames</code>, though.</p>
<pre><code>lookupV &lt;- deframe(lookup)

data %&gt;% 
  mutate(x = modify_if(x, x %in% lookup$old, ~ lookupV[.x]))
</code></pre>
<h2>str_replace_all</h2>
<p>Alternatively, you could use <code>stringr::str_replace_all</code>, which can take a named vector for the <code>replacement</code> argument.</p>
<pre><code>data %&gt;% 
  mutate(x = str_replace_all(x, lookupV))
</code></pre>
<p><strong>Update</strong></p>
<p>To accommodate the change to your edited example, the named vector used in <code>str_replace_all</code> needs to be modified. In this way, the entire literal string needs to be match so that &quot;A&quot; does not get substituted in &quot;AA&quot;, or &quot;.&quot; does not replace everything:</p>
<pre><code>lookupV &lt;- setNames(lookup$new, do.call(sprintf, list(&quot;^\\Q%s\\E$&quot;, lookup$old)))

data %&gt;% 
  mutate(x = str_replace_all(x, lookupV))
</code></pre>
<h2>left_join</h2>
<p>Using <code>dplyr::left_join</code> this is very similar to OP solution, but uses <code>.keep</code> argument of <code>mutate</code> so it has less steps. This argument is currently in the <em>experimental</em> lifecycle and so it is not included in the benchmark (though it is around the middle of posted solutions).</p>
<pre><code>left_join(data, lookup, by = c(&quot;x&quot; = &quot;old&quot;)) %&gt;% 
    mutate(x = coalesce(new, x) , .keep = &quot;unused&quot;)
</code></pre>
<h2>Base <code>R</code></h2>
<h3>Named Vector</h3>
<p>Create a substitution value for every unique value in your dataframe.</p>
<pre><code>lookupV &lt;- c(with(lookup, setNames(new, old)), setNames(nm = setdiff(unique(data$x), lookup$old)))

data$x &lt;- lookupV[data$x]
</code></pre>
<h3>ifelse</h3>
<pre><code>with(data, ifelse(x %in% lookup$old, lookupV[x], x))
</code></pre>
","6382434","","6382434","","2021-04-19 20:50:25","2021-04-19 20:50:25","","","","2","","","","CC BY-SA 4.0"
"64977620","2","","64977541","2020-11-23 22:40:20","","21","","<p>I think the relevant part of the C++20 standard is [stmt.return], which says</p>
<blockquote>
<p>The copy-initialization of the result of the call is sequenced before the destruction of temporaries at the end of the full-expression established by the operand of the return statement, which, in turn, is sequenced before the destruction of local variables (8.7) of the block enclosing the return statement</p>
</blockquote>
<p>So the result of the function call (the return value) should be constructed first, then <code>foo</code> is destroyed. Since the returned value is constructed before <code>foo</code>'s destructor is run, the result should be 0.</p>
<p>The [class.copy.elision] section says</p>
<blockquote>
<p>When certain criteria are met, an implementation is allowed to omit the copy/move construction of a class object, even if the constructor selected for the copy/move operation and/or the destructor for the object have side effects.</p>
</blockquote>
<p>So both compilers can be considered correct.</p>
","5231607","","5231607","","2020-11-23 22:47:43","2020-11-23 22:47:43","","","","1","","","","CC BY-SA 4.0"
"64977664","2","","64977541","2020-11-23 22:44:32","","16","","<p>I think both compiler are right. NRVO is a common and permitted optimization. If that optimization indeed happen, you're gonna see the item inserted in it by the destructor.</p>
<p>If NRVO don't happen, then just like @1201ProgramAlarm said, the expected behavior is to return the empty vector.</p>
<p>To quote the same content as his answer,</p>
<blockquote>
<p>The copy-initialization of the result of the call is sequenced before the destruction of temporaries at the end of the full-expression established by the operand of the return statement, which, in turn, is sequenced before the destruction of local variables (8.7) of the block enclosing the return statement</p>
</blockquote>
<p>So whithout copy elision, you end up copying the vector before the destruction resulting in a size of <code>0</code>. With copy elision, you're inserting into the same vector you seen in the main function.</p>
<p>TL;DR: Don't rely on behavior that can change when NRVO is applied. These kind of behavior includes observable side effect from calling a constructor or a destructor, just like your example did.</p>
","2104697","","2104697","","2020-11-28 16:20:02","2020-11-28 16:20:02","","","","1","","","","CC BY-SA 4.0"
"68332748","2","","68332664","2021-07-11 02:02:44","","34","","<p>Yes, indexing by <code>Int</code> is causing you to lose your <code>O(1)</code> access into the reversed array. Quite the gotcha!</p>
<p>As you note, <code>reversed()</code> here is an overloaded method; on <code>Array</code> specifically, you have two definitions to choose from:</p>
<ol>
<li><a href=""https://github.com/apple/swift/blob/7123d2614b5f222d03b3762cb110d27a9dd98e24/stdlib/public/core/Reverse.swift#L292"" rel=""noreferrer""><code>BidirectionalCollection.reversed()</code></a>, which returns a <code>ReversedCollection</code>, and</li>
<li><a href=""https://github.com/apple/swift/blob/7123d2614b5f222d03b3762cb110d27a9dd98e24/stdlib/public/core/SequenceAlgorithms.swift#L709"" rel=""noreferrer""><code>Sequence.reversed()</code></a>, which turns any sequence into a reversed <code>[Element]</code></li>
</ol>
<p>The overloading here is most confusing for <code>Array</code> itself, because it's the only <code>Sequence</code> type such that <code>type(of: x) == type(of: x.reversed())</code>.</p>
<p>The Swift type checker prefers more specific overloads over less-specific ones, so in general, the compiler will use the <code>BidirectionalCollection</code> overload instead of the <code>Sequence</code> one where possible. The rub: <code>BidirectionalCollection</code> has an <a href=""https://github.com/apple/swift/blob/7123d2614b5f222d03b3762cb110d27a9dd98e24/stdlib/public/core/Reverse.swift#L116"" rel=""noreferrer""><em>opaque</em> index type</a>, and cannot be indexed using an <code>Int</code>; when you <em>do</em> index into the collection with an <code>Int</code>, the compiler is instead forced to choose the <code>Sequence</code> overload over the <code>BidirectionalCollection</code> one. This is also why your second code sample fails to compile: Swift code inference does not take into account surrounding context on other lines; on its own, <code>rev</code> is preferred to be a <code>ReversedCollection&lt;Array&lt;Int&gt;&gt;</code>, so attempting to index into it with an <code>Int</code> fails.</p>
<p>You can see this a little more clearly with the following:</p>
<pre><code>func collType1&lt;T: Collection&gt;(_: T) {
    print(T.self) // ReversedCollection&lt;Array&lt;Int&gt;&gt;
    print(T.Index.self) // Index
}

func collType2&lt;T: Collection&gt;(_: T) where T.Index == Int {
    print(T.self) // Array&lt;Int&gt;
    print(T.Index.self) // Int
}

let x: [Int] = [1, 2, 3]
collType1(x.reversed())
collType2(x.reversed())
</code></pre>
<hr />
<p>Lest you wonder whether the compiler can optimize around this when the fact of <code>Int</code>-based indexing appears to not have any other side effects, at the time of writing, the answer appears to be &quot;no&quot;. The <a href=""https://godbolt.org/z/z8zxc3K6P"" rel=""noreferrer"">Godbolt output</a> is a bit too long to reproduce here, but at the moment, comparing</p>
<pre><code>func foo1(_ array: [Int]) {
    if array.reversed()[100] &gt; 42 {
        print(&quot;Wow!&quot;)
    }
}
</code></pre>
<p>with</p>
<pre><code>func foo2(_ array: [Int]) {
    if array.reversed().dropFirst(100).first! &gt; 42 {
        print(&quot;Wow!&quot;)
    }
}
</code></pre>
<p>with optimizations enabled shows <code>foo2</code> performing direct array access</p>
<pre><code>cmp     qword ptr [rdi + 8*rax + 24], 43
</code></pre>
<p>having optimized away the <code>ReversedCollection</code> wrapper entirely, while <code>foo1</code> goes through significantly more indirection.</p>
","169394","","169394","","2021-07-11 13:28:11","2021-07-11 13:28:11","","","","6","","","","CC BY-SA 4.0"
"59603215","2","","59603086","2020-01-05 19:01:12","","2","","<p><code>std::map</code> use <code>std::less</code> that have a specialization for pointer type :</p>

<blockquote>
  <p>A specialization of std::less for any pointer type yields a strict
  total order, even if the built-in operator&lt; does not. The strict total
  order is consistent among specializations of std::less, std::greater,
  std::less_equal, and std::greater_equal for that pointer type, and is
  also consistent with the partial order imposed by the corresponding
  built-in operators (&lt;, >, &lt;= and >=).</p>
</blockquote>

<p>For a more specific description i leave you 2 links:</p>

<p><a href=""https://en.cppreference.com/w/cpp/utility/functional/less"" rel=""nofollow noreferrer"">std::less first link</a></p>

<p><a href=""http://www.enseignement.polytechnique.fr/informatique/INF478/docs/Cpp/en/cpp/utility/functional/less.html"" rel=""nofollow noreferrer"">std::less second link</a></p>
","12491175","","","","","2020-01-05 19:01:12","","","","0","","","","CC BY-SA 4.0"
"61531318","2","","61531317","2020-04-30 19:32:24","","55","","<h1>Short version of answer:</h1>
<ul>
<li>Use <code>getClass().getResource(...)</code> or <code>SomeOtherClass.class.getResource(...)</code> to create a <code>URL</code> to the resource</li>
<li>Pass either an absolute path (with a leading <code>/</code>) or a relative path (without a leading <code>/</code>) to the <code>getResource(...)</code> method. The path is the <em>package</em> containing the resource, with <code>.</code> replaced with <code>/</code>.</li>
<li><strong>Do not use</strong> <code>..</code> in the resource path. If and when the application is bundled as a jar file, this will not work. If the resource is not in the same package or in a subpackage of the class, use an absolute path.</li>
<li>For FXML files, pass the <code>URL</code> directly to the <code>FXMLLoader</code>.</li>
<li>For images and stylesheets, call <code>toExternalForm()</code> on the <code>URL</code> to generate the <code>String</code> to pass to the <code>Image</code> or <code>ImageView</code> constructor, or to add to the <code>stylesheets</code> list.</li>
<li>To troubleshoot, examine the content of your <em>build</em> folder (or jar file), not your <em>source</em> folder.</li>
</ul>
<hr />
<h1>Full Answer</h1>
<h2>Contents</h2>
<ol>
<li>Scope of this answer</li>
<li>Resources are loaded at runtime</li>
<li>JavaFX uses URLs to load resources</li>
<li>Rules for resource names</li>
<li>Creating a resource URL with <code>getClass().getResource(...)</code></li>
<li>Organizing code and resources</li>
<li>Maven (and similar) standard layouts</li>
<li>Troubleshooting</li>
</ol>
<h2>
Scope of this answer</h2>
<p>Note that this answer <em>only</em> addresses loading resources (for example FXML files, images, and stylesheets) that are part of the application, and bundled with it. So, for example, loading images that the user chooses from the file system on the machine on which the application is running would require different techniques that are not covered here.</p>
<h2>
Resources are loaded at runtime</h2>
<p>The first thing to understand about loading resources is that they, of course, are loaded at runtime. Typically, during development, an application is run from the file system: that is, the class files and resources required to run it are individual files on the file system. However, once the application is built, it is usually executed from a jar file. In this case, the resources such as FXML files, stylesheets, and images, are no longer individual files on the filesystem but are entries in the jar file. Therefore:</p>
<blockquote>
<p>Code cannot use <code>File</code>, <code>FileInputStream</code>, or <code>file:</code> URLs to load a resource</p>
</blockquote>
<h2>
JavaFX uses URLs to load resources</h2>
<p>JavaFX loads FXML, Images, and CSS stylesheets using URLs.</p>
<p>The <code>FXMLLoader</code> explicitly expects a <code>java.net.URL</code> object to be passed to it (either to the <code>static</code> <code>FXMLLoader.load(...)</code> method, to the <code>FXMLLoader</code> constructor, or to the <code>setLocation()</code> method).</p>
<p>Both <code>Image</code> and <code>Scene.getStylesheets().add(...)</code> expect <code>String</code>s that represent URLs. If URLs are passed without a scheme, they are interpreted relative to the classpath. These strings can be created from a <code>URL</code> in a robust way by calling <code>toExternalForm()</code> on the <code>URL</code>.</p>
<p>The recommended mechanism for creating the correct URL for a resource is to use <code>Class.getResource(...)</code>, which is called on an appropriate <code>Class</code> instance. Such a class instance can be obtained by calling <code>getClass()</code> (which gives the class of the current object), or <code>ClassName.class</code>. The <code>Class.getResource(...)</code> method takes a <code>String</code> representing the resource name.</p>
<h2>
Rules for resource names</h2>
<ul>
<li>Resource names are <code>/</code>-separated path names. Each component represents a package or sub-package name component.</li>
<li>Resource names are case-sensitive.</li>
<li>The individual components in the resource name <strong>must be valid Java identifiers</strong></li>
</ul>
<p>The last point has an important consequence:</p>
<blockquote>
<p><code>.</code> and <code>..</code> are not valid Java identifiers, so they <em><strong>cannot be used in resource names</strong></em>.</p>
</blockquote>
<p>These may actually work when the application is running from the filesystem, though this is really more of an accident of the implementation of <code>getResource()</code>. They will fail when the application is bundled as a jar file.</p>
<p>Similarly, if you are running on an operating system that does not distinguish between filenames that differ only by case, then using the wrong case in a resource name might work while running from the filesystem, but will fail when running from a jar file.</p>
<p>Resource names beginning with a leading <code>/</code> are <em>absolute</em>: in other words they are interpreted relative to the classpath. Resource names without a leading <code>/</code> are interpreted relative to the class on which <code>getResource()</code> was called.</p>
<p>A slight variation on this is to use <code>getClass().getClassLoader().getResource(...)</code>. The path supplied to <code>ClassLoader.getResource(...)</code> <strong>must not</strong> begin with a <code>/</code> and is <em>always</em> absolute, i.e. it is relative to the classpath. It should also be noted that in modular applications, access to resources using <code>ClassLoader.getResource()</code> is, under some circumstances, subject to rules of strong encapsulation, and additionally the package containing the resource must be opened unconditionally. See the <a href=""https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/ClassLoader.html#getResource(java.lang.String)"" rel=""noreferrer"">documentation</a> for details.</p>
<h2>
Creating a resource URL with <code>getClass().getResource()</code></h2>
<p>To create a resource URL, use <code>someClass.getResource(...)</code>. Usually, <code>someClass</code> represents the class of the current object, and is obtained using <code>getClass()</code>. However, this doesn't have to be the case, as described in the next section.</p>
<ul>
<li><p>If the resource is in the same package as the current class, or in a subpackage of that class, use a relative path to the resource:</p>
<pre><code> // FXML file in the same package as the current class:
 URL fxmlURL = getClass().getResource(&quot;MyFile.fxml&quot;);
 Parent root = FXMLLoader.load(fxmlURL);

 // FXML file in a subpackage called `fxml`:
 URL fxmlURL2 = getClass().getResource(&quot;fxml/MyFile.fxml&quot;);
 Parent root2 = FXMLLoader.load(fxmlURL2);

 // Similarly for images:
 URL imageURL = getClass().getResource(&quot;myimages/image.png&quot;);
 Image image = new Image(imageURL.toExternalForm());
</code></pre>
</li>
<li><p>If the resource is in a package that is not a subpackage of the current class, use an absolute path. For example, if the current class is in the package <code>org.jamesd.examples.view</code>, and we need to load a CSS file <code>style.css</code> which is in the package <code>org.jamesd.examples.css</code>, we have to use an absolute path:</p>
<pre><code> URL cssURL = getClass().getResource(&quot;/org/jamesd/examples/css/style.css&quot;);
 scene.getStylesheets().add(cssURL.toExternalForm());
</code></pre>
<p>It's worth re-emphasizing for this example that the path <code>&quot;../css/style.css&quot;</code> does not contain valid Java resource names, and <strong>will not work</strong> if the application is bundled as a jar file.</p>
</li>
</ul>
<h2>
Organizing code and resources</h2>
<p>I recommend organizing your code and resources into packages determined by the part of the UI they are associated with. The following source layout in Eclipse gives an example of this organization:</p>
<p><a href=""https://i.stack.imgur.com/fPFmF.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/fPFmF.png"" alt=""enter image description here"" /></a></p>
<p>Using this structure, each resource has a class in the same package, so it is easy to generate the correct URL for any resource:</p>
<pre><code>FXMLLoader editorLoader = new FXMLLoader(EditorController.class.getResource(&quot;Editor.fxml&quot;));
Parent editor = editorLoader.load();
FXMLLoader sidebarLoader = new FXMLLoader(SidebarController.class.getResource(&quot;Sidebar.fxml&quot;));
Parent sidebar = sidebarLoader.load();

ImageView logo = new ImageView();
logo.setImage(newImage(SidebarController.class.getResource(&quot;logo.png&quot;).toExternalForm()));

mainScene.getStylesheets().add(App.class.getResource(&quot;style.css&quot;).toExternalForm());
</code></pre>
<p>If you have a package with only resources and no classes, for example, the <code>images</code> package in the layout below</p>
<p><a href=""https://i.stack.imgur.com/s26lK.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/s26lK.png"" alt=""enter image description here"" /></a></p>
<p>you can even consider creating a &quot;marker interface&quot; solely for the purposes of looking up the resource names:</p>
<pre><code>package org.jamesd.examples.sample.images ;
public interface ImageLocation { }
</code></pre>
<p>which now lets you find these resources easily:</p>
<pre><code>Image clubs = new Image(ImageLocation.class.getResource(&quot;clubs.png&quot;).toExternalForm());
</code></pre>
<p>Loading resources from a subpackage of a class is also reasonably straightforward. Given the following layout:</p>
<p><a href=""https://i.stack.imgur.com/5VFSe.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/5VFSe.png"" alt=""enter image description here"" /></a></p>
<p>we can load resources in the <code>App</code> class as follows:</p>
<pre><code>package org.jamesd.examples.resourcedemo;

import java.net.URL;

import javafx.application.Application;
import javafx.fxml.FXMLLoader;
import javafx.scene.Parent;
import javafx.scene.Scene;
import javafx.stage.Stage;

public class App extends Application {

    @Override
    public void start(Stage primaryStage) throws Exception {        
        
        URL fxmlResource = getClass().getResource(&quot;fxml/MainView.fxml&quot;);
        
        
        FXMLLoader loader = new FXMLLoader();
        loader.setLocation(fxmlResource);
        Parent root = loader.load();
        Scene scene = new Scene(root);
        scene.getStylesheets().add(getClass().getResource(&quot;style/main-style.css&quot;).toExternalForm());
        primaryStage.setScene(scene);
        primaryStage.show();
    }
    
    public static void main(String[] args) {
        Application.launch(args);
    }

}
</code></pre>
<p>To load resources which are not in the same package, or a subpackage, of the class from which you're loading them, you need to use the absolute path:</p>
<pre><code>    URL fxmlResource = getClass().getResource(&quot;/org/jamesd/examples/resourcedemo/fxml/MainView.fxml&quot;);
</code></pre>
<h2>
Maven (and similar) standard layouts</h2>
<p>Maven and other dependency management and build tools recommend a <em>source</em> folder layout in which resources are separated from Java source files. The Maven layout version of the previous example looks like:</p>
<p><a href=""https://i.stack.imgur.com/JW08B.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/JW08B.png"" alt=""enter image description here"" /></a></p>
<p>It is important to understand how this is built to assemble the application:</p>
<ul>
<li><code>*.java</code> files in the <em>source</em> folder <code>src/main/java</code> are compiled to class files, which are deployed to the build folder or jar file.</li>
<li>Resources in the <em>resource</em> folder <code>src/main/resources</code> are <em>copied</em> to the build folder or jar file.</li>
</ul>
<p>In this example, because the resources are in folders that correspond to subpackages of the packages where the source code is defined, the resulting build (which, by default with Maven, is in <code>target/classes</code>) consists of a single structure.</p>
<p>Note that both <code>src/main/java</code> and <code>src/main/resources</code> are considered the root for the corresponding structure in the build, so only their content, not the folders themselves, are part of the build. In other words, there is no <code>resources</code> folder available at runtime. The build structure is shown below in the &quot;troubleshooting&quot; section.</p>
<p>Notice that the IDE in this case (Eclipse) displays the <code>src/main/java</code> source folder differently to the <code>src/main/resources</code> folder; in the first case it displays <em>packages</em>, but for the resource folder it displays <em>folders</em>. Make sure you know if you are creating packages (whose names are <code>.</code>-delimited) or folders (whose names must not contain <code>.</code>, or any other character not valid in a Java identifier) in your IDE.</p>
<h2>
Troubleshooting</h2>
<p>If you get errors you do not expect, first check the following:</p>
<ul>
<li>Make sure you are not using invalid names for your resources. This includes using <code>.</code> or <code>..</code> in the resource path.</li>
<li>Make sure you are using relative paths where expected, and absolute paths where expected. for <code>Class.getResource(...)</code> the path is absolute if it has a leading <code>/</code>, and relative otherwise. For <code>ClassLoader.getResource(...)</code>, the path is always absolute, and <strong>must not</strong> start with a <code>/</code>.</li>
<li>Remember that absolute paths are defined relative to the <em>classpath</em>. Typically the root of the classpath is the union of all source and resource folders in your IDE.</li>
</ul>
<p>If all this seems correct, and you still see errors, check the <em>build</em> or deployment folder. The exact location of this folder will vary by IDE and build tool. If you are using Maven, by default it is <code>target/classes</code>. Other build tools and IDEs will deploy to folders named <code>bin</code>, <code>classes</code>, <code>build</code>, or <code>out</code>.</p>
<p>Often, your IDE will not show the build folder, so you may need to check it with the system file explorer.</p>
<p>The combined source and build structure  for the Maven example above is</p>
<p><a href=""https://i.stack.imgur.com/qX18M.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qX18M.png"" alt=""enter image description here"" /></a></p>
<p>If you are generating a jar file, some IDEs may allow you to expand the jar file in a tree view to inspect its contents. You can also check the contents from the command line with <code>jar tf file.jar</code>:</p>
<pre class=""lang-none prettyprint-override""><code>$ jar -tf resource-demo-0.0.1-SNAPSHOT.jar 
META-INF/
META-INF/MANIFEST.MF
org/
org/jamesd/
org/jamesd/examples/
org/jamesd/examples/resourcedemo/
org/jamesd/examples/resourcedemo/images/
org/jamesd/examples/resourcedemo/style/
org/jamesd/examples/resourcedemo/fxml/
org/jamesd/examples/resourcedemo/images/so-logo.png
org/jamesd/examples/resourcedemo/style/main-style.css
org/jamesd/examples/resourcedemo/Controller.class
org/jamesd/examples/resourcedemo/fxml/MainView.fxml
org/jamesd/examples/resourcedemo/App.class
module-info.class
META-INF/maven/
META-INF/maven/org.jamesd.examples/
META-INF/maven/org.jamesd.examples/resource-demo/
META-INF/maven/org.jamesd.examples/resource-demo/pom.xml
META-INF/maven/org.jamesd.examples/resource-demo/pom.properties
$ 
</code></pre>
<p>If the resources are not being deployed, or are being deployed to an unexpected location, check the configuration of your build tool or IDE.</p>
<h2>Example image loading troubleshooting code</h2>
<p>This code is deliberately more verbose than is strictly necessarily to facilitate adding additional debugging information for the image loading process.  It also uses System.out rather than a logger for easier portability.</p>
<pre><code>String resourcePathString = &quot;/img/wumpus.png&quot;;
Image image = loadImage(resourcePathString);

// ...

private Image loadImage(String resourcePathString) {
    System.out.println(&quot;Attempting to load an image from the resourcePath: &quot; + resourcePathString);
    URL resource = HelloApplication.class.getResource(resourcePathString);
    if (resource == null) {
        System.out.println(&quot;Resource does not exist: &quot; + resourcePathString);

        return null;
    }

    String path = resource.toExternalForm();
    System.out.println(&quot;Image path: &quot; + path);

    Image image = new Image(path);
    System.out.println(&quot;Image load error?  &quot; + image.isError());
    System.out.println(&quot;Image load exception? &quot; + image.getException());

    if (!image.isError()) {
        System.out.println(&quot;Successfully loaded an image from &quot; + resourcePathString);
    }

    return image;
}
</code></pre>
<h2>External Tutorial Reference</h2>
<p>A useful external tutorial for resource location is Eden coding's tutorial:</p>
<ul>
<li><a href=""https://edencoding.com/where-to-put-resource-files-in-javafx/"" rel=""noreferrer"">Where to put resource files in JavaFX</a>.</li>
</ul>
<p>The nice thing about the Eden coding tutorial is that it is comprehensive.  In addition to covering the information on lookups from Java code which is in this question.  The Eden tutorial covers topics such as locating resources that are encoded as urls in CSS, or resource references in FXML using an <code>@</code> specifier or <code>fx:include</code> element (which are topics currently not directly covered in this answer).</p>
","2189127","","1155209","","2022-03-23 22:56:52","2022-03-23 22:56:52","","","","9","","","2020-04-30 19:32:24","CC BY-SA 4.0"
"61534738","2","","61521819","2020-04-30 23:53:09","","10","","<blockquote>
  <p>Do any / all real modern systems trigger an SMI on every store to the text-mode framebuffer?</p>
</blockquote>

<p>For video cards, I very much doubt it. Video card manufacturers have had the ""get pixel data from char+attribute"" logic built into hardware since the 1980s (it predates VGA and hasn't changed much since CGA), and just cut&amp;paste that logic into each newer design without caring much about it.</p>

<p>For things that are not video cards at all (e.g. remote system management tools using LAN) I don't know but suspect not (often they use a special management CPU rather than the main CPU/s so that it works even if the computer is turned ""off"").</p>

<blockquote>
  <p>If no, can we approximate a WC store+clflush to the framebuffer, using a movnti + something in user-space on WB memory?</p>
</blockquote>

<p>If you're not in user-space, you can change MTTRs (on all CPUs - MTRRs must match and there's a special sequence involved) to make an area of RAM ""uncached""; or use PAT in the page tables (much easier than messing with MTRRs, especially if you're using paging anyway, but slightly different behavior due to still needing cache coherency). If you are in user-space then you will have to rely on whatever the OS/kernel provides, and (depending on which OS it is) the OS/kernel may not provide any way to do this at all.</p>

<p>However; even if you find a way to make (an area of) RAM uncached it still won't be very similar, because you'll be writing directly to something attached to a memory controller built into the CPU (that CPU can write to extremely quickly) instead of talking to something at the other end of a PCI link (that will have higher latency and lower bandwidth from CPU's side). Even for integrated video (where it's technically the same RAM chips in the end) writes to VRAM go through a very different path (subject to remapping/GART/paging in the video card, effected by a ""write mode"" VGA register, effected by bit/plane mask VGA registers, etc).</p>

<blockquote>
  <p>Would a PCIe or PCI video card with hardware VGA textmode be faster than whatever integrated GPUs actually do?</p>
</blockquote>

<p>For writes from CPU to VRAM; typically integrated video is significantly faster than discrete cards (at least for plain writes from CPU to linear frame buffers where none of the VGA's ""write logic"" is involved).</p>

<p>For extremely rough ballpark estimates; I'd expect a single write to RAM to be around 150 cycles and a single write to PCI to be close to 1000 cycles. For SMI I'd expect a few hundred cycles of latency before SMI arrives at CPU, then the cost of CPU pipeline flush, then about 500 cycles to save CPU's state (and same loading state on the return path); then the firmware's code would have to find the cause of the SMI (another few hundred cycles?) before it could know it was a write to VRAM and not something else; then it'd have to examine the saved CPU state and find and decode the instruction that made the write (because it can't know what data was being written, if it was a byte/word/dword write, etc) while taking into account previous CPU state (which mode CPU was in, code size, etc) and keeping track of how emulating the instruction effects the future CPU state (advancing RIP, etc - don't forget that they'll be emulating every instruction that can cause a write, including things like <code>XADD</code>, etc). Next it would have to analyze the state of (emulated) VGA registers (write mode, write mask, plane enable, whatever controls which 64 KiB bank is mapped into the legacy area, font height, ...). Basically; for SMI emulation of a write to text mode frame buffer; I'd expect it to take tens of thousands of cycles before the firmware's code overlooks a minor but important detail buried among a huge amount of complexity, causing it to do the wrong thing and be unusably broken.</p>

<p><strong>Other Notes</strong></p>

<blockquote>
  <p>I found Phoenix BIOS's patent US20120159520 from 2011, Emulating legacy video using uefi.</p>
</blockquote>

<p>I doubt this was ever implemented, because I doubt it can ever work. There's far too many (common and obscure) things you can do with the legacy interfaces (e.g. detect vertical refresh, setup non-standard video modes like ""mode X"", fiddle with ""display start"" to implement smooth scrolling and/or page flipping, use ""CRTC info"" in VBE to alter video timings, etc) that isn't supported by UEFI and can't be done via. a third party video driver for UEFI.</p>

<p>Instead, video card manufacturers didn't bother providing UEFI drivers for about 10 years and UEFI firmware used the legacy interface to emulate UEFI services (often breaking secure boot while they were at it); until almost everything was UEFI anyway.</p>

<blockquote>
  <p>I assume it (SMM) is used for VGA I/O ports for mode-setting.</p>
</blockquote>

<p>I assume not. The only thing vaguely related to video that I'd suspect SMM may be used for is controlling the brightness of the screen's backlight in laptops (especially for older laptops, and especially for ""lid open/close events"") during early boot (before OS takes over).</p>

<blockquote>
  <p>.. leaving out HW support for text mode seems like something vendors might want to do</p>
</blockquote>

<p>I still believe that the (eventual, after the already too long ""hybrid BIOS+UEFI"" transition phase) removal of 30+ years of accumulated legacy mess (A20, VGA, PS/2, PIT, PIC, ...) from hardware is one of the main reasons hardware manufacturers (Intel) are/have been pushing for UEFI adoption.</p>
","559737","","","","","2020-04-30 23:53:09","","","","3","","","","CC BY-SA 4.0"
"61550413","2","","61521819","2020-05-01 20:37:13","","6","","<p>Reading through various modern Intel CPU and Platform Controller Hub (PCH) datasheets, it doesn't appear that the necessary hardware is implemented.  There doesn't seem to be any way to generate an SMI (System Management Interrupt) in response to processor accesses of the VGA frame buffer (physical addresses 0xA0000 - 0xBFFFF).</p>

<p>The memory controller in the CPU will either route accesses to VGA frame buffer to the integrated graphics controller, the PCI Express port connected directly to the CPU, or the DMI interface connecting the CPU to the PCH.  While it's possible route parts VGA frame buffer separately, this appears only meant to support a separate MDA (Monochrome Display Adapter) device. The integrated graphics controller is not well documented so it's possible that it can be configured to generate an SMI on VGA frame buffer accesses, but this seems unlikely.  In any case, it wouldn't work with discrete graphics. </p>

<p>Intel PCH's also don't seem to have any support for generating SMIs in response to VGA frame buffer accesses.  This would be the most natural place for it, as it already has support for generating SMIs in response to I/O accesses to the keyboard controller, IDE controller and other legacy devices. It possible that there's some undocumented feature that does this, but it's not included in the lists of possible SMI sources given in the PCH datasheets.</p>

<p>Theoretically, it would be possible for a motherboard manufacture to connect a fake VGA device to the PCH through a PCI Express port and then generate SMIs using a PCH GPIO pin. However, I'm not sure this will work in practice.  By the time the CPU gets the SMI it could have moved on to executing other instructions and it wouldn't be possible to examine the CPU state at the time of the frame buffer access.</p>

<p>(A similar problem happened with SoundBlaster 16 emulation on the SoundBlaster Live. It would generate a PCI SERR# when the legacy SoundBlaster ports were accessed, which would generate a NMI on the CPU. Unfortunately the emulation would break on many Pentium 4 motherboards because the NMI would arrive on the next or subsequent instruction.)</p>
","3826372","","","","","2020-05-01 20:37:13","","","","2","","","","CC BY-SA 4.0"
"61781240","2","","61772822","2020-05-13 17:39:38","","5","","<p>Yes, there is meaning to both parts of the error message. In the case you have at hand, the return value of <code>Symbol()</code> is not iterable, so that's the second option. As an example for the first option, just take something that's not a function:</p>

<pre><code>let NotAFunction = {};  // Or any other object.
for (let val of NotAFunction()) {}
</code></pre>

<p>gives: <code>Uncaught TypeError: NotAFunction is not a function or its return value is not iterable</code>. In this case, clearly, <code>NotAFunction</code> is not a function ;-)</p>

<p>I don't know why there aren't two separate error messages for ""it's not a function at all"" and ""it was a function and it's been called, but its return type wasn't iterable"". Presumably something in the internal logic to implement <code>for..of</code> loops made it prohibitively complicated to have finer-grained error reporting -- so the combined error message simply mentions two possible reasons why the loop didn't work.</p>
","6036428","","","","","2020-05-13 17:39:38","","","","0","","","","CC BY-SA 4.0"
"70964664","2","","69116668","2022-02-03 00:40:06","","-1","","<p>The resolution of the expression is done during compilation, hence the CSxxx compilation errors. So the operator <strong>nameof()</strong> has no effect during runtime.</p>
<p>Plus, it might use <em>.Net Reflection</em> to get the name of the value that you gave as parameter. Therefore to resolve a type via reflection, the compiler needs the &quot;full path&quot; of the member (i.e from the namespace to it).</p>
","18104532","","","","","2022-02-03 00:40:06","","","","1","","","","CC BY-SA 4.0"
"71196073","2","","64545862","2022-02-20 15:53:17","","0","","<p>Version 9 provides a set of compat packages that are API compatible with Version 8. They are intended to be used to make the upgrade to the modular API easier by allowing you to upgrade your app piece by piece. See the Upgrade Guide for more detail.</p>
<p>To access the compat packages, use the subpath compat like so:</p>
<p>// v9 compat packages are API compatible with v8 code</p>
<pre><code>import firebase from 'firebase/compat/app';
import 'firebase/compat/auth';
import 'firebase/compat/firestore';
</code></pre>
","11622827","","","","","2022-02-20 15:53:17","","","","0","","","","CC BY-SA 4.0"
"71507771","2","","69116668","2022-03-17 06:13:11","","1","","<h2>Answer to underlying question</h2>
<p>if you came here for compile-time desision - there is no way at this moment. It is an expected behavior from compilator side as result of expression compilation.</p>
<h3>Quick runtime solution</h3>
<p><code>(typeof(f::SomeCustomClassName)).Name</code> instead of <code>nameof(f::SomeCustomClassName)</code></p>
<h2>Explanation</h2>
<p>Now lets see again to <strong>nameof_expression</strong> <a href=""https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/expressions#11720-nameof-expressions"" rel=""nofollow noreferrer"">(link)</a></p>
<pre class=""lang-cs prettyprint-override""><code>nameof_expression = 'nameof' '(' named_entity ')'
</code></pre>
<p>where <strong>named_entity</strong> is</p>
<pre class=""lang-cs prettyprint-override""><code>named_entity = named_entity_target ('.' identifier type_argument_list?)*
</code></pre>
<p>And lets look again to calling class name.
In common variant without aliases we got:
<code>nameof(SomeCustomClassName)</code> that unfolds to <code>nameof(ConsoleApp1.SomeCustomClassName)</code></p>
<p>That matches <code>named_entity_target.identifier</code>.</p>
<p>But the alias <code>nameof(f::SomeCustomClassName)</code>...</p>
<p>From specification</p>
<pre class=""lang-cs prettyprint-override""><code>named_entity_target
    : simple_name
    | 'this'
    | 'base'
    | predefined_type 
    | qualified_alias_member
    ;
</code></pre>
<p>Is <strong>qualified_alias_member</strong> so <em>named_entity_target = qualified_alias_member</em></p>
<p>So <strong>nameof_expression</strong> unfolds to</p>
<pre class=""lang-cs prettyprint-override""><code>qualified_alias_member ('.' identifier type_argument_list?)*
</code></pre>
<p>Lets have a look to <strong>qualified_alias_member</strong> <a href=""https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/namespaces#138-qualified-alias-member"" rel=""nofollow noreferrer"">(link)</a>:</p>
<pre class=""lang-cs prettyprint-override""><code>qualified_alias_member
    : identifier '::' identifier type_argument_list?
    ;
</code></pre>
<p>According to all of this we have</p>
<pre class=""lang-cs prettyprint-override""><code>identifier '::' identifier ('.' identifier type_argument_list?)*
</code></pre>
<p>That does not match to <code>nameof(f::SomeCustomClassName)</code>
Thats why it is incorrect for compilator.
Thats why it need for <em>dot</em>
<code>nameof(f::SomeCustomClassName.SomeCustomClassName2)</code></p>
<p>it is not a bug. It is miscalculation from expression creators or porposive limitation.</p>
","4905704","","4905704","","2022-03-17 08:20:11","2022-03-17 08:20:11","","","","3","","","","CC BY-SA 4.0"
"73172956","2","","63778276","2022-07-30 04:51:45","","1","","<h3>A real-life example:</h3>
<p>This record</p>
<pre class=""lang-cs prettyprint-override""><code>public record GetAccountHolderParameters([property: JsonProperty(&quot;accountHolderCode&quot;)] string Code, [property: JsonProperty(&quot;showDetails&quot;)] bool ShowDetails);

</code></pre>
<p>or this <strong>preferred syntax</strong> which is better to read</p>
<pre class=""lang-cs prettyprint-override""><code>public record GetAccountHolderParameters(
    [property: JsonProperty(&quot;accountHolderCode&quot;)] string Code,
    [property: JsonProperty(&quot;showDetails&quot;)] bool ShowDetails
);

</code></pre>
<p>is equivalent to</p>
<pre class=""lang-cs prettyprint-override""><code>public class GetAccountHolderParameters
{
    [JsonProperty(PropertyName = &quot;accountHolderCode&quot;)]
    public string Code { get; set; }

    [JsonProperty(PropertyName = &quot;showDetails&quot;)]
    public bool ShowDetails { get; set; }
}
</code></pre>
","4553982","","","","","2022-07-30 04:51:45","","","","0","","","","CC BY-SA 4.0"
"68376414","2","","68332664","2021-07-14 10:31:30","","1","","<p>Ferber explained the reason very well.</p>
<p>Here's an ad-hoc solution (which may not be preferred by everyone, because we are extending types from the standard library):</p>
<pre><code>// RandomAccessCollection ensures fast index creation
extension ReversedCollection where Base: RandomAccessCollection {
  subscript(_ offset: Int) -&gt; Element {
    let index = index(startIndex, offsetBy: offset)
    return self[index]
  }
}

[1, 2, 3].reversed()[0] // 3
</code></pre>
","4133981","","","","","2021-07-14 10:31:30","","","","1","","","","CC BY-SA 4.0"
"71024135","2","","60079472","2022-02-07 19:13:56","","1","","<p>Actually what worked for me for Android 12 to schedule the exact time alarm is adding to your app's AndroidManifest file a permission:</p>
<pre><code>&lt;uses-permission android:name=&quot;android.permission.SCHEDULE_EXACT_ALARM&quot;/&gt;
</code></pre>
<p>And to change the Flag for your PendingIntent:</p>
<pre><code>  val pendingIntent = alarmIntent.let { intent -&gt;
    val flag = if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.S) {
        PendingIntent.FLAG_MUTABLE //this is needed in Android 12
    } else {
        PendingIntent.FLAG_CANCEL_CURRENT
    }
    PendingIntent.getBroadcast(
        context,
        DailyAlarmReceiver.REQUEST_DAILY_NOTIFICATION,
        intent,
        flag
    )
}
</code></pre>
<p>You can also check if the app can schedule the alarm with checking on <em>canScheduleExactAlarms</em>:</p>
<pre><code>val alarmManager: AlarmManager = getSystemService(Context.ALARM_SERVICE) as AlarmManager

if(alarmManager.canScheduleExactAlarms()){
  //schedule the alarm 
}
</code></pre>
","1554363","","","","","2022-02-07 19:13:56","","","","2","","","","CC BY-SA 4.0"
"59692095","2","","59637100","2020-01-11 06:05:13","","11","","<p>You (Matt) probably know at least some of this already, but here are some facts for other readers:</p>
<ul>
<li><p>Swift infers types on one whole statement at a time, but not across statements.</p>
</li>
<li><p>Swift allows type inference to automatically promote an object of type <code>T</code> to type <code>Optional&lt;T&gt;</code>, if necessary to make the statement type-check.</p>
</li>
<li><p>Swift also allows type inference to automatically promote a closure of type <code>(A) -&gt; B</code> to type <code>(A) -&gt; B?</code>. In other words, this compiles:</p>
<pre><code>  let a: (Data) -&gt; UIImage? = { UIImage(data: $0) }
  let b: (Data) -&gt; UIImage?? = a
</code></pre>
<p>This came as a surprise to me. I discovered it while investigating your problem.</p>
</li>
</ul>
<p>Now let's consider the use of <code>assign</code>:</p>
<pre><code>let p0 = Just(Data())
    .compactMap { UIImage(data: $0) }
    .receive(on: DispatchQueue.main)
    .assign(to: \.image, on: self.iv)
</code></pre>
<p>Swift type-checks this entire statement simultaneously. Since <code>\UIImageView.image</code>'s <code>Value</code> type is <code>UIImage?</code>, and <code>self.iv</code>'s type is <code>UIImageView!</code>, Swift has to do two “automatic” things to make this statement type-check:</p>
<ul>
<li><p>It has to promote the closure <code>{ UIImage(data: $0) }</code> from type <code>(Data) -&gt; UIImage?</code> to type <code>(Data) -&gt; UIImage??</code> so that <code>compactMap</code> can strip off one level of <code>Optional</code> and make the <code>Output</code> type be <code>UIImage?</code>.</p>
</li>
<li><p>It has to implicitly unwrap <code>iv</code>, because <code>Optional&lt;UIImageView&gt;</code> has no property named <code>image</code>, but <code>UIImageView</code> does.</p>
</li>
</ul>
<p>These two actions let Swift type-check the statement successfully.</p>
<p>Now suppose we break it into three statements:</p>
<pre><code>let p1 = Just(Data())
    .compactMap { UIImage(data: $0) }
    .receive(on: DispatchQueue.main)
let a1 = Subscribers.Assign(object: self.iv, keyPath: \.image)
p1.subscribe(a1)
</code></pre>
<p>Swift first type-checks the <code>let p1</code> statement. It has no need to promote the closure type, so it can deduce an <code>Output</code> type of <code>UIImage</code>.</p>
<p>Then Swift type-checks the <code>let a1</code> statement. It must implicitly unwrap <code>iv</code>, but there's no need for any <code>Optional</code> promotion. It deduces the <code>Input</code> type as <code>UIImage?</code> because that is the <code>Value</code> type of the key path.</p>
<p>Finally, Swift tries to type-check the <code>subscribe</code> statement. The <code>Output</code> type of <code>p1</code> is <code>UIImage</code>, and the <code>Input</code> type of <code>a1</code> is <code>UIImage?</code>. These are different, so Swift cannot type-check the statement successfully. Swift does not support <code>Optional</code> promotion of generic type parameters like <code>Input</code> and <code>Output</code>. So this doesn't compile.</p>
<p>We can make this type-check by forcing the <code>Output</code> type of <code>p1</code> to be <code>UIImage?</code>:</p>
<pre><code>let p1: AnyPublisher&lt;UIImage?, Never&gt; = Just(Data())
    .compactMap { UIImage(data: $0) }
    .receive(on: DispatchQueue.main)
    .eraseToAnyPublisher()
let a1 = Subscribers.Assign(object: self.iv, keyPath: \.image)
p1.subscribe(a1)
</code></pre>
<p>Here, we force Swift to promote the closure type. I used <code>eraseToAnyPublisher</code> because otherwise <code>p1</code>'s type is too ugly to spell out.</p>
<p>Since <code>Subscribers.Assign.init</code> is public, we can also use it directly to make Swift infer all the types:</p>
<pre><code>let p2 = Just(Data())
    .compactMap { UIImage(data: $0) }
    .receive(on: DispatchQueue.main)
    .subscribe(Subscribers.Assign(object: self.iv, keyPath: \.image))
</code></pre>
<p>Swift type-checks this successfully. It is essentially the same as the statement that used <code>.assign</code> earlier. Note that it infers type <code>()</code> for <code>p2</code> because that's what <code>.subscribe</code> returns here.</p>
<hr />
<p>Now, back to your keypath-based assignment:</p>
<pre><code>class Thing {
    var iv: UIImageView! = UIImageView()

    func test() {
        let im = UIImage()
        let kp = \UIImageView.image
        self.iv[keyPath: kp] = im
    }
}
</code></pre>
<p>This doesn't compile, with the error <code>value of optional type 'UIImage?' must be unwrapped to a value of type 'UIImage'</code>. I don't know why Swift can't compile this. It compiles if we explicitly convert <code>im</code> to <code>UIImage?</code>:</p>
<pre><code>class Thing {
    var iv: UIImageView! = UIImageView()

    func test() {
        let im = UIImage()
        let kp = \UIImageView.image
        self.iv[keyPath: kp] = .some(im)
    }
}
</code></pre>
<p>It also compiles if we change the type of <code>iv</code> to <code>UIImageView?</code> and optionalize the assignment:</p>
<pre><code>class Thing {
    var iv: UIImageView? = UIImageView()

    func test() {
        let im = UIImage()
        let kp = \UIImageView.image
        self.iv?[keyPath: kp] = im
    }
}
</code></pre>
<p>But it does not compile if we just force-unwrap the implicitly-unwrapped optional:</p>
<pre><code>class Thing {
    var iv: UIImageView! = UIImageView()

    func test() {
        let im = UIImage()
        let kp = \UIImageView.image
        self.iv![keyPath: kp] = im
    }
}
</code></pre>
<p>And it does not compile if we just optionalize the assignment:</p>
<pre><code>class Thing {
    var iv: UIImageView! = UIImageView()

    func test() {
        let im = UIImage()
        let kp = \UIImageView.image
        self.iv?[keyPath: kp] = im
    }
}
</code></pre>
<p>I think this might be a bug in the compiler.</p>
","77567","","77567","","2022-08-03 15:40:43","2022-08-03 15:40:43","","","","4","","","","CC BY-SA 4.0"
"59788538","2","","59787879","2020-01-17 13:39:36","","7","","<p>It would seem to me that gcc and clang are correct. This should not compile. The function parameter from which you'd like <code>T</code> to be deduced becomes a non-deduced context here the moment the argument supplied is an overload set that contains a function template <a href=""https://timsong-cpp.github.io/cppwp/n4659/temp.deduct.type#5.5"" rel=""nofollow noreferrer"">[temp.deduct.type]/5.5</a>:</p>

<blockquote>
  <p>The non-deduced contexts are:</p>
  
  <ul>
  <li>[…]</li>
  <li><p>A function parameter for which argument deduction cannot be done because the associated function argument is a function, or a set of overloaded functions ([over.over]), and one or more of the following apply:</p>
  
  <ul>
  <li>[…]</li>
  <li>the set of functions supplied as an argument contains one or more function templates. </li>
  </ul></li>
  <li>[…]</li>
  </ul>
</blockquote>

<p>Thus, <code>T</code> cannot be deduced and the other overload is not viable due to there being no conversion; exactly what gcc says…</p>
","2064761","","2064761","","2020-01-17 16:16:59","2020-01-17 16:16:59","","","","0","","","","CC BY-SA 4.0"
"59788608","2","","59787879","2020-01-17 13:43:44","","0","","<p>These are two overloaded functions and non-template function is should be selected compare 
to templated function, so f(int x) was selected hence passing a function as an argument
in the function which int must be passed is impossible .
and the below should work. Thanks</p>

<pre><code>void f( void ( *fn )( int ) ){
  fn( 42 );
}
void f( int x ){
    std::cout &lt;&lt; ""f( "" &lt;&lt; x &lt;&lt; "" );\n"";
  }

  int main(){

     f( f );
  }
</code></pre>
","9995428","","","","","2020-01-17 13:43:44","","","","1","","","","CC BY-SA 4.0"
"60344208","2","","60286204","2020-02-21 18:13:37","","0","","<p>Try adding the line below to your Web.Config file. 
Seems like it could have to do with how mobile networks try and compress your packets as they're sent back to the device.</p>

<pre><code>&lt;system.webServer&gt;
   &lt;httpProtocol&gt;
     &lt;customHeaders&gt;
     &lt;add name=""Cache-Control"" value=""no-transform"" /&gt;
     &lt;/customHeaders&gt;
   &lt;/httpProtocol&gt;
&lt;/system.webServer&gt;
</code></pre>

<p>which I believe is the equivalent of adding 
<code>Header set Cache-Control ""no-transform""</code> to your .htaccess file.</p>

<p>If that doesn't work, try adding the following to all pages that should normally be touched during the request.</p>

<pre><code>&lt;% @Language=""VBScript"" %&gt;
&lt;% Response.CacheControl = ""no-transform"" %&gt;
</code></pre>

<p>NOTE: This code must be inserted at the beginning of the page, unless buffering is enabled, because it is modifying the HTTP headers.</p>
","9488697","","9488697","","2020-02-21 20:35:40","2020-02-21 20:35:40","","","","5","","","","CC BY-SA 4.0"
"67083065","2","","67081496","2021-04-13 22:14:37","","4","","<p>dplyr+plyr solution that is in order with all ur bulletpoints (if u consider plyr in the the tidyverse):</p>
<pre><code>data &lt;- data %&gt;% 
  dplyr::mutate(
    x = plyr::mapvalues(x, lookup$old, lookup$new) #Can add , F to remove warnings
  )
</code></pre>
","9274323","","","","","2021-04-13 22:14:37","","","","2","","","","CC BY-SA 4.0"
"67095381","2","","67081496","2021-04-14 16:13:42","","14","","<h2>Benchmarking</h2>
<p>Expanding the original dataset to 10M rows, 15 runs using microbenchmark gave the follow results on my computer:</p>
<p>Note that <code>forcats::fct_recode</code> and <code>dplyr::recode</code> solutions mentioned by the OP have also been included. Neither works with the updated data because the named vector that resolves to <code>. = !</code> will throw an error, which is why results are tested on the original dataset.</p>
<pre><code>data = data.frame(
  id = 1:5,
  x = c(&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;)
)

lookup = data.frame(
  old = c(&quot;A&quot;, &quot;D&quot;),
  new = c(&quot;a&quot;, &quot;d&quot;)
)

set.seed(1)
data &lt;- data[sample(1:5, 1E7, replace = T),]

dt_lookup &lt;- data.table::copy(lookup)

dplyr_coalesce &lt;- function(){
  library(dplyr)
  lookupV &lt;- setNames(lookup$new, lookup$old)
  data %&gt;% 
    dplyr::mutate(x = coalesce(lookupV[ x ], x))
}

datatable_in &lt;- function(){
  library(data.table)
  lookupV &lt;- setNames(lookup$new, lookup$old)
  setDT(dt_data)
  dt_data[ x %in% names(lookupV), x := lookupV[ x ] ]
}

datatable &lt;- function(){
  library(data.table)
  
  setDT(dt_data)
  setDT(dt_lookup)
  
  ## If needed
  # setkey(data,x)
  # setkey(lookup,old)
  
  dt_data[dt_lookup, x:=new, on =.(x=old)]
}

purrr_modify_if &lt;- function(){
  library(dplyr)
  library(purrr)
  lookupV &lt;- setNames(lookup$new, lookup$old)
  data %&gt;% 
    dplyr::mutate(x = modify_if(x, x %in% lookup$old, ~ lookupV[.x]))
}

stringr_str_replace_all_update &lt;- function(){
  library(dplyr)
  library(stringr)
  lookupV &lt;- setNames(lookup$new, do.call(sprintf, list(&quot;^\\Q%s\\E$&quot;, lookup$old)))
  
  data %&gt;% 
    dplyr::mutate(x = str_replace_all(x, lookupV))
}

base_named_vector &lt;- function(){
  lookupV &lt;- c(with(lookup, setNames(new, old)), rlang::set_names(setdiff(unique(data$x), lookup$old)))
  lookupV[data$x]
}

base_ifelse &lt;- function(){
  lookupV &lt;- setNames(lookup$new, lookup$old)
  with(data, ifelse(x %in% lookup$old, lookup$new, x))
}

plyr_mapvalues &lt;- function(){
  library(plyr)
  data %&gt;% 
    dplyr::mutate(x = plyr::mapvalues(x, lookup$old, lookup$new, warn_missing = F))
}

base_match &lt;- function(){
  tochange &lt;- match(data$x, lookup$old, nomatch = 0)
  data$x[tochange &gt; 0] &lt;- lookup$new[tochange]
}

base_local_safe_lookup &lt;- function(){
  lv &lt;- structure(lookup$new, names = lookup$old)
  
  safe_lookup &lt;- function(val) {
    new_val &lt;- lv[val]
    unname(ifelse(is.na(new_val), val, new_val))
  }
  
  safe_lookup(data$x)
}

dplyr_recode &lt;- function(){
  library(dplyr)
  lookupV &lt;- setNames(lookup$new, lookup$old)
  
  data %&gt;%
    dplyr::mutate(x = recode(x, !!!lookupV))
}

base_for &lt;- function(){
  for (i in seq_len(nrow(lookup))) {
    data$x[data$x == lookup$old[i]] = lookup$new[i]
  }
}

datatable_for &lt;- function(){
  library(data.table)
  setDT(dt_data)
  
  for (i in seq_len(nrow(lookup))) {
    dt_data[x == lookup$old[i], x := lookup$new[i]]
  }
}

forcats_fct_recode &lt;- function(){
  library(dplyr)
  library(forcats)
  lookupV &lt;- setNames(lookup$new, lookup$old)
  
  data %&gt;% 
    dplyr::mutate(x = as.character(fct_recode(x, !!!lookupV)))
  
}

datatable_set &lt;- function(){
  library(data.table)
  setDT(dt_data)
  
  tochange &lt;- dt_data[, chmatch(x, lookup$old, nomatch = 0)]
  set(dt_data, i = which(tochange &gt; 0), j = &quot;x&quot;, value = lookup$new[tochange])
}

library(microbenchmark)
bench &lt;- microbenchmark(dplyr_coalesce(),
                        datatable(),
                        datatable_in(),
                        datatable_for(),
                        base_for(),
                        purrr_modify_if(),
                        stringr_str_replace_all_update(),
                        base_named_vector(),
                        base_ifelse(),
                        plyr_mapvalues(),
                        base_match(),
                        base_local_safe_lookup(),
                        dplyr_recode(),
                        forcats_fct_recode(),
                        datatable_set(),
                        times = 15L,
                        setup = dt_data &lt;- data.table::copy(data))

bench$expr &lt;- forcats::fct_rev(forcats::fct_reorder(bench$expr, bench$time, mean))
ggplot2::autoplot(bench)
</code></pre>
<p><a href=""https://i.stack.imgur.com/8nsFY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/8nsFY.png"" alt=""enter image description here"" /></a></p>
<p>Thanks to @Waldi and @nicola for advice implementing <code>data.table</code> solutions in the benchmark.</p>
","6382434","","6382434","","2021-04-19 21:25:05","2021-04-19 21:25:05","","","","3","","","","CC BY-SA 4.0"
"67119629","2","","67081496","2021-04-16 05:35:17","","15","","<p>A direct <code>data.table</code> solution, without <code>%in%</code>.<br />
Depending on the length of the lookup / data tables, adding keys could improve performance substantially, but this isn't the case on this simple example.</p>
<pre><code>library(data.table)

setDT(data)
setDT(lookup)

## If needed
# setkey(data,x)
# setkey(lookup,old)

data[lookup, x:=new, on=.(x=old)]
data 

   id  x
1:  1  a
2:  2  a
3:  3  B
4:  4  C
5:  5  d
6:  6 AA
7:  7  !
</code></pre>
","13513328","","13513328","","2021-04-22 14:44:24","2021-04-22 14:44:24","","","","3","","","","CC BY-SA 4.0"
"67127533","2","","67081496","2021-04-16 14:55:50","","5","","<p>Another option that is clear is to use a <code>for</code>-loop with subsetting to loop through the rows of the <code>lookup</code> table. This will almost always be quicker with <code>data.table</code> because of <a href=""https://cran.r-project.org/web/packages/data.table/vignettes/datatable-secondary-indices-and-auto-indexing.html"" rel=""nofollow noreferrer"">auto indexing</a>, or if you set the key (i.e., <code>?data.table::setkey()</code>) ahead of time. Also, it will--of course--get slower as the lookup table gets longer. I would guess an update-join would be preferred if there is a long lookup table.</p>
<p>Base R:</p>
<pre><code>for (i in seq_len(nrow(lookup))) {
  data$x[data$x == lookup$old[i]] &lt;- lookup$new[i]
}

data$x
# [1] &quot;a&quot;  &quot;a&quot;  &quot;B&quot;  &quot;C&quot;  &quot;d&quot;  &quot;AA&quot; &quot;!&quot; 
</code></pre>
<p>Or the same logic with <code>data.table</code>:</p>
<pre><code>library(data.table)
setDT(data)

for (i in seq_len(nrow(lookup))) {
  data[x == lookup$old[i], x := lookup$new[i]]
}

data$x
# [1] &quot;a&quot;  &quot;a&quot;  &quot;B&quot;  &quot;C&quot;  &quot;d&quot;  &quot;AA&quot; &quot;!&quot; 
</code></pre>
<p><strong>Data</strong>:</p>
<pre><code>data = data.frame(
  id = 1:7,
  x = c(&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;AA&quot;, &quot;.&quot;)
)

lookup = data.frame(
  old = c(&quot;A&quot;, &quot;D&quot;, &quot;.&quot;),
  new = c(&quot;a&quot;, &quot;d&quot;, &quot;!&quot;)
)
</code></pre>
","10112285","","10112285","","2021-04-17 00:30:33","2021-04-17 00:30:33","","","","0","","","","CC BY-SA 4.0"
"67193741","2","","67081496","2021-04-21 10:11:26","","4","","<p>I basically share the same problem. Although <code>dplyr::recode</code> is in the &quot;questioning&quot; life cycle I don't expect it to become deprecated. At some point it might be superseded, but even in this case it should still be usable. Therefore I'm using a wrapper around <code>dplyr::recode</code> which allows the use of named vectors and or two vectors (which could be a lookup table).</p>

<pre class=""lang-r prettyprint-override""><code>library(dplyr)
library(rlang)

recode2 &lt;- function(x, new, old = NULL, .default = NULL, .missing = NULL) {
  
  if (!rlang::is_named(new) &amp;&amp; !is.null(old)) {
    new &lt;- setNames(new, old)
  }
  
  do.call(dplyr::recode,
          c(.x = list(x),
            .default = list(.default),
            .missing = list(.missing),
            as.list(new)))
  
}

data = data.frame(
  id = 1:7,
  x = c(&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;AA&quot;, &quot;.&quot;)
)

lookup = data.frame(
  old = c(&quot;A&quot;, &quot;D&quot;, &quot;.&quot;),
  new = c(&quot;a&quot;, &quot;d&quot;, &quot;!&quot;)
)

# two vectors new / old
data %&gt;% 
  mutate(x = recode2(x, lookup$new, lookup$old))
#&gt;   id  x
#&gt; 1  1  a
#&gt; 2  2  a
#&gt; 3  3  B
#&gt; 4  4  C
#&gt; 5  5  d
#&gt; 6  6 AA
#&gt; 7  7  !

# named vector
data %&gt;% 
  mutate(x = recode2(x, c(&quot;A&quot; = &quot;a&quot;,
                          &quot;D&quot; = &quot;d&quot;,
                          &quot;.&quot; = &quot;!&quot;)))
#&gt;   id  x
#&gt; 1  1  a
#&gt; 2  2  a
#&gt; 3  3  B
#&gt; 4  4  C
#&gt; 5  5  d
#&gt; 6  6 AA
#&gt; 7  7  !
</code></pre>
<p><sup>Created on 2021-04-21 by the <a href=""https://reprex.tidyverse.org"" rel=""nofollow noreferrer"">reprex package</a> (v0.3.0)</sup></p>
","9349302","","","","","2021-04-21 10:11:26","","","","0","","","","CC BY-SA 4.0"
"59866805","2","","59859095","2020-01-22 19:16:31","","12","","<p>In your new 3.7 venv you should have <code>pkg_resources</code> available - <code>setuptools</code> is automatically installed when created. If not, just <code>pip install setuptools</code>.</p>

<p><code>setuptools</code> library code is actually what <code>pip</code> is vendoring to make <code>pip freeze</code> work. But you can just freeze it manually.</p>

<pre><code># in 3.7 runtime...
import pkg_resources
old_site_dir = "".venv/lib/python3.6/site-packages/""
working_set = pkg_resources.WorkingSet([old_site_dir])
for dist in working_set:
    print(dist.as_requirement())
</code></pre>

<p>You can throw that output in a <code>requirements.txt</code> file and likely have a working reconstructed site, no <code>python3.6</code> runtime required.</p>

<p>Note that this method may not be 100% foolproof, because it is possible for projects to declare separate dependency trees for python3.6 and python3.7 by using <em>environment markers</em> in their distribution metadata (see <a href=""https://www.python.org/dev/peps/pep-0508/#environment-markers"" rel=""noreferrer"">PEP 508</a>). It is also possible that items installed in your 3.6 site do not support 3.7 <em>at all</em>. However it is pretty uncommon to see that in a minor version bump between 3.6 and 3.7, so just using the working set should be ""good enough"" in practice.</p>
","674039","","674039","","2020-01-22 20:17:27","2020-01-22 20:17:27","","","","1","","","","CC BY-SA 4.0"
"60627981","2","","60624851","2020-03-11 01:11:15","","10","","<p>It was a topic of conversation on the <a href=""https://gum.co/usingcombine"" rel=""noreferrer"">Using Combine</a> project repo a while back - the whole thread: <a href=""https://github.com/heckj/swiftui-notes/issues/164"" rel=""noreferrer"">https://github.com/heckj/swiftui-notes/issues/164</a>.</p>

<p>The long and short was we made an example that I think does what you want, although it does use <code>catch</code>:</p>

<pre class=""lang-swift prettyprint-override""><code>let resultPublisher = upstreamPublisher.catch { error -&gt; AnyPublisher&lt;String, Error&gt; in
    return Publishers.Delay(upstream: upstreamPublisher,
                            interval: 3,
                            tolerance: 1,
                            scheduler: DispatchQueue.global())
    // moving retry into this block reduces the number of duplicate requests
    // In effect, there's the original request, and the `retry(2)` here will operate
    // two additional retries on the otherwise one-shot publisher that is initiated with
    // the `Publishers.Delay()` just above. Just starting this publisher with delay makes
    // an additional request, so the total number of requests ends up being 4 (assuming all
    // fail). However, no delay is introduced in this sequence if the original request
    // is successful.
    .retry(2)
    .eraseToAnyPublisher()
}
</code></pre>

<p>This is referencing the a <a href=""https://heckj.github.io/swiftui-notes/#patterns-retry"" rel=""noreferrer"">retry pattern I have in the book/online</a>, which is basically what you describe (but wasn't what you asked about).</p>

<p>The <a href=""https://github.com/anechaev"" rel=""noreferrer"">person I was corresponding with on the issue</a> provided a variant in that thread as an extension that might be interesting as well: </p>

<pre class=""lang-swift prettyprint-override""><code>extension Publisher {
  func retryWithDelay&lt;T, E&gt;()
    -&gt; Publishers.Catch&lt;Self, AnyPublisher&lt;T, E&gt;&gt; where T == Self.Output, E == Self.Failure
  {
    return self.catch { error -&gt; AnyPublisher&lt;T, E&gt; in
      return Publishers.Delay(
        upstream: self,
        interval: 3,
        tolerance: 1,
        scheduler: DispatchQueue.global()).retry(2).eraseToAnyPublisher()
    }
  }
}
</code></pre>
","19477","","","","","2020-03-11 01:11:15","","","","4","","","","CC BY-SA 4.0"
"60637050","2","","60624851","2020-03-11 13:20:31","","5","","<p>Using <code>.catch</code> is indeed the answer. We simply make a reference to the data task publisher and use that reference as the head of both pipelines — the outer pipeline that does the initial networking, and the inner pipeline produced by the <code>.catch</code> function.</p>

<p>Let's start by creating the data task publisher <em>and stop</em>:</p>

<pre><code>let pub = URLSession.shared.dataTaskPublisher(for: url).share()
</code></pre>

<p>Now I can form the head of the pipeline:</p>

<pre><code>let head = pub.catch {_ in pub.delay(for: 3, scheduler: DispatchQueue.main)}
    .retry(3)
</code></pre>

<p>That should do it! <code>head</code> is now a pipeline that inserts a delay operator only just in case there is an error. We can then proceed to form the rest of the pipeline, based on <code>head</code>.</p>

<p>Observe that we do indeed change publishers; if there is a failure and the <code>catch</code> function runs, the <code>pub</code> which is the upstream of the <code>.delay</code> becomes the publisher, replacing the <code>pub</code> we started out with. However, they are the same object (because I said <code>share</code>), so this is a distinction without a difference.</p>
","341994","","126855","","2020-03-22 00:10:48","2020-03-22 00:10:48","","","","6","","","","CC BY-SA 4.0"
"62557768","2","","62550828","2020-06-24 14:46:11","","22","","<p>In HotSpot JVM, safepoints (where the JVM can safely stop Java threads) are</p>
<ul>
<li>before the return from a non-inlined method;</li>
<li>at backward branches (i.e. in loops), unless the loop is counted. The loop is counted, if it is known to have finite number of iterations, and the loop variable fits integer type;</li>
<li>at thread state transitions (native -&gt; Java, native -&gt; VM);</li>
<li>in the blocking functions of the JVM runtime.</li>
</ul>
<p>All the above places, except backward branches, imply at least a method call overhead. So,  apparently the cheapest way to put a safepoint is to write a non-counted loop:</p>
<pre><code>public class Safepoint {
    private static volatile int one = 1;

    public static void force() {
        for (int i = 0; i &lt; one; i++) ;
    }
}
</code></pre>
<p><code>volatile</code> guarantees that the loop will not be eliminated by the optimizer, and it will not be treated as counted.</p>
<p>I verified with <code>-XX:+PrintAssembly</code> that the safepoint poll instruction is inserted wherever I call <code>Safepoint.force()</code>. The call itself takes about 1 ns.</p>
<p>However, due to a bug in JDK 8, the existence of safepoint polls does not yet guarantee the correctness of stack traces obtained from a different thread. A native method call sets the last Java frame anchor, and thus &quot;repairs&quot; the stack trace. I guess this was a reason why you chose a native method. The bug was fixed in JDK 9+ though.</p>
<p>BTW, here is a couple of native methods that have lower overhead than <code>Thread.holdsLock</code>:</p>
<pre><code>Thread.currentThread().isAlive()
Runtime.getRuntime().totalMemory()
</code></pre>
<p>As to profiling, the safepoint-based profilers are <a href=""http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html"" rel=""noreferrer"">completely broken in the first place</a>. This is actually a reason why I started <a href=""https://github.com/jvm-profiling-tools/async-profiler"" rel=""noreferrer"">async-profiler</a> project a few years ago. Its goal is to facilitate profiling of Java applications with low overhead and with no safepoint bias.</p>
","3448419","","","","","2020-06-24 14:46:11","","","","8","","","","CC BY-SA 4.0"
"66654459","2","","61772822","2021-03-16 11:35:29","","3","","<p>The for..of operator pass an argument to a variable trough the iterator protocol.</p>
<p>The iterator protocol specifies the needs of <strong>@@iterator</strong> method to work, so, if the function, object or a class doesn't have the Symbol.iterator/Symbol.asyncIterator implemented it will throw this error.</p>
<p>On the first case, the Symbol it's a constant, so it's not iterable. On the second, the value trowed it's a intermediate value, this means that the VM can't do a conversion to a iterable type(arrays, objects, classes or functions with the iterator method), that is, it can't be executed to get a result due to the fact that the for..of is expecting an implementation of the @@iterator method.</p>
<p>The emphasis comes due the fact that iterator is a function that have the @@iterator method. eg:</p>
<pre class=""lang-js prettyprint-override""><code>
const someIterator = {};
someIterator[Symbol.iterator] = function(names) {
    return {
        next() {
            this.index = 0;
            yield names[index];
            this.index = this.index++;
        }
    }
}
</code></pre>
<p>Printing:</p>
<pre><code>{[Symbol.iterator]: [Function (anonymous)]}
</code></pre>
<p>The expected method of an for..of loop is a iterator function. So, the error message will empathize that is expecting a function.</p>
<p>To implement the method, you can do the same thing above, using ES6 classes, or with objects(accessing trough the key), prototype functions, or just a generator.</p>
","1783432","","1783432","","2021-04-21 17:18:44","2021-04-21 17:18:44","","","","0","","","","CC BY-SA 4.0"
"67902834","2","","67888049","2021-06-09 10:57:48","","10","","<p>The default RNG in .NET up to (and including) .NET 5 has known bias and performance issues, most documented here <a href=""https://github.com/dotnet/runtime/issues/23198"" rel=""noreferrer"">https://github.com/dotnet/runtime/issues/23198</a>:</p>
<ul>
<li>A typo in the implementation of Donald E. Knuth's subtractive random number generator with unknown practical effects.</li>
<li>A different modulo (2^32-1 instead of a power of two) with unknown practical effects.</li>
<li><code>Next(0, int.MaxValue)</code> has heavy bias.</li>
<li><code>NextDouble()</code> only produces 2^31 possible values, where it could pick from approx. 2^62 distinct values.</li>
</ul>
<p>This is why .NET 6 implemented a better algorithm (<a href=""https://en.wikipedia.org/wiki/Xorshift#xoshiro256**"" rel=""noreferrer"">xoshiro256**</a>). You will get this better RNG when you instantiate a <code>new Random()</code> instance without a seed. This is described in <a href=""https://github.com/dotnet/runtime/pull/47085"" rel=""noreferrer"">https://github.com/dotnet/runtime/pull/47085</a>. Unfortunately, it's not easy to replace the old RNG when a seed is provided since people might rely on the behavior of the current, biased RNG.</p>
<p>Even though xoshiro256** has some <a href=""https://www.pcg-random.org/posts/a-quick-look-at-xoshiro256.html"" rel=""noreferrer"">documented flaws</a> (and a <a href=""https://www.reddit.com/r/programming/comments/8gx2d3/new_line_of_fast_prngs_released_by_the_author_of/dyqe1u4/"" rel=""noreferrer"">rebuttal</a>) as well, I found it to work pretty well for my purposes. I <a href=""https://github.com/deiruch/Extensions/blob/master/Extensions/Random.cs"" rel=""noreferrer"">have copied</a> the <a href=""https://github.com/dotnet/runtime/blob/main/src/libraries/System.Private.CoreLib/src/System/Random.Xoshiro256StarStarImpl.cs"" rel=""noreferrer"">improved implementation from .NET 6</a> and use that.</p>
<p>Side-note: LINQ queries are lazily evaluated (a.k.a. &quot;deferred execution&quot;). If you use a RNG in the <code>.OrderBy</code> lambda, you might get confusing results if you iterate multiple times, because the order might change every time. Some sorting algorithms rely on the fact that elements won't suddenly change their relative order to work correctly. Returning inconsistent ordering values will break such sorting algorithms. Sure, todays <code>OrderBy</code> implementation in LINQ-to-Objects works fine, but there's no documented guarantee that it has to work with &quot;randomly&quot;-changing values. A reasonable alternative is <code>.OrderBy(e =&gt; HashCode.Combine(0x1337, e))</code>.</p>
","742404","","742404","","2021-06-09 19:31:21","2021-06-09 19:31:21","","","","9","","","","CC BY-SA 4.0"
"60434381","2","","60286204","2020-02-27 13:29:21","","0","","<blockquote>
  <p>It might be caused by browsers not getting correct content-type</p>
  
  <p>Can you add this to your head in the view or layout(if you are using)</p>
</blockquote>

<pre><code>&lt;head&gt;
  &lt;meta http-equiv=""Content-Type"" content=""text/html; charset=utf-8""/&gt;
&lt;/head&gt;
</code></pre>
","5036698","","","","","2020-02-27 13:29:21","","","","0","","","","CC BY-SA 4.0"
"60436565","2","","60286204","2020-02-27 15:26:40","","3","","<p>I finally stumbled upon a fix, although I still do not know why the error does not manifest itself on desktops and mobile WiFi connections. The issue has to do with hosting my web application on IIS using out-of-process mode, and calling <code>UseHttpsRedirection()</code> during the setup.</p>

<p>What happens next is <a href=""https://stackoverflow.com/a/50028655/335858"">described in this answer</a>: IIS, which connects to my out-of-process host (Kestrel) via http, gets redirected, and the browser on my phone somehow detects it. There is also a second redirection (the legitimate one) to the login page, which the phone browser counts as well. Now the phone browser sees two redirections, so it displays an error, because at most one redirection is allowed.</p>

<p>The fix was simply to remove the call to <code>UseHttpsRedirection()</code>. It was unnecessary in out-of-process hosting scenario: IIS front is configured to require https, so clients get redirected anyway.</p>
","335858","","","","","2020-02-27 15:26:40","","","","2","","","","CC BY-SA 4.0"
"60627915","2","","60627249","2020-03-11 01:00:26","","9","","<blockquote>
  <p>The implicit object creation is supposed to happen just once, at the point of <code>malloc</code>; it isn't triggered by the assignment statement in <code>foo</code>.</p>
</blockquote>

<p>That's not relevant. What matters is which object gets created. The standard says that the object which gets created is one which makes something which would have been UB into well-defined code:</p>

<blockquote>
  <p>that operation implicitly creates and starts the lifetime of zero or more objects of implicit-lifetime types ([basic.types]) in its specified region of storage if doing so would result in the program having defined behavior.</p>
</blockquote>

<p>Behavior is ultimately based on runtime execution, not static analysis. So you need only follow the execution of the program until you run into a case where behavior would not be defined, yet would be defined if an object of some type had been created in that storage at the time of the operation in question.</p>

<p>So the location of creation is always ""the operation"", but the determination of what gets created is based on how the memory gets used at runtime (ie: behavior).</p>
","734069","","","","","2020-03-11 01:00:26","","","","1","","","","CC BY-SA 4.0"
"61855132","2","","61841254","2020-05-17 16:29:00","","6","","<p>Using the accepted answer, I wound up with this structure:</p>

<pre><code>head // [Entity]
    .flatMap { entities -&gt; AnyPublisher&lt;Entity, Error&gt; in
        Publishers.Sequence(sequence: entities).eraseToAnyPublisher()
    }.flatMap { entity -&gt; AnyPublisher&lt;Entity, Error&gt; in
        self.makeFuture(for: entity) // [Derivative]
            .flatMap { derivatives -&gt; AnyPublisher&lt;Derivative, Error&gt; in
                Publishers.Sequence(sequence: derivatives).eraseToAnyPublisher()
            }
            .flatMap { derivative -&gt; AnyPublisher&lt;Derivative2, Error&gt; in
                self.makeFuture(for: derivative).eraseToAnyPublisher() // Derivative2
        }.collect().map { derivative2s -&gt; Entity in
            self.configuredEntity(entity, from: derivative2s)
        }.eraseToAnyPublisher()
    }.collect()
</code></pre>

<p>That has exactly the elegant tightness I was looking for! So the idea is: </p>

<p>We receive an array of something, and we need to process each element asynchronously. The old way would have been a DispatchGroup and a <code>for...in</code> loop. The Combine equivalent is:</p>

<ul>
<li><p>The equivalent of the <code>for...in</code> line is <code>flatMap</code> and Publishers.Sequence.</p></li>
<li><p>The equivalent of the DispatchGroup (dealing with asynchronousness) is a further <code>flatMap</code> (on the individual element) and some publisher. In my case I start with a Future based on the individual element we just received.</p></li>
<li><p>The equivalent of the right curly brace at the end is <code>collect()</code>, waiting for all elements to be processed and putting the array back together again.</p></li>
</ul>

<p>So to sum up, the pattern is:</p>

<ol>
<li><code>flatMap</code> the array to a Sequence.</li>
<li><code>flatMap</code> the individual element to a publisher that launches the asynchronous operation on that element.</li>
<li>Continue the chain from that publisher as needed.</li>
<li><code>collect</code> back into an array.</li>
</ol>

<p>By <em>nesting</em> that pattern, we can take advantage of Swift scoping rules to keep the thing we need to process in scope until we have acquired enough information to produce the processed object. </p>
","341994","","341994","","2020-05-25 03:17:58","2020-05-25 03:17:58","","","","5","","","","CC BY-SA 4.0"
"60983361","2","","60982068","2020-04-02 02:31:49","","10","","<p>As you mention, Cloud Build creates a bucket or buckets with multi region because when creating the service in Cloud Run, there are only added the needed flags and arguments to deploy the service.</p>
<p>The <a href=""https://cloud.google.com/sdk/gcloud/reference/builds/submit#--gcs-source-staging-dir"" rel=""noreferrer"">documentation</a> for the command <code>gcloud builds submit</code> mentions the following for the flag <code>--gcs-source-staging-dir</code>:</p>
<blockquote>
<pre><code>--gcs-source-staging-dir=GCS_SOURCE_STAGING_DIR
</code></pre>
<p>A directory in Google Cloud Storage to copy the source used for staging the build. If the specified bucket does not exist, Cloud Build will create one. If you don't set this field, gs://[PROJECT_ID]_cloudbuild/source is used.</p>
</blockquote>
<p>As this flag is not set, the bucket is created in <code>multi-region</code> and in <code>us</code>. This behavior also applies for the flag <a href=""https://cloud.google.com/sdk/gcloud/reference/builds/submit#--gcs-log-dir"" rel=""noreferrer""><code>--gcs-log-dir</code></a>.</p>
<p>Now the necessary steps to use the bucket in the dual-region, region or multi-region you want is using a <code>cloudbuild.yaml</code> and using the flag <code>--gcs-source-staging-dir</code>. You can do the following:</p>
<ol>
<li>Create a bucket in the region, dual-region or multi-region you may want. For example I created a bucket called &quot;example-bucket&quot; in <code>australia-southeast1</code>.</li>
<li>Create a <code>cloudbuild.yaml</code> file. This is necessary to store the artifacts of the build in the bucket you want as mentioned <a href=""https://cloud.google.com/cloud-build/docs/building/store-build-artifacts"" rel=""noreferrer"">here</a>. An example is as follows:</li>
</ol>
<pre class=""lang-yaml prettyprint-override""><code>steps:
- name: 'gcr.io/cloud-builders/gcloud'
    args:
    - 'run'
    - 'deploy'
    - 'cloudrunservice'
    - '--image'
    - 'gcr.io/PROJECT_ID/IMAGE'
    - '--region'
    - 'REGION_TO_DEPLOY'
    - '--platform'
    - 'managed'
    - '--allow-unauthenticated'
artifacts:
    objects:
    location: 'gs://example-bucket'
    paths: ['*']
</code></pre>
<ol start=""3"">
<li>Finally you could run the following command:</li>
</ol>
<pre class=""lang-sh prettyprint-override""><code>gcloud builds submit --gcs-source-staging-dir=&quot;gs://example-bucket/cloudbuild-custom&quot; --config cloudbuild.yaml
</code></pre>
<p>The steps mentioned before can adapted to your script. Please give a try :) and you will see that even if the Cloud Run service is deployed in Asia, Europe or US, the bucket specified before can be in another location.</p>
","12265927","","12265927","","2021-01-26 17:35:57","2021-01-26 17:35:57","","","","5","","","","CC BY-SA 4.0"
"60983841","2","","60982068","2020-04-02 03:31:36","","3","","<p>Looks like this is only possible by doing what you're mentioning in the comments:</p>

<ol>
<li>Create a storage bucket in <code>us-east1</code> as the source bucket (<code>$SOURCE_BUCKET</code>);</li>
<li>Create a Artifact Registry repo in <code>us-east1</code>;</li>
<li>Create the following <code>cloudbuild.yaml</code>:

<pre class=""lang-yaml prettyprint-override""><code>steps:
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'us-east1-docker.pkg.dev/$PROJECT_ID/my-repo/my-image', '.']
images:
- 'us-east1-docker.pkg.dev/$PROJECT_ID/my-repo/my-image'
</code></pre></li>
<li>Deploy with:

<pre><code>$ gcloud builds submit --config cloudbuild.yaml --gcs-source-staging-dir=gs://$SOURCE_BUCKET/source
</code></pre></li>
</ol>

<p>More details here: <a href=""https://cloud.google.com/artifact-registry/docs/configure-cloud-build"" rel=""nofollow noreferrer"">https://cloud.google.com/artifact-registry/docs/configure-cloud-build</a></p>

<p>I think it should at least be possible to specify the Artifact Registry repo with the <code>--tag</code> option and have it be automatically created, but it currently rejects any domain that isn't <code>gcr.io</code> outright.</p>
","328036","","","","","2020-04-02 03:31:36","","","","2","","","","CC BY-SA 4.0"
"62162579","2","","61825087","2020-06-02 22:46:40","","4","","<p>You need to somehow call <a href=""https://learn.microsoft.com/en-us/sql/odbc/reference/syntax/sqlbrowseconnect-function"" rel=""nofollow noreferrer"">SQLBrowseConnect</a> function to get all available parameters of connection string for specific ODBC driver or DSN. Unfortunately, as I can see this call isn’t implemented in R ODBC packages. See documentation and example code at the link for more information.</p>
","4915707","","","","","2020-06-02 22:46:40","","","","5","","","","CC BY-SA 4.0"
"68468786","2","","67749284","2021-07-21 11:36:05","","8","","<p>ad 1. I cannot explain that exactly (haven't looked into the code), but from our (developers) perspective it's like a queue for job requests that takes your apps job quota into account. So basically you can rely on it <strong>if</strong> your app behaves properly battery wise (whatever that means...)</p>
<p>ad 2. Every app gets <strong>some</strong> quota that it cannot exceed. The details of this quota are (and probably always will) an OEM internal implementation detail. As to reaching quota - that's exactly what the <code>OutOfQuotaPolicy</code> flag is for. You can set that if your app reaches its quota - job can run as normal job or it can be dropped</p>
<p>ad 3. That's a mistery. <a href=""https://developer.android.com/about/versions/12/foreground-services"" rel=""noreferrer"">Here</a> we can find vague statement:</p>
<blockquote>
<p>Expedited jobs, new in Android 12, allow apps to execute short, important tasks while giving the system better control over access to resources. These jobs have a set of characteristics somewhere in between a foreground service and a regular JobScheduler job</p>
</blockquote>
<p>Which (as i understand it) means that work manager will be only for short running jobs. So it seems like it won't be ANY official way to launch long running jobs from the background, period. Which (my opinions) is insane, but hey - it is what it is.</p>
<p>What we do know is that it <strong>should</strong> launch right away, but it might get deferred. <a href=""https://developer.android.com/about/versions/12/foreground-services#expedited-jobs-deferred"" rel=""noreferrer"">source</a></p>
<p>ad 4. You cannot run foreground service from the background. So if you need to run a &quot;few minutes task&quot; when app is not in foreground - expedited job will the only way to do it in android 12. Want to run longer task? You need to get your into the foreground. It will probably require you to run job just to show notification that launches activity. Than from activity you can run foreground service! Excited already?</p>
<p>ad 5. On android 12 they won't see a thing. On earlier versions expedited job will fallback to foreground service. You need to override <code>public open suspend fun getForegroundInfo(): ForegroundInfo</code> to do custom notification. I'm not sure what will happen if you don't override that though.</p>
<p>Sample usage (log uploading worker):</p>
<pre><code>@HiltWorker
class LogReporterWorker @AssistedInject constructor(
    @Assisted appContext: Context,
    @Assisted workerParams: WorkerParameters,
    private val loggingRepository: LoggingRepository,
) : CoroutineWorker(appContext, workerParams) {
    override suspend fun doWork(): Result {
        loggingRepository.uploadLogs()
    }

    override suspend fun getForegroundInfo(): ForegroundInfo {
        SystemNotificationsHandler.registerForegroundServiceChannel(applicationContext)
        val notification = NotificationCompat.Builder(
            applicationContext,
            SystemNotificationsHandler.FOREGROUND_SERVICE_CHANNEL
        )
            .setContentTitle(Res.string(R.string.uploading_logs))
            .setSmallIcon(R.drawable.ic_logo_small)
            .setPriority(NotificationCompat.PRIORITY_LOW)
            .build()
        return if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.Q) {
            ForegroundInfo(
                NOTIFICATION_ID,
                notification,
                ServiceInfo.FOREGROUND_SERVICE_TYPE_DATA_SYNC
            )
        } else {
            ForegroundInfo(
                NOTIFICATION_ID,
                notification
            )
        }
    }

    companion object {
        private const val TAG = &quot;LogReporterWorker&quot;
        private const val INTERVAL_HOURS = 1L
        private const val NOTIFICATION_ID = 3562

        fun schedule(context: Context) {
            val constraints = Constraints.Builder()
                .setRequiredNetworkType(NetworkType.UNMETERED)
                .build()
            val worker = PeriodicWorkRequestBuilder&lt;LogReporterWorker&gt;(
                INTERVAL_HOURS,
                TimeUnit.HOURS
            )
                .setConstraints(constraints)
                .setExpedited(OutOfQuotaPolicy.RUN_AS_NON_EXPEDITED_WORK_REQUEST)
                .addTag(TAG)
                .build()

            WorkManager.getInstance(context)
                .enqueueUniquePeriodicWork(TAG, ExistingPeriodicWorkPolicy.REPLACE, worker)
        }
    }
}
</code></pre>
","939133","","939133","","2021-08-02 14:18:59","2021-08-02 14:18:59","","","","19","","","","CC BY-SA 4.0"
"69766795","2","","67749284","2021-10-29 09:45:51","","8","","<p>Conceptually Foreground Services &amp; Expedited Work are not the same thing.</p>
<p>Only a <code>OneTimeWorkRequest</code> can be run expedited as these are time sensitive. Any Worker can request to be run in the foreground. That might succeed depending on the app's foreground state.</p>
<p>A <code>Worker</code> can try to run its work in the foreground using <code>setForeground[Async]()</code> like this from WorkManager 2.7 onwards:</p>
<pre class=""lang-kotlin prettyprint-override""><code>class DownloadWorker(context: Context, parameters: WorkerParameters) :
    CoroutineWorker(context, parameters) {

    override suspend fun getForegroundInfo(): ForegroundInfo {
        TODO()
    }

    override suspend fun doWork(): Result {
        return try {
            setForeground(getForegroundInfo())
            Result.success()
        } catch(e: ForegroundServiceStartNotAllowedException) {
            // TODO handle according to your use case or fail.
            Result.fail()
        }
    }
}


</code></pre>
<p>You can request a <code>WorkRequest</code> to be run ASAP by using <code>setExpedited</code> when building it.</p>
<pre><code>val request = OneTimeWorkRequestBuilder&lt;SendMessageWorker&gt;()
    .setExpedited(OutOfQuotaPolicy.RUN_AS_NON_EXPEDITED_WORK_REQUEST)
    .build()


WorkManager.getInstance(context)
    .enqueue(request)
</code></pre>
<p>On Android versions before 12 expedited jobs will be run as a foreground service, showing a notification. On Android 12+ the notification might not be shown.</p>
<p><a href=""https://i.stack.imgur.com/ZW5Gw.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ZW5Gw.png"" alt=""Diagram of when to use Foreground Services &amp; Expedited Jobs"" /></a></p>
","422060","","","","","2021-10-29 09:45:51","","","","7","","","","CC BY-SA 4.0"
"59603246","2","","59603086","2020-01-05 19:04:55","","1","","<blockquote>
  <p>that is; in reality I'm not aware of mainstream implementations that
  will actually raise hell over comparing arbitrary pointers.</p>
</blockquote>

<p>Depends on what <em>hell</em> means. Hell isn't just crashing right away or scrambling memory with random data. It could be giving indeterminate results to what should be a deterministic function.</p>

<p>GCC was known to optimize pointer comparisons on objects known to point to related (virtual) (sub) objects of different complete objects A and B: anything based on <code>&amp;A</code> would compare differently to anything based on <code>&amp;B</code>, even <code>&amp;A+1</code>, even when the address were actually the same. I don't know if that was observed in C or in C++, but your question is pretty much C/C++ (and applies to <code>qsort</code> too).</p>

<p>That is, the result of a pointer comparison would depend on the known origin of a pointer. That mean that depending on optimization level, inlining context, translation unit, etc. a comparison could give different results.</p>

<p>So yes it could break down on at least some versions of a popular compiler if you did these pointer comparisons. </p>

<p>Which you don't as <code>std::map</code> is not defined in term <code>operator&lt;</code> but in term of <code>std::less</code>.</p>
","963864","","","","","2020-01-05 19:04:55","","","","1","","","","CC BY-SA 4.0"
"59725362","2","","59724711","2020-01-13 22:53:42","","5","","<p>An array of unknown size is incomplete:</p>

<blockquote>
  <p>An array type of unknown size is an incomplete type. It is completed, for an identifier of that type, by specifying the size in a later declaration (with internal or external linkage).</p>
</blockquote>

<p>The type <code>int (*)[]</code> however is not incomplete: It's a pointer of an array of <code>int</code> of unknown size.<br>
And a pointer has a well known size:</p>

<pre><code>printf (""Size %d\n"", sizeof(int (*)[]));
</code></pre>

<blockquote>
  <p>6.2.5/23: A type has known constant size if the type is not incomplete and is not a variable length array type.</p>
</blockquote>

<p>Furthermore you can even dereference it, thanks to the array semantics: </p>

<pre><code>typedef int (*T)[];
...
int a[10];
for (int i=0; i&lt;10; i++) a[i]=i;
T p=a;
for (int i=0; i&lt;10; i++) printf (""%d "",(*p)[i]);
printf (""\n"");
</code></pre>

<h3>Edit</h3>

<p>In addition, a pointer is always a complete type.  It's written black on white in 6.2.5/20:</p>

<blockquote>
  <p>A pointer type may be derived from a function type or an object type,
  called the referenced type. A pointer type describes an object whose
  value provides a reference to an entity of the referenced type. A
  pointer type derived from the referenced type T is sometimes called
  ‘‘pointer to T’’. The construction of a pointer type from a referenced
  type is called ‘‘pointer type derivation’’. <strong>A pointer type is a
  complete object type.</strong></p>
</blockquote>
","3723423","","3204551","","2020-01-13 23:06:21","2020-01-13 23:06:21","","","","10","","","","CC BY-SA 4.0"
"61968621","2","","61841254","2020-05-23 07:06:49","","14","","<p>With your latest edit and this comment below:</p>
<blockquote>
<p>I literally am asking is there a Combine equivalent of &quot;don't proceed to the next step until this step, involving multiple asynchronous steps, has finished&quot;</p>
</blockquote>
<p>I think this pattern can be achieved with <code>.flatMap</code> to an array publisher (Publishers.Sequence), which emits one-by-one and completes, followed by whatever per-element async processing is needed, and finalized with a <code>.collect</code>, which waits for all elements to complete before proceeding</p>
<p>So, in code, assuming we have these functions:</p>
<pre><code>func getFoos() -&gt; AnyPublisher&lt;[Foo], Error&gt;
func getPartials(for: Foo) -&gt; AnyPublisher&lt;[Partial], Error&gt;
func getMoreInfo(for: Partial, of: Foo) -&gt; AnyPublisher&lt;MoreInfo, Error&gt;
</code></pre>
<p>We can do the following:</p>
<pre><code>getFoos()
.flatMap { fooArr in 
    fooArr.publisher.setFailureType(to: Error.self)
 }

// per-foo element async processing
.flatMap { foo in

  getPartials(for: foo)
    .flatMap { partialArr in
       partialArr.publisher.setFailureType(to: Error.self)
     }

     // per-partial of foo async processing
    .flatMap { partial in

       getMoreInfo(for: partial, of: foo)
         // build completed partial with more info
         .map { moreInfo in
            var newPartial = partial
            newPartial.moreInfo = moreInfo
            return newPartial
         }
     }
     .collect()
     // build completed foo with all partials
     .map { partialArr in
        var newFoo = foo
        newFoo.partials = partialArr
        return newFoo
     }
}
.collect()
</code></pre>
<p>(Deleted the old answer)</p>
","968155","","968155","","2020-08-18 16:48:45","2020-08-18 16:48:45","","","","17","","","","CC BY-SA 4.0"
"65081791","2","","65080685","2020-11-30 22:02:20","","19","","<p>My apologies for the log spam. If you aren't having issues connecting to a device with WebUSB you can ignore these warnings. They are triggered by Chrome attempting to read properties of USB devices that are currently suspended.</p>
","4275660","","","","","2020-11-30 22:02:20","","","","3","","","","CC BY-SA 4.0"
"65134639","2","","65080685","2020-12-03 21:45:08","","16","","<p>After going through quite a few discussions, documentations and Chromium issues here are the details related to the surfacing of the log message:</p>
<pre><code>[9848:10684:1201/013233.169:ERROR:device_event_log_impl.cc(211)] [01:32:33.170] USB: usb_device_handle_win.cc:1020 Failed to read descriptor from node connection: A device attached to the system is not functioning. (0x1F)
</code></pre>
<hr />
<h2>Details</h2>
<p>It all started with the reporting of <em>chromium</em> issue <a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404"" rel=""noreferrer"">Remove WebUSB's dependency on libusb on Windows</a> as:</p>
<ul>
<li>For Linux (probably Mac as well), both WebUSB notification and communication works correctly (after allowing user access to the device in udev rules).</li>
<li>For Windows, it seems that libusb only works with a non-standard WinUsb driver (<a href=""https://github.com/libusb/libusb/issues/255"" rel=""noreferrer"">https://github.com/libusb/libusb/issues/255</a>).</li>
</ul>
<p>When the hardware is inserted and the VID/PID is unknown to the system, windows 10 correctly loads it's CDC driver for the CDC part and the WinUSB driver (version 10) for the WebUSB part (no red flags).  However, it seems that chrome never finds the device until I manually force an older WinUSB driver (version 6 - probably modified also) on the interface.</p>
<p>The solution was implemented in a step-wise manner as follows:</p>
<ol>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c10"" rel=""noreferrer"">Start supporting some transfers in the new Windows USB backend</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c12"" rel=""noreferrer"">Fix bulk/interrupt transfers in the new Windows USB backend</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c19"" rel=""noreferrer"">[usb] Read BOS descriptors from the hub driver on Windows</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c21"" rel=""noreferrer"">[usb] Collect all composite devices paths during enumeration on Windows</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c22"" rel=""noreferrer"">[usb] Remove out parameters in UsbServiceWin helper functions</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c23"" rel=""noreferrer"">[usb] Support composite devices in the new Windows backend</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c24"" rel=""noreferrer"">[usb] Detect USB functions as Windows enumerates them</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c25"" rel=""noreferrer"">[usb] Support composite devices with multiple functions</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c26"" rel=""noreferrer"">[usb] Hold interface requests until Windows enumerates functions</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c27"" rel=""noreferrer"">[usb] Add direction parameter to ClearHalt</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c28"" rel=""noreferrer"">[usb] Count references to a WINUSB_INTERFACE_HANDLE</a></li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c29"" rel=""noreferrer"">[usb] Implement blocking operations in the Windows backend</a></li>
</ol>
<p>These changes ensured that the new backend was ready to be tested and was available through <a href=""https://stackoverflow.com/questions/47656059/chrome-canary-headless-mode-does-not-work-on-windows10/47674154#47674154"">Chrome Canary</a> and chrome-dev-channel which you can access manually through:</p>
<pre><code>chrome://flags#enable-new-usb-backend
</code></pre>
<p>More change requests were submitted as follows:</p>
<ul>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c33"" rel=""noreferrer"">[usb] Mark calls to SetupDiGetDeviceProperty as potentially blocking</a>: According to hang reports this function performs an RPC call which may take some time to complete. Mark calls with a base::ScopedBlockingCall so that the thread pool knows this task may be busy for a while.</li>
<li><a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c34"" rel=""noreferrer"">variations: Enable NewUsbBackend in field trial testing config</a>: This flag was experimental as beta-channel uses this change configuration as the default for testing.</li>
</ul>
<p>As the experimental launch of the new backend appeared to be stable, finally these configuration was enabled by default so that the chanege rolls out to all users of <a href=""https://developers.google.com/web/updates/2020/11/nic87"" rel=""noreferrer""><strong>Chrome 87</strong></a> through <a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c35"" rel=""noreferrer"">usb: Enable new Windows USB backend by default</a>. <a href=""https://chromium.googlesource.com/chromium/src.git/+/999983a0fd1d3bea655df1f6d6e3bd9e3f3e2feb"" rel=""noreferrer"">Revision</a> / <a href=""https://chromium.googlesource.com/chromium/src/+/999983a0fd1d3bea655df1f6d6e3bd9e3f3e2feb"" rel=""noreferrer"">Commit</a></p>
<p>The idea was once this configuration becomes the default for a few milestones, <em>Chromium Team</em> will start removing the Windows-specific code from the old back-end and remove the flag.</p>
<hr />
<h2>Road Ahead</h2>
<p><em>Chromium Team</em> have already merged the <a href=""https://chromium.googlesource.com/chromium/src.git/+/3182b136ef56eadaf927a2f35446ddb06b133d9e"" rel=""noreferrer"">revision</a>/<a href=""https://crrev.com/3182b136ef56eadaf927a2f35446ddb06b133d9e"" rel=""noreferrer"">commit</a> to <a href=""https://bugs.chromium.org/p/chromium/issues/detail?id=637404#c37"" rel=""noreferrer"">Extend new-usb-backend flag expiration</a> within <strong>Chrome v90</strong> which will be available soon.</p>
<hr />
<h2>Update</h2>
<p>As per <a href=""https://stackoverflow.com/users/4275660/reilly-grant"">@ReillyGrant</a>'s [Committer, WebDriver for Google Chrome] <a href=""https://stackoverflow.com/questions/65080685/usb-usb-device-handle-win-cc1020-failed-to-read-descriptor-from-node-connectio/65081791#comment115197946_65081791"">comment</a> :</p>
<blockquote>
<p><em>...&quot; it would be good to reduce the log level for these messages so they don't appear on the console by default but we haven't landed code to do that yet&quot;...</em></p>
</blockquote>
<hr />
<h2>References</h2>
<p>You can find a couple of relevant detailed discussions in:</p>
<ul>
<li><a href=""https://stackoverflow.com/questions/64927909/failed-to-read-descriptor-from-node-connection-a-device-attached-to-the-system/64928509#64928509"">Failed to read descriptor from node connection: A device attached to the system is not functioning error using ChromeDriver Selenium on Windows OS</a></li>
<li><a href=""https://stackoverflow.com/questions/64940553/failed-to-read-descriptor-from-node-connection-a-device-attached-to-the-system/64947966#64947966"">Failed to read descriptor from node connection: A device attached to the system is not functioning error using ChromeDriver Chrome through Selenium</a></li>
</ul>
","7429447","","7429447","","2020-12-11 10:40:57","2020-12-11 10:40:57","","","","3","","","","CC BY-SA 4.0"
"65573699","2","","65463893","2021-01-05 05:26:32","","2","","<p>I think your instinct about <code>android:allowBackup=false</code> being the culprit is correct. I experienced a similar issue (encrypted shared preferences throwing errors on app update when allowBackup was set to false). In my case I managed to reproduce by installing, logging in (to set the encrypted preference), and then updating to a more recent version of the app and attempting to read the preference. I ended up working around the issue by removing <code>android:allowBackup=false</code></p>
","5482166","","","","","2021-01-05 05:26:32","","","","10","","","","CC BY-SA 4.0"
"66449347","2","","65080685","2021-03-03 01:12:24","","0","","<p>I encounered this problem yesterday,and I has fixed it by update all available windows update.</p>
<p><a href=""https://support.microsoft.com/en-us/windows/what-to-try-if-your-touchscreen-doesn-t-work-f159b366-b3ef-99ad-24a4-31a4c62ab46d"" rel=""nofollow noreferrer"">https://support.microsoft.com/en-us/windows/what-to-try-if-your-touchscreen-doesn-t-work-f159b366-b3ef-99ad-24a4-31a4c62ab46d</a></p>
","5834769","","","","","2021-03-03 01:12:24","","","","0","","","","CC BY-SA 4.0"
"66460490","2","","65967690","2021-03-03 15:52:44","","1","","<p>Well, I tried this code and it works on Android API 29, Samsung Galaxy 20FE:</p>
<pre><code>@TargetApi(Build.VERSION_CODES.LOLLIPOP)
private void triggerStorageAccessFramework() {
    Intent intent = new Intent(Intent.ACTION_OPEN_DOCUMENT_TREE);
    startActivityForResult(intent, REQUEST_CODE_STORAGE_ACCESS);
}

@Override
protected void onActivityResult(int requestCode, int resultCode, Intent data) {
    if (requestCode == REQUEST_CODE_STORAGE_ACCESS) {
        Uri treeUri = null;
        // Get Uri from Storage Access Framework.
        treeUri = data.getData();

        // Persist URI in shared preference so that you can use it later.
        // Use your own framework here instead of PreferenceUtil.
        MySharedPreferences.getInstance(null).setFileURI(treeUri);

        // Persist access permissions.
        final int takeFlags = data.getFlags()
                &amp; (Intent.FLAG_GRANT_READ_URI_PERMISSION | Intent.FLAG_GRANT_WRITE_URI_PERMISSION);
        getContentResolver().takePersistableUriPermission(treeUri, takeFlags);

        createDir(DIR_PATH);


        finish();
    }
}

private void createDir(String path) {
    Uri treeUri = MySharedPreferences.getInstance(null).getFileURI();

    if (treeUri == null) {
        return;
    }

    // start with root of SD card and then parse through document tree.
    DocumentFile document = DocumentFile.fromTreeUri(getApplicationContext(), treeUri);
    document.createDirectory(path);
}
</code></pre>
<p>I'm calling this from a button onClick:</p>
<pre><code>Button btnLinkSd = findViewById(R.id.btnLinkSD);
    btnLinkSd.setOnClickListener(new View.OnClickListener() {
        @Override
        public void onClick(View view) {
            triggerStorageAccessFramework();
        }
    });
</code></pre>
<p>In the UI, I'm pressing &quot;show internal storage&quot;, I navigate to Android directory and press allow. After that, in debugging, if I try to list all files under android I'm getting a list of all directories in Data. If that's what you are looking for.
<a href=""https://i.stack.imgur.com/8dM0j.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8dM0j.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/61bjL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/61bjL.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/zTFIB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zTFIB.png"" alt=""enter image description here"" /></a></p>
<p>And finally, results in debug:
<a href=""https://i.stack.imgur.com/XAm2m.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XAm2m.png"" alt=""enter image description here"" /></a></p>
","8688810","","8688810","","2021-03-03 21:27:40","2021-03-03 21:27:40","","","","7","","","","CC BY-SA 4.0"
"67954900","2","","67954414","2021-06-13 04:34:59","","12","","<p>I think the rule must be that a Task initializer in a MainActor method runs on the main thread.</p>
<p>And all methods of a view controller are MainActor methods by default; plus, I observe that if I declare <code>test2</code> to be <code>nonisolated</code>, its Task operation runs on a background thread instead of the main thread.</p>
<p>My guess, then, is that this is an example of the rule that a Task initializer's operation &quot;inherits&quot; from its context:</p>
<ul>
<li><p><code>test2</code> is a MainActor method; it runs on the main thread, so the Task operation &quot;inherits&quot; that.</p>
</li>
<li><p>But <code>test1</code> is not marked for any special thread. <code>test1</code> <em>itself</em> runs on the main thread, because it is <em>called</em> on the main thread; but it is not <em>marked</em> to run on the main thread. Therefore its Task operation falls back to running on a background thread.</p>
</li>
</ul>
<p>That's my theory, anyway, But I find it curious that this rule is nowhere clearly enunciated in the relevant WWDC videos.</p>
<p>Moreover, even <code>test2</code> is only a MainActor method in a sort of &quot;weak&quot; way. If it were <em>really</em> a MainActor method, you could not be able to call it from a background thread without <code>await</code>. But you can, as this version of the code shows:</p>
<pre><code>func test1() {
    print(&quot;test1&quot;, Thread.isMainThread) // true
    Task {
        print(&quot;test1 task&quot;, Thread.isMainThread) // false
    }
}
class ViewController: UIViewController {
    override func viewDidLoad() {
        super.viewDidLoad()
        test1()
        Task.detached {
            self.test2()
        }
    }

    func test2() {
        print(&quot;test2&quot;, Thread.isMainThread) // false
        Task {
            print(&quot;test2 task&quot;, Thread.isMainThread) // true
        }
    }
}
</code></pre>
<p>I find that truly weird, and I have some difficulty enunciating what rule would govern this relentless context-switching behavior, so I don't regard the matter as settled.</p>
","341994","","341994","","2021-09-22 13:04:10","2021-09-22 13:04:10","","","","6","","","","CC BY-SA 4.0"
"73509287","2","","67954414","2022-08-27 08:00:21","","2","","<p>This is because of how actor isolation and task creation work in swift. Actors have serial executor that processes one task at a time to synchronize mutable state. So any method that is isolated to the actor will run on the actor's executor. And when creating <code>Task</code> with <code>Task.init</code> the newly created task inherits the actor's context (isolated to the parent actor) it was created in (unless you specify a different global actor explicitly when creating task) and then processed by the actor's executor.</p>
<p>What's happening here is your <code>ViewController</code> class and all its methods and properties are <code>MainActor</code> isolated since <code>UIViewController</code> is <code>MainActor</code> isolated and you are inheriting from it. So your <code>test2</code> method is isolated to <code>MainActor</code> and when you are creating a task inside <code>test2</code> the new task inherits the <code>MainActor</code> context and gets executed by <code>MainActor</code> on the main thread.</p>
<p>But this behaves differently from your <code>test1</code> method because your <code>test1</code> method isn't isolated to <code>MainActor</code>. When you are calling <code>test1</code> from <code>viewDidLoad</code> the synchronous part of <code>test1</code> is executed on <code>MainActor</code> as part of the current task but when you are creating a new task is <code>test1</code>, since <code>test1</code> isn't isolated to <code>MainActor</code>, your new task isn't executed on it.</p>
<p>To have the same behavior in <code>test1</code> as <code>test2</code>, you can mark your method to be isolated to <code>MainActor</code> by applying  the <code>@MainActor</code> attribute to function definition:</p>
<pre class=""lang-swift prettyprint-override""><code>@MainActor
func test1() {
    print(&quot;test1&quot;, Thread.isMainThread) // true
    Task {
        print(&quot;test1 task&quot;, Thread.isMainThread) // true
    }
}
</code></pre>
","13225760","","","","","2022-08-27 08:00:21","","","","0","","","","CC BY-SA 4.0"
"62352121","2","","62352043","2020-06-12 20:38:13","","13","","<p>See the <code>Show hints</code> section of <code>Code Vision</code> in Preferences/Settings under <code>Editor</code> &gt; <code>Java</code>. See <a href=""https://www.jetbrains.com/help/idea/inlay-hints-java.html#lenses"" rel=""nofollow noreferrer"">documentation</a>.</p>
<p>You may uncheck the <code>Usages</code> item as it seen in the screenshot.</p>
<p><a href=""https://i.stack.imgur.com/sbtQw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/sbtQw.png"" alt=""enter image description here"" /></a></p>
<p>IntelliJ 2020.2 gains a new third checkbox, <code>Broken usages</code>, along with the <code>Usages</code> &amp; <code>Inheritors</code> items.</p>
<p>Intellij 2022.2 reorganized the inlay hints preferences, so the option is in a different place:</p>
<p><a href=""https://i.stack.imgur.com/umSMs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/umSMs.png"" alt=""enter image description here"" /></a></p>
","2188922","","13317","","2022-08-05 21:09:36","2022-08-05 21:09:36","","","","5","","","","CC BY-SA 4.0"
"63282063","2","","63237657","2020-08-06 10:53:42","","1","","<p>To answer this question I will briefly explain how App Bundle works. Here are main points:</p>
<ul>
<li><p>App Bundle is just a set of all your code a resources packaged into a special format archive.</p>
</li>
<li><p>It is not a built project as you may expect with apk file.</p>
</li>
<li><p>Thus in order Google to distribute it to Play Store it must firstly build it and sign it with release keystore.</p>
</li>
<li><p>You must enroll in app Play App Signing your keystore for Google to be able to sign the app built out of App Bundle.</p>
</li>
</ul>
<p>As it is obvious from the points above - there is not workaround for that and I doubt there will be due to the physical requirements of build process and Google desire of more control over what is going to its store.</p>
<p>Why Google moves to this approach. Mainly because:</p>
<ul>
<li><p>Many developers do not care about app size and resources optimization, thus the build becomes much bigger and slower that it could have been.</p>
</li>
<li><p>Easier security checks.</p>
</li>
<li><p>It allows us to use <a href=""https://developer.android.com/guide/app-bundle/dynamic-delivery"" rel=""nofollow noreferrer"">feature modules</a> in our apps.</p>
</li>
</ul>
<p>So we just need to get ready to changed app publishing.</p>
","9248201","","1839439","","2020-08-06 10:59:17","2020-08-06 10:59:17","","","","2","","","","CC BY-SA 4.0"
"63298314","2","","63237657","2020-08-07 08:42:24","","6","","<p>Just to confirm what the documentation says, it is a requirement to use Play App Signing in order to publish with App Bundles on Google Play.</p>
<p>Source: I am on the Android team at Google.</p>
","1178871","","","","","2020-08-07 08:42:24","","","","1","","","","CC BY-SA 4.0"
"63556918","2","","63550588","2020-08-24 07:58:44","","8","","<p>I modified the function <code>train_cartesian</code> to match the output format of <code>view_scales_from_scale</code> (defined <a href=""https://github.com/tidyverse/ggplot2/blob/master/R/coord-cartesian-.r"" rel=""noreferrer"">here</a>), which seems to work:</p>
<pre><code>train_cartesian &lt;- function(scale, limits, name, given_range = NULL) {
    if (is.null(given_range)) {
        expansion &lt;- ggplot2:::default_expansion(scale, expand = self$expand)
        range &lt;- ggplot2:::expand_limits_scale(scale, expansion,
                                               coord_limits = self$limits[[name]])
    } else {
        range &lt;- given_range
    }
    
    out &lt;- list(
        ggplot2:::view_scale_primary(scale, limits, range),
        sec = ggplot2:::view_scale_secondary(scale, limits, range),
        arrange = scale$axis_order(),
        range = range
    )
    names(out) &lt;- c(name, paste0(name, &quot;.&quot;, names(out)[-1]))
    out
}
</code></pre>
<pre><code>p &lt;- test_data %&gt;%
  ggplot(aes(x=Nsubjects, y = Odds, color=EffectSize)) +
  facet_wrap(DataType ~ ExpType, labeller = label_both, scales=&quot;free&quot;) +
  geom_line(size=2) +
  geom_ribbon(aes(ymax=Upper, ymin=Lower, fill=EffectSize, color=NULL), alpha=0.2)

p + 
  coord_panel_ranges(panel_ranges = list(
    list(x=c(8,64), y=c(1,4)), # Panel 1
    list(x=c(8,64), y=c(1,6)), # Panel 2
    list(NULL),                # Panel 3, an empty list falls back on the default values
    list(x=c(8,64), y=c(1,7))  # Panel 4
  ))
</code></pre>
<p><a href=""https://i.stack.imgur.com/mpVTJ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/mpVTJ.png"" alt=""result"" /></a></p>
<hr>
<h1>Original answer</h1>
<p>I've cheated my way out of a <a href=""https://stackoverflow.com/a/54417358/8449629"">similar problem</a> before.</p>
<pre><code># alternate version of plot with data truncated to desired range for each facet
p.alt &lt;- p %+% {test_data %&gt;%
    mutate(facet = as.integer(interaction(DataType, ExpType, lex.order = TRUE))) %&gt;%
    left_join(data.frame(facet = 1:4,
                         ymin = c(1, 1, -Inf, 1),  # change values here to enforce
                         ymax = c(4, 6, Inf, 7)),  # different axis limits
              by = &quot;facet&quot;) %&gt;%
    mutate_at(vars(Odds, Upper, Lower), list(~ ifelse(. &lt; ymin, ymin, .))) %&gt;%
    mutate_at(vars(Odds, Upper, Lower), list(~ ifelse(. &gt; ymax, ymax, .))) }

# copy alternate version's panel parameters to original plot &amp; plot the result
p1 &lt;- ggplot_build(p)
p1.alt &lt;- ggplot_build(p.alt)
p1$layout$panel_params &lt;- p1.alt$layout$panel_params
p2 &lt;- ggplot_gtable(p1)
grid::grid.draw(p2)
</code></pre>
<p><a href=""https://i.stack.imgur.com/R3OIa.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/R3OIa.png"" alt=""result"" /></a></p>
","8449629","","8449629","","2020-08-24 08:46:22","2020-08-24 08:46:22","","","","1","","","","CC BY-SA 4.0"
"59920635","2","","59918865","2020-01-26 17:01:04","","7","","<p>As already mentioned, the weights are normalized to sum to 1 as can be demonstrated:</p>

<pre><code>&gt; x/sum(x)
[1] 0.15384615 0.38461538 0.38461538 0.07692308
</code></pre>

<p>This matches your simulated tabulated data:</p>

<pre><code>#     1      2      3      4 
#0.1544 0.3839 0.3848 0.0768 
</code></pre>
","322912","","2250190","","2020-01-26 17:26:06","2020-01-26 17:26:06","","","","0","","","","CC BY-SA 4.0"
"59921493","2","","59918865","2020-01-26 18:37:48","","16","","<p>Good question. The docs are unclear on this, but the question can be answered by reviewing the source code.</p>

<p>If you look at the R code, <code>sample</code> always calls another R function, <code>sample.int</code> If you pass in a single number <code>x</code> to <code>sample</code>, it will use <code>sample.int</code> to create a vector of integers less than or equal to that number, whereas if <code>x</code> is a vector, it uses <code>sample.int</code> to generate a sample of integers less than or equal to <code>length(x)</code>, then uses that to subset x.</p>

<p>Now, if you examine the function <code>sample.int</code>, it looks like this:</p>

<pre><code>function (n, size = n, replace = FALSE, prob = NULL, useHash = (!replace &amp;&amp; 
    is.null(prob) &amp;&amp; size &lt;= n/2 &amp;&amp; n &gt; 1e+07)) 
{
    if (useHash) 
        .Internal(sample2(n, size))
    else .Internal(sample(n, size, replace, prob))
}
</code></pre>

<p>The <code>.Internal</code> means any sampling is done by calling compiled code written in C: in this case, it's the function <code>do_sample</code>, defined <a href=""https://github.com/SurajGupta/r-source/blob/a28e609e72ed7c47f6ddfbb86c85279a0750f0b7/src/main/random.c#L461"" rel=""noreferrer"">here in src/main/random.c</a>. </p>

<p>If you look at this C code, <code>do_sample</code> checks whether it has been passed a <code>prob</code> vector. If not, it samples on the assumption of equal weights. If <code>prob</code> exists, the function ensures that it is numeric and not NA. If <code>prob</code> passes these checks, a pointer to the underlying array of doubles is generated and passed to another function in random.c called <code>FixUpProbs</code>, defined <a href=""https://github.com/SurajGupta/r-source/blob/a28e609e72ed7c47f6ddfbb86c85279a0750f0b7/src/main/random.c#LC432"" rel=""noreferrer"">here</a>.</p>

<p>This function examines each member of <code>prob</code> and throws an error if any elements of <code>prob</code> are not positive finite doubles. It then normalises the numbers by dividing each by the sum of all. There is therefore no preference at all for <code>prob</code> summing to 1 inherent in the code. That is, even if <code>prob</code> sums to 1 in your input, the function will still calculate the sum and divide each number by it.</p>

<p>Therefore, the parameter is poorly named. It should be ""weights"", as others here have pointed out. To be fair, the docs only say that <code>prob</code> should be a vector of weights, not absolute probabilities.</p>

<p>So the behaviour of the <code>prob</code> parameter from my reading of the code should be:</p>

<ol>
<li><code>prob</code> can be absent altogether, in which case sampling defaults to equal weights.</li>
<li>If any of <code>prob</code>'s numbers are less than zero, or are infinite, or NA, the function will throw. </li>
<li>An error should be thrown if any of the <code>prob</code> values are non-numeric, as they will be interpreted as <code>NA</code> in the SEXP passed to the C code.</li>
<li><code>prob</code> must have the same length as <code>x</code> or the C code throws</li>
<li>You can pass a zero probability as one or more elements of <code>prob</code> if you have specified <code>replace=T</code>, as long as you have at least one non-zero probability. </li>
<li>If you specify <code>replace=F</code>, the number of samples you request must be less than or equal to the number of non-zero elements in <code>prob</code>. Essentially, <code>FixUpProbs</code> will throw if you ask it to sample with a zero probability. </li>
<li>A valid <code>prob</code> vector will be normalised to sum to 1 and used as sampling weights.</li>
</ol>

<p>As an interesting side effect of this behaviour, this allows you to use odds instead of probabilities if you are choosing between 2 alternatives by setting probs = <code>c(1, odds)</code> </p>
","12500315","","12500315","","2020-01-27 12:20:01","2020-01-27 12:20:01","","","","3","","","","CC BY-SA 4.0"
"73818156","2","","68369058","2022-09-22 16:45:20","","0","","<p>Not sure if you still have this question but I put this line at the top of my first test file and it works in R 4.2.1.</p>
<pre><code>Sys.setenv(NOT_CRAN='skip')
</code></pre>
","2608281","","","","","2022-09-22 16:45:20","","","","0","","","","CC BY-SA 4.0"
"60170134","2","","60127747","2020-02-11 13:38:25","","1","","<p><a href=""https://pubs.opengroup.org/onlinepubs/009695399/basedefs/signal.h.html"" rel=""nofollow noreferrer"">IEEE Std 1003.1 Standard</a> defines SIGFPE as:</p>

<blockquote>
  <p>Erroneous arithmetic operation.</p>
</blockquote>

<p>And doesn't really mention floating point operations. Reasoning behind this is not clearly stated, but here's my take on it.</p>

<p>x86 FPU can operate on both integer and floating point data at the same time with instructions such as <code>FIDIV</code>, thus it would be unclear whether dividing floating poitn data by integer zero would generate a floating or and integer point exception.</p>

<p>Additionally, up to 80486 (which was released the same year as the ISO/ANSI C standard) x86 CPUs did not have floating point capabilities at all, floating point co-processor was a separate chip. Software floating point emulation could be used in place of the chip, but that used CPU's built in ALU (integer arithmetic-logical unit) which would throw integer exceptions. </p>
","12873346","","","","","2020-02-11 13:38:25","","","","1","","","","CC BY-SA 4.0"
"60766868","2","","60330730","2020-03-20 00:15:38","","-3","","<p>The <code>-&gt;</code> doesn't really do much in python. </p>

<pre><code>&gt;&gt;&gt; def foo()-&gt;int:
...     return ""yeet""
...
&gt;&gt;&gt; foo()
'yeet'
</code></pre>

<p>Similarly with denoting types in method signatures:</p>

<pre><code>&gt;&gt;&gt; def bar(a: int):
...     print(a)
...
&gt;&gt;&gt; bar(""yeet"")
'yeet'
</code></pre>

<p>The syntax is really just a means of commenting your code. Conceptually you could implement something of an interface by raising an exception in the constructor.</p>

<pre><code>&gt;&gt;&gt; class foo:
...     def __init__(self):
...             raise()
...     def someFunc(self):
...             return(42)
...
&gt;&gt;&gt; class bar(foo):
...     def __init__(self):
...             self.whatEver = ""idk""
...
&gt;&gt;&gt; a = bar()
&gt;&gt;&gt; a.someFunc()
42
&gt;&gt;&gt; baz = foo()
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""&lt;stdin&gt;"", line 3, in __init__
TypeError: exceptions must derive from BaseException
</code></pre>

<p>However you will not get the benefits of type stringency that you are looking for because python isn't a <s>strongly typed</s> language. <code>Edit: Python doesn't use static typing.</code></p>
","2334254","","2334254","","2020-03-20 00:29:43","2020-03-20 00:29:43","","","","2","","","","CC BY-SA 4.0"
"60766965","2","","60330730","2020-03-20 00:28:38","","10","","<p>You could use a <code>typing.Union</code> but, it sounds like you really want <em>structural typing</em> not nominal. <a href=""https://www.python.org/dev/peps/pep-0544/"" rel=""noreferrer"">Python supports this using <code>typing.Protocol</code></a>, which is a supported part of the python type-hinting system, so <code>mypy</code> will understand it, for example:</p>

<pre><code>import typing

class Fooable(typing.Protocol):
    def foo(self) -&gt; int:
        ...

class One(object):
    def foo(self) -&gt; int:
        return 42


class Two(object):
    def foo(self) -&gt; int:
        return 142


def factory(a: str) -&gt; Fooable:
    if a == ""one"":
        return One()

    return Two()

x = factory('one')
x.foo()
</code></pre>

<p>Note, structural typing fits well with Python's duck-typing ethos. Python's typing system supports both structural and nominal forms.</p>
","5014455","","5014455","","2020-03-20 07:30:01","2020-03-20 07:30:01","","","","2","","","","CC BY-SA 4.0"
"61518029","2","","61517878","2020-04-30 07:27:15","","5","","<p>Slice to get those top N indices and use those to create the final mask -</p>

<pre><code>idx = np.argsort(-arr, kind='mergesort')[:,:N]
mask = np.zeros(arr.shape, dtype=bool)
np.put_along_axis(mask, idx, True, axis=-1)
</code></pre>
","3293881","","","","","2020-04-30 07:27:15","","","","0","","","","CC BY-SA 4.0"
"70252898","2","","69976189","2021-12-06 22:46:26","","0","","<p>This is probably in violation of <a href=""https://timsong-cpp.github.io/cppwp/temp.param#14"" rel=""nofollow noreferrer"">[temp.param] section 14</a>:</p>
<blockquote>
<p>... A template parameter pack of a function template shall not be followed by another template parameter unless that template parameter can be deduced from the parameter-type-list ([dcl.fct]) of the function template or has a default argument ([temp.deduct]). ...</p>
</blockquote>
<p>It includes this example:</p>
<pre class=""lang-cpp prettyprint-override""><code>template&lt;class T1 = int, class T2&gt; class B;     // error

// U can be neither deduced from the parameter-type-list nor specified
template&lt;class... T, class... U&gt; void f() { }   // error
template&lt;class... T, class U&gt; void g() { }      // error
</code></pre>
<p>However, cases like <code>f(T..., U...)</code> are currently accepted by compilers, which see one (or both) parameter packs as empty.</p>
<p>By the the example in <a href=""https://timsong-cpp.github.io/cppwp/temp.param#5"" rel=""nofollow noreferrer"">section 5</a> about type constraints,</p>
<pre class=""lang-cpp prettyprint-override""><code>template&lt;C3&lt;int&gt;... T&gt; struct s5;       // associates (C3&lt;T, int&gt; &amp;&amp; ...)
</code></pre>
<p>the syntax in your example should be &quot;functionally equivalent, but not equivalent&quot; to <code>template&lt;typename... Ls, typename... Ts&gt; requires (Any&lt;Ls,Is&gt; &amp;&amp; ...)</code>. The expansion rules <a href=""https://timsong-cpp.github.io/cppwp/temp.variadic#7"" rel=""nofollow noreferrer"">[temp.variadic]</a> require that <code>Ls</code> and <code>Is</code> have the same size, which is why gcc and MSVC ultimately reject the call in your example. Interestingly, if you use the functionally equivalent syntax, clang does join the other compilers in rejecting it.</p>
","1719926","","","","","2021-12-06 22:46:26","","","","4","","","","CC BY-SA 4.0"
"63568587","2","","63550588","2020-08-24 20:51:59","","6","","<p>Many thanks go to Z.Lin for starting the fix to my question, and that answer certainly helped me get past the errors and learn a more appropriate way of working with <code>ggproto</code> objects.</p>
<p>This answer is posted as more of a flexible method of fixing the underlying problem of per-panel limits within a faceted plot. The major issue I had with my first batch of code was that it relies on the ordering of the facets, which in some of my other (private) use-cases is not always known (well, not <em>controlled</em>) a priori. Because of this, I wanted an unambiguous determination of per-panel limits.</p>
<p>I've changed the function name (and the args) to represent two points: (1) this appears to be mimic/replace <code>coord_cartesian</code>, and (2) I don't know that it will translate to other <code>coord_*</code> functions without adjustment. Comments/patches welcome at my <a href=""https://gist.github.com/r2evans/6057f7995c117bb787495dc14a228d5d"" rel=""noreferrer"">gist</a>.</p>
<p>Up front, a perfect duplication of Z.Lin's results can be had with:</p>
<pre class=""lang-r prettyprint-override""><code>p &lt;- test_data %&gt;%
  ggplot(aes(x = Nsubjects, y = Odds, color=EffectSize)) +
  facet_wrap(DataType ~ ExpType, labeller = label_both, scales = &quot;free&quot;) +
  geom_line(size = 2) +
  geom_ribbon(aes(ymax = Upper, ymin = Lower, fill = EffectSize, color = NULL), alpha = 0.2)

p + coord_cartesian_panels(
  panel_limits = tibble::tribble(
    ~DataType, ~ExpType, ~ymin, ~ymax
  , &quot;A&quot;      , &quot;X&quot;     ,     1,     4
  , &quot;A&quot;      , &quot;Y&quot;     ,     1,     6
  , &quot;B&quot;      , &quot;Y&quot;     ,     1,     7
  )
)
</code></pre>
<p>and gone is the ambiguity (that the original code introduced) of <em>which</em> panel is <em>which</em> argument in the list. Since it uses a <code>data.frame</code> to match (usually <code>merge</code>) with the <code>layout</code> of the plot, the order of rows does not matter.</p>
<p>Notes:</p>
<ol>
<li>the <code>panel_limits</code> fields referenced are: <code>xmin</code>, <code>xmax</code>, <code>ymin</code>, and <code>ymax</code>, on top of whichever faceting variables are desired;</li>
<li>an <code>NA</code> in a particular field (or a missing field) means to use the previously-defined limit;</li>
<li>when <em>all</em> faceting-variables match (between <code>panel_limits</code> and the layout defined by <code>facet_*</code>), the limits are set on individual panels; this one-to-one mapping is the going-in assumption about this function;</li>
<li>when <em>some</em> (but not all) variables match, the limits are set on a subset of panels (e.g., on one axis of the panels, depending on the faceting method);</li>
<li>when no variables match and <code>panel_limits</code> is a single row, then set the limits for all panels indiscriminately; and</li>
<li>faceting rows in <code>panel_limits</code> that match nothing in <code>layout</code> are silently ignored.</li>
</ol>
<p>Errors:</p>
<ul>
<li>any faceting variables in <code>panel_limits</code> that do not exist in the layout (i.e., not specified within <code>facet_*</code>); or</li>
<li>more than one row in <code>panel_limits</code> matches a particular panel.</li>
</ul>
<p>As an extension, this also handles a subset of the faceting variables, so if we want to limit all facets by <code>ExpType</code> only, then</p>
<pre class=""lang-r prettyprint-override""><code># set the limits on panels based on one faceting variable only
p + coord_cartesian_panels(
  panel_limits = tibble::tribble(
    ~ExpType, ~ymin, ~ymax
  , &quot;X&quot;     ,    NA,     4
  , &quot;Y&quot;     ,     1,     5
  )
) + labs(title = &quot;panel_limits, one variable&quot;)

# set the limits on all panels
p + coord_cartesian_panels(
  panel_limits = tibble::tribble(
    ~ymin, ~ymax
  , NA,     5
  )
) + labs(title = &quot;panel_limits, no variables&quot;)
</code></pre>
<p>(The last example seems silly, but if the facets/plots are being built programmatically and it is not guaranteed a priori that there are individual facets, then this will result in a reasonable default behavior, assuming that everything is otherwise unambiguous.)</p>
<hr />
<p>A further extension might allow for an <code>NA</code> in a facet variable to match all, such as</p>
<pre class=""lang-r prettyprint-override""><code># does not work
p + coord_cartesian_panels(
  panel_limits = tibble::tribble(
    ~DataType, ~ExpType, ~ymin, ~ymax
  , &quot;A&quot;      , NA      ,     1,     4
  , NA       , &quot;Y&quot;     ,     1,     6
  )
)
</code></pre>
<p>This would require that <code>merge</code> understand that <code>NA</code> means &quot;all/any&quot;, not a literal <code>NA</code>. I'm not going to extend <code>merge</code> at the moment to handle that, so I'm not going to complicate this function to attempt to do that. If there is a reasonable <code>merge</code> replacement that does this kind of calculus, let me know :-)</p>
<h2><em>Many Thanks</em> to ...</h2>
<ul>
<li><a href=""https://gist.github.com/burchill"" rel=""noreferrer"">burchill</a> for the original effort and <a href=""https://gist.github.com/burchill/d780d3e8663ad15bcbda7869394a348a"" rel=""noreferrer"">gist</a>; and</li>
<li>Z.Lin, for helping to bring the function up to <code>ggplot2-3.3.0</code>.</li>
</ul>
<hr />
<pre class=""lang-r prettyprint-override""><code>UniquePanelCoords &lt;- ggplot2::ggproto(
  &quot;UniquePanelCoords&quot;, ggplot2::CoordCartesian,
  
  num_of_panels = 1,
  panel_counter = 1,
  layout = NULL,
  
  setup_layout = function(self, layout, params) {
    self$num_of_panels &lt;- length(unique(layout$PANEL))
    self$panel_counter &lt;- 1
    self$layout &lt;- layout # store for later
    layout
  },
  
  setup_panel_params =  function(self, scale_x, scale_y, params = list()) {
    train_cartesian &lt;- function(scale, limits, name, given_range = c(NA, NA)) {
      if (anyNA(given_range)) {
        expansion &lt;- ggplot2:::default_expansion(scale, expand = self$expand)
        range &lt;- ggplot2:::expand_limits_scale(scale, expansion, coord_limits = limits)
        isna &lt;- is.na(given_range)
        given_range[isna] &lt;- range[isna]
      }
      out &lt;- list(
        ggplot2:::view_scale_primary(scale, limits, given_range),
        sec = ggplot2:::view_scale_secondary(scale, limits, given_range),
        arrange = scale$axis_order(),
        range = given_range
      )
      names(out) &lt;- c(name, paste0(name, &quot;.&quot;, names(out)[-1]))
      out
    }

    this_layout &lt;- self$layout[ self$panel_counter,, drop = FALSE ]
    self$panel_counter &lt;- 
      if (self$panel_counter &lt; self$num_of_panels) {
        self$panel_counter + 1
      } else 1

    # determine merge column names by removing all &quot;standard&quot; names
    layout_names &lt;- setdiff(names(this_layout),
                            c(&quot;PANEL&quot;, &quot;ROW&quot;, &quot;COL&quot;, &quot;SCALE_X&quot;, &quot;SCALE_Y&quot;))
    limits_names &lt;- setdiff(names(self$panel_limits),
                            c(&quot;xmin&quot;, &quot;xmax&quot;, &quot;ymin&quot;, &quot;ymax&quot;))

    limit_extras &lt;- setdiff(limits_names, layout_names)
    if (length(limit_extras) &gt; 0) {
      stop(&quot;facet names in 'panel_limits' not found in 'layout': &quot;,
           paste(sQuote(limit_extras), collapse = &quot;,&quot;))
    } else if (length(limits_names) == 0 &amp;&amp; NROW(self$panel_limits) == 1) {
      # no panels in 'panel_limits'
      this_panel_limits &lt;- cbind(this_layout, self$panel_limits)
    } else {
      this_panel_limits &lt;- merge(this_layout, self$panel_limits, all.x = TRUE, by = limits_names)
    }

    if (isTRUE(NROW(this_panel_limits) &gt; 1)) {
      stop(&quot;multiple matches for current panel in 'panel_limits'&quot;)
    }

    # add missing min/max columns, default to &quot;no override&quot; (NA)
    this_panel_limits[, setdiff(c(&quot;xmin&quot;, &quot;xmax&quot;, &quot;ymin&quot;, &quot;ymax&quot;),
                                names(this_panel_limits)) ] &lt;- NA

    c(train_cartesian(scale_x, self$limits$x, &quot;x&quot;,
                      unlist(this_panel_limits[, c(&quot;xmin&quot;, &quot;xmax&quot;), drop = TRUE])),
      train_cartesian(scale_y, self$limits$y, &quot;y&quot;,
                      unlist(this_panel_limits[, c(&quot;ymin&quot;, &quot;ymax&quot;), drop = TRUE])))
  }
)

coord_cartesian_panels &lt;- function(panel_limits, expand = TRUE, default = FALSE, clip = &quot;on&quot;) {
  ggplot2::ggproto(NULL, UniquePanelCoords,
                   panel_limits = panel_limits,
                   expand = expand, default = default, clip = clip)
}
</code></pre>
","3358272","","3358272","","2020-08-24 21:47:19","2020-08-24 21:47:19","","","","3","","","","CC BY-SA 4.0"
"63569242","2","","63550588","2020-08-24 21:59:00","","3","","<p>At some point I had a similar problem to this. The result was a slightly more verbose but also more flexible option that can customize many aspects of position scales on a per-facet basis. Due to some technicality it uses the equivalent of <code>scales::oob_keep()</code> as oob arguments on the scales, thereby acting as if the coordinates determined the limits.</p>
<pre><code>library(ggh4x)
library(tidyverse)

p &lt;- test_data %&gt;%
  ggplot(aes(x=Nsubjects, y = Odds, color=EffectSize)) +
  facet_wrap(DataType ~ ExpType, labeller = label_both, scales=&quot;free&quot;) +
  geom_line(size=2) +
  geom_ribbon(aes(ymax=Upper, ymin=Lower, fill=EffectSize, color=NULL), alpha=0.2) +
  facetted_pos_scales(
    x = list(
      scale_x_continuous(limits = c(8, 64)),
      scale_x_continuous(limits = c(64, 8), trans = &quot;reverse&quot;),
      NULL,
      scale_x_continuous(limits = c(8, 64), labels = scales::dollar_format())
    ),
    y = list(
      scale_y_continuous(limits = c(1, 4), guide = &quot;none&quot;),
      scale_y_continuous(limits = c(1, 6), breaks = 1:3),
      NULL,
      scale_y_continuous(limits = c(1, 7), position = &quot;right&quot;)
    )
  )
</code></pre>
<p><a href=""https://i.stack.imgur.com/qKdju.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qKdju.png"" alt=""enter image description here"" /></a></p>
","11374827","","11374827","","2021-02-11 16:32:56","2021-02-11 16:32:56","","","","10","","","","CC BY-SA 4.0"
"64017128","2","","64012057","2020-09-22 20:19:30","","2","","<p>I double-checked the Standard and agree there's nothing requiring shuffle make any guarantees about its use of random numbers. It simply remarks:</p>
<blockquote>
<p>&quot;To the extent that the implementation of this function makes use of random numbers, the object referenced by g shall serve as the implementation’s source of randomness.&quot;.</p>
</blockquote>
<p>So, the remaining question seems to be whether you're interested in
implementation-defined or -observed behaviour for any specific
implementation(s), or will stick to a Standards-compliant portable
solution (e.g. shuffling proxy objects or using an array of
indices)...?</p>
<p>Based on your comments, it seems you're opposed to the array-of-indices suggestion, so below - an implementation of using custom iterators and proxies to shuffle the vectors themselves...</p>
<p>(Not done very carefully - more a proof of concept / illustration, so check carefully before using for anything important....)</p>
<p>The approach requires a <code>move_together</code> object that keeps references to the vectors, and then passes <code>shuffle</code> <code>iterator</code>s that have a pointer to the <code>move_together</code> object and an index in the vectors being processed.  You could arguably simplify this by foregoing the <code>move_together</code> object and having pointers or references to both vectors directly in the iterators.  When the iterators are dereferenced, they return proxy objects that then support <code>swap</code>ping.</p>
<p>It ostensibly works with GCC 10.2 and clang 10, but there could be a different implementation of <code>std::shuffle</code> for another compiler that requires a more fully fleshed out iterator or proxy....</p>
<pre><code>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;random&gt;
#include &lt;string&gt;
#include &lt;algorithm&gt;

template &lt;typename T1, typename T2&gt;
struct move_together;

template &lt;typename T1, typename T2&gt;
struct proxy
{
    const move_together&lt;T1, T2&gt;* p_;
    const size_t i_;
    proxy&amp; operator=(const proxy&amp; rhs);
};

template &lt;typename T1, typename T2&gt;
struct move_together
{
    move_together(std::vector&lt;T1&gt;&amp; v1, std::vector&lt;T2&gt;&amp; v2)
      : v1_(v1), v2_(v2)
    { }
    struct iterator
    {
        using iterator_category = std::random_access_iterator_tag;
        using difference_type = ssize_t;
        using value_type = proxy&lt;T1, T2&gt;;
        using pointer = value_type*;
        using reference = value_type&amp;;

        const move_together* p_;
        size_t i_;
        value_type operator*() { return {p_, i_}; }
        bool operator==(const iterator&amp; rhs) const { return i_ == rhs.i_; }
        bool operator!=(const iterator&amp; rhs) const { return !(*this == rhs); }
        difference_type operator-(const iterator&amp; rhs) const
           { return i_ - rhs.i_; }
        iterator operator+(int distance) const
           { return {p_, i_ + distance}; }
        iterator operator++(int) { auto x = *this; ++i_; return x; }
        iterator&amp; operator++() { ++i_; return *this; }
    };

    iterator begin() { return {this, 0}; }
    iterator end()   { return {this, std::min(v1_.size(), v2_.size())}; }
    std::vector&lt;T1&gt;&amp; v1_;
    std::vector&lt;T2&gt;&amp; v2_;
};

template &lt;typename T1, typename T2&gt;
proxy&lt;T1, T2&gt;&amp; proxy&lt;T1, T2&gt;::operator=(const proxy&lt;T1, T2&gt;&amp; rhs)
{
    p_-&gt;v1_[i_] = rhs.p_-&gt;v1_[rhs.i_];
    p_-&gt;v2_[i_] = rhs.p_-&gt;v2_[rhs.i_];
}

template &lt;typename T1, typename T2&gt;
void swap(proxy&lt;T1, T2&gt; lhs, proxy&lt;T1, T2&gt; rhs) {
    using std::swap;
    swap(lhs.p_-&gt;v1_[lhs.i_], rhs.p_-&gt;v1_[rhs.i_]);
    swap(lhs.p_-&gt;v2_[lhs.i_], rhs.p_-&gt;v2_[rhs.i_]);
}

int main()
{
    std::vector&lt;int&gt; v1{ {1, 2, 3, 4, 5} };
    std::vector&lt;std::string&gt; v2{ {&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;, &quot;five&quot;} };

    std::random_device rd;
    std::mt19937 rng{rd()};

    move_together m{v1, v2};
    std::shuffle(m.begin(), m.end(), rng);

    for (const auto&amp; x : v1) std::cout &lt;&lt; x &lt;&lt; '/';
    std::cout &lt;&lt; '\n';
    for (const auto&amp; x : v2) std::cout &lt;&lt; x &lt;&lt; '/';
    std::cout &lt;&lt; '\n';
}
</code></pre>
","410767","","410767","","2020-09-23 14:08:39","2020-09-23 14:08:39","","","","3","","","","CC BY-SA 4.0"
"65236693","2","","63421086","2020-12-10 14:43:05","","7","","<p>First install webdriver manager using the following command in command prompt opened from the python file path.</p>
<pre><code>pip install webdriver-manager.
</code></pre>
<p>Next open your pycharm tool and go to <code>settings -&gt; project interpreter -&gt;</code> and click on + icon and search for webdriver-manager and install that.</p>
<p>And run the below code:</p>
<pre><code>from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager

driver = webdriver.Chrome(ChromeDriverManager().install()) 
</code></pre>
","14801933","","14095522","","2020-12-10 22:03:07","2020-12-10 22:03:07","","","","0","","","","CC BY-SA 4.0"
"65836870","2","","63421086","2021-01-21 22:44:21","","0","","<p>This worked for me:</p>
<pre><code>python3 -m pip install webdriver-manager
</code></pre>
<p>I'm on windows so I'll leave this incase it helps anyone.</p>
","13203366","","","","","2021-01-21 22:44:21","","","","0","","","","CC BY-SA 4.0"
"66446906","2","","60624851","2021-03-02 20:47:06","","9","","<p>I found a few quirks with the implementations in the accepted answer.</p>
<ul>
<li><p>Firstly the first two attempts will be fired off without a delay since the first delay will only take effect after the second attempt.</p>
</li>
<li><p>Secondly if any one of the retry attempts succeed, the output value will also delayed which seems unnecessary.</p>
</li>
<li><p>Thirdly the extension is not flexible enough to allow the user to decide which scheduler it would like the retry attempts to be dispatched to.</p>
</li>
</ul>
<p>After some tinkering back and forth I ended up with a solution like this:</p>
<pre class=""lang-swift prettyprint-override""><code>public extension Publisher {
    /**
     Creates a new publisher which will upon failure retry the upstream publisher a provided number of times, with the provided delay between retry attempts.
     If the upstream publisher succeeds the first time this is bypassed and proceeds as normal.

     - Parameters:
        - retries: The number of times to retry the upstream publisher.
        - delay: Delay in seconds between retry attempts.
        - scheduler: The scheduler to dispatch the delayed events.

     - Returns: A new publisher which will retry the upstream publisher with a delay upon failure.

     ~~~
     let url = URL(string: &quot;https://api.myService.com&quot;)!

     URLSession.shared.dataTaskPublisher(for: url)
         .retryWithDelay(retries: 4, delay: 5, scheduler: DispatchQueue.global())
         .sink { completion in
             switch completion {
             case .finished:
                 print(&quot;Success 😊&quot;)
             case .failure(let error):
                 print(&quot;The last and final failure after retry attempts: \(error)&quot;)
             }
         } receiveValue: { output in
             print(&quot;Received value: \(output)&quot;)
         }
         .store(in: &amp;cancellables)
     ~~~
     */
    func retryWithDelay&lt;S&gt;(
        retries: Int,
        delay: S.SchedulerTimeType.Stride,
        scheduler: S
    ) -&gt; AnyPublisher&lt;Output, Failure&gt; where S: Scheduler {
        self
            .delayIfFailure(for: delay, scheduler: scheduler)
            .retry(retries)
            .eraseToAnyPublisher()
    }

    private func delayIfFailure&lt;S&gt;(
        for delay: S.SchedulerTimeType.Stride,
        scheduler: S
    ) -&gt; AnyPublisher&lt;Output, Failure&gt; where S: Scheduler {
        self.catch { error in
            Future { completion in
                scheduler.schedule(after: scheduler.now.advanced(by: delay)) {
                    completion(.failure(error))
                }
            }
        }
        .eraseToAnyPublisher()
    }
}
</code></pre>
","2464345","","2464345","","2021-03-03 07:25:01","2021-03-03 07:25:01","","","","2","","","","CC BY-SA 4.0"
"60674700","2","","60644544","2020-03-13 17:14:45","","10","","<p>Looks like executing raw SQL is not priority for EF Core, so up to now (EF Core 3.1) it's providing publicly just few basic limited methods. <code>FromSql</code> requires entity type or <a href=""https://learn.microsoft.com/en-us/ef/core/modeling/keyless-entity-types"" rel=""noreferrer"">keyless entity type</a>, and <code>ExecuteSqlRaw</code> / <code>ExecuteSqlInterpolated</code> are the ""modern"" bridge to ADO.NET <code>ExecuteNonQuery</code> which returns the affected rows.</p>

<p>The good thing is that EF Core is built on top of a public service architecture, so it can be used to add some missing functionalities. For instance, services can be used to build the so called <a href=""https://learn.microsoft.com/en-us/dotnet/api/microsoft.entityframeworkcore.storage.irelationalcommand?view=efcore-3.1"" rel=""noreferrer"">IRelationalCommand</a>, which has all the <code>DbCommand</code> execute methods, in particular <code>ExecuteScalar</code> needed for SQL in question.</p>

<p>Since EF Core model supports sequences, there is also a service for building the <code>IRelationalCommand</code> needed to retrieve the next value (used internally by HiLo value generators). </p>

<p>With that being said, following is a sample implementation of the custom method in question using the aforementioned concepts:</p>

<pre class=""lang-cs prettyprint-override""><code>using System;
using System.Globalization;
using Microsoft.EntityFrameworkCore.Diagnostics;
using Microsoft.EntityFrameworkCore.Infrastructure;
using Microsoft.EntityFrameworkCore.Storage;
using Microsoft.EntityFrameworkCore.Update;

namespace Microsoft.EntityFrameworkCore
{
    public static partial class CustomExtensions
    {
        public static long GetNextSequenceValue(this DbContext context, string name, string schema = null)
        {
            var sqlGenerator = context.GetService&lt;IUpdateSqlGenerator&gt;();
            var sql = sqlGenerator.GenerateNextSequenceValueOperation(name, schema ?? context.Model.GetDefaultSchema());
            var rawCommandBuilder = context.GetService&lt;IRawSqlCommandBuilder&gt;();
            var command = rawCommandBuilder.Build(sql);
            var connection = context.GetService&lt;IRelationalConnection&gt;();
            var logger = context.GetService&lt;IDiagnosticsLogger&lt;DbLoggerCategory.Database.Command&gt;&gt;();
            var parameters = new RelationalCommandParameterObject(connection, null, null, context, logger);
            var result = command.ExecuteScalar(parameters);
            return Convert.ToInt64(result, CultureInfo.InvariantCulture);
        }
    }
}
</code></pre>
","5202563","","5202563","","2020-03-13 19:39:48","2020-03-13 19:39:48","","","","7","","","","CC BY-SA 4.0"
"60916114","2","","60859112","2020-03-29 15:02:16","","1","","<p>I think they mean to suggest to use an <code>Executor</code> instead of a <code>Handler</code>. I don't know of any <code>Executor</code> implementation backed by a <code>Looper</code>.</p>

<blockquote>
  <p>Instead [of a <code>Handler</code>], use an <code>Executor</code> or specify the <code>Looper</code> explicitly, using <code>Looper#getMainLooper</code>, <code>View#getHandler</code>, or similar.</p>
</blockquote>

<p>This is useful when you only need to run a <code>Runable</code>. For example the <a href=""https://developer.android.com/reference/android/hardware/camera2/CameraManager#openCamera(java.lang.String,%20java.util.concurrent.Executor,%20android.hardware.camera2.CameraDevice.StateCallback)"" rel=""nofollow noreferrer"">CameraManager.openCamera()</a> method got an overload with the API level 28.</p>

<blockquote>
  <p>The behavior of this method matches that of <code>openCamera(java.lang.String, StateCallback, android.os.Handler)</code>, except that it uses <code>Executor</code> as an argument instead of <code>Handler</code>.</p>
</blockquote>

<p>If you require a <code>Messenger</code>, you'll always have to provide a <code>Hanlder</code> backed by a <code>Looper</code>, which was resolved by <code>Looper.getMainLooper()</code>, <code>Looper.myLooper()</code> or from a <code>HandlerThread</code>.</p>

<p>Alternatively you could create a <code>Looper</code> and run <a href=""https://developer.android.com/reference/kotlin/android/os/Looper#loop()"" rel=""nofollow noreferrer""><code>loop()</code></a> on it. But this is basically what a <code>HandlerThread</code> does.</p>
","3385212","","3385212","","2020-03-30 06:44:55","2020-03-30 06:44:55","","","","4","","","","CC BY-SA 4.0"
"66466205","2","","65967690","2021-03-03 22:58:12","","24","","<p>Here is how it works in X-plore:</p>
<p>When on <code>Build.VERSION.SDK_INT&gt;=30</code>,
[Internal storage]/Android/data is not accessible, java <code>File.canRead()</code> or <code>File.canWrite()</code> returns false, so we need to switch to alternative file system for files inside of this folder (and possibly also obb).</p>
<p>You already know how Storage access framework works, so I'll just give details about what needs to be done exactly.</p>
<p>You call <code>ContentResolver.getPersistedUriPermissions()</code> to find out if you already have saved permission for this folder. Initially you don't have it, so you ask user for permission:</p>
<p>To request access, use <code>startActivityForResult</code> with <code>Intent(Intent.ACTION_OPEN_DOCUMENT_TREE).putExtra(DocumentsContract.EXTRA_INITIAL_URI, DocumentsContract.buildDocumentUri(&quot;com.android.externalstorage.documents&quot;, &quot;primary:Android&quot;))</code>
Here you set with <code>EXTRA_INITIAL_URI</code> that picker shall start directly on Android folder on primary storage, because we want access to Android folder. When your app will target API30, picker won't allow to choose root of storage, and also by getting permission to Android folder, you can work with both <code>data</code> and <code>obb</code> folders inside, with one permission request.</p>
<p>When user confirms by 2 clicks, in <code>onActivityResult</code> you'll get Uri in data which should be <code>content://com.android.externalstorage.documents/tree/primary%3AAndroid</code>. Make needed checks to verify that user confirmed correct folder. Then call <code>contentResolver.takePersistableUriPermission(uri, Intent.FLAG_GRANT_WRITE_URI_PERMISSION | Intent.FLAG_GRANT_READ_URI_PERMISSION)</code> to save permission, and you're ready.</p>
<p>So we're back to <code>ContentResolver.getPersistedUriPermissions()</code>, which contains list of granted permissions (there may be more of them), the one you've granted above looks like this: <code>UriPermission {uri=content://com.android.externalstorage.documents/tree/primary%3AAndroid, modeFlags=3}</code> (same Uri as you got in <code>onActivityResult</code>). Iterate the list from <code>getPersistedUriPermissions</code> to find uri of interest, if found work with it, otherwise ask user for grant.</p>
<p>Now you want to work with <code>ContentResolver</code> and <code>DocumentsContract</code> using this &quot;tree&quot; uri and your relative path to files inside of Android folder. Here is example to list <code>data</code> folder:
<code>data/</code> is path relative to granted &quot;tree&quot; uri. Build final uri using either <code>DocumentsContract.buildChildDocumentsUriUsingTree()</code> (to list files) or <code>DocumentsContract.buildDocumentUriUsingTree()</code> (for working with individual files), example: <code>DocumentsContract.buildChildDocumentsUriUsingTree(treeUri, DocumentsContract.getTreeDocumentId(treeUri), DocumentsContract.getTreeDocumentId(treeUri)+&quot;/data/&quot;)</code>, you'll get uri=<code>content://com.android.externalstorage.documents/tree/primary%3AAndroid/document/primary%3AAndroid%2Fdata%2F/children</code> suitable for listing files in data folder. Now call <code>ContentResolver.query(uri, ...)</code> and process data in <code>Cursor</code> to get folder listing.</p>
<p>Similar way you work with other SAF functionality to read/write/rename/move/delete/create, which you probably already know, using <code>ContentResolver</code> or methods of <code>DocumentsContract</code>.</p>
<p>Some details:</p>
<ul>
<li>it doesn't need <code>android.permission.MANAGE_EXTERNAL_STORAGE</code></li>
<li>it works on target API 29 or 30</li>
<li>it works only on primary storage, not for external SD cards</li>
<li>for all files inside of data folder, you need to use SAF (java File won't work), just use file hierarchy relative to Android folder</li>
<li>in future Google may patch this hole in their &quot;security&quot; intentions, and this may not work after some security update</li>
</ul>
<hr />
<p>EDIT: sample code, based on Cheticamp <a href=""https://github.com/Cheticamp/SAFWalker"" rel=""noreferrer"">Github sample</a>. The sample shows the content (and file-count) of each of the sub-folders of &quot;Android&quot; folder:</p>
<pre><code>class MainActivity : AppCompatActivity() {
    private val handleIntentActivityResult =
        registerForActivityResult(ActivityResultContracts.StartActivityForResult()) {
            if (it.resultCode != Activity.RESULT_OK)
                return@registerForActivityResult
            val directoryUri = it.data?.data ?: return@registerForActivityResult
            contentResolver.takePersistableUriPermission(
                directoryUri, Intent.FLAG_GRANT_READ_URI_PERMISSION or Intent.FLAG_GRANT_WRITE_URI_PERMISSION
            )
            if (checkIfGotAccess())
                onGotAccess()
            else
                Log.d(&quot;AppLog&quot;, &quot;you didn't grant permission to the correct folder&quot;)
        }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)
        setSupportActionBar(findViewById(R.id.toolbar))
        val openDirectoryButton = findViewById&lt;FloatingActionButton&gt;(R.id.fab_open_directory)
        openDirectoryButton.setOnClickListener {
            openDirectory()
        }
    }

    private fun checkIfGotAccess(): Boolean {
        return contentResolver.persistedUriPermissions.indexOfFirst { uriPermission -&gt;
            uriPermission.uri.equals(androidTreeUri) &amp;&amp; uriPermission.isReadPermission &amp;&amp; uriPermission.isWritePermission
        } &gt;= 0
    }

    private fun onGotAccess() {
        Log.d(&quot;AppLog&quot;, &quot;got access to Android folder. showing content of each folder:&quot;)
        @Suppress(&quot;DEPRECATION&quot;)
        File(Environment.getExternalStorageDirectory(), &quot;Android&quot;).listFiles()?.forEach { androidSubFolder -&gt;
            val docId = &quot;$ANDROID_DOCID/${androidSubFolder.name}&quot;
            val childrenUri = DocumentsContract.buildChildDocumentsUriUsingTree(androidTreeUri, docId)
            val contentResolver = this.contentResolver
            Log.d(&quot;AppLog&quot;, &quot;content of:${androidSubFolder.absolutePath} :&quot;)
            contentResolver.query(childrenUri, null, null, null)
                ?.use { cursor -&gt;
                    val filesCount = cursor.count
                    Log.d(&quot;AppLog&quot;, &quot;filesCount:$filesCount&quot;)
                    val nameIndex = cursor.getColumnIndex(OpenableColumns.DISPLAY_NAME)
                    val mimeIndex = cursor.getColumnIndex(&quot;mime_type&quot;)
                    while (cursor.moveToNext()) {
                        val displayName = cursor.getString(nameIndex)
                        val mimeType = cursor.getString(mimeIndex)
                        Log.d(&quot;AppLog&quot;, &quot;  $displayName isFolder?${mimeType == DocumentsContract.Document.MIME_TYPE_DIR}&quot;)
                    }
                }
        }
    }

    private fun openDirectory() {
        if (checkIfGotAccess())
            onGotAccess()
        else {
            val primaryStorageVolume = (getSystemService(STORAGE_SERVICE) as StorageManager).primaryStorageVolume
            val intent =
                primaryStorageVolume.createOpenDocumentTreeIntent().putExtra(EXTRA_INITIAL_URI, androidUri)
            handleIntentActivityResult.launch(intent)
        }
    }

    companion object {
        private const val ANDROID_DOCID = &quot;primary:Android&quot;
        private const val EXTERNAL_STORAGE_PROVIDER_AUTHORITY = &quot;com.android.externalstorage.documents&quot;
        private val androidUri = DocumentsContract.buildDocumentUri(
            EXTERNAL_STORAGE_PROVIDER_AUTHORITY, ANDROID_DOCID
        )
        private val androidTreeUri = DocumentsContract.buildTreeDocumentUri(
            EXTERNAL_STORAGE_PROVIDER_AUTHORITY, ANDROID_DOCID
        )
    }
}
</code></pre>
","907695","","878126","","2021-03-04 21:22:12","2021-03-04 21:22:12","","","","15","","","","CC BY-SA 4.0"
"67978029","2","","67978028","2021-06-14 22:50:04","","11","","<p>It looks like this curious behavior is a limitation of the simulator. If I run it on my physical iPhone 12 Pro Max, the async-await task group approach results in 6 concurrent tasks ...</p>
<p><a href=""https://i.stack.imgur.com/wn5X2.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/wn5X2.png"" alt=""enter image description here"" /></a></p>
<p>... which is essentially the same as the <code>concurrentPerform</code> behavior:</p>
<p><a href=""https://i.stack.imgur.com/65rFm.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/65rFm.png"" alt=""enter image description here"" /></a></p>
<p>The behavior, including the degree of concurrency, is essentially the same on the physical device.</p>
<p>One is left to infer that the simulator appears to be configured to constrain async-await more than what is achievable with direct GCD calls. But on actual physical devices, the async-await task group behavior is as one would expect.</p>
","1271826","","","","","2021-06-14 22:50:04","","","","7","","","","CC BY-SA 4.0"
"68597084","2","","68505026","2021-07-30 21:05:26","","3","","<p>Apparently, no one is both interested enough and confident enough to write an answer, so I guess I'll go ahead.</p>
<blockquote>
<p><strong>isn't that argument fatally flawed?</strong></p>
</blockquote>
<p>To the extent that the proof quoted from the paper is intended to demonstrate that a conforming C implementation is not permitted to perform the source-to-source transformation described in the question, or an equivalent, <strong>yes</strong>, the proof is flawed.  The refutation presented in the question is sound.</p>
<p>There was some discussion in comments about how the refutation could be viewed as boiling down to anything being permissible in the event of undefined behavior.  That is a valid perspective, and in no way does it undercut the argument.  However, I think it's unnecessarily minimalistic.</p>
<p>Again, the key problem with the paper's proof is here:</p>
<blockquote>
<blockquote>
<p>the load of <code>a</code> can only return 0 (the initial value of <code>a</code>) because the
store <code>a=1</code> does not happen before it (because it is in a different
thread that has not been synchronised with) and non-atomic loads must
return the latest write that happens before them.</p>
</blockquote>
</blockquote>
<p>The proof's error is that the language specification's requirement that a read of <code>a</code> must return the result of a write to <code>a</code> that &quot;happened before&quot; it is conditioned on the program being free of data races.  This is an essential foundation for the whole model, not some kind of escape hatch.  The program manifestly is not free of data races if in fact the read of <code>a</code> is performed, so the requirement is moot in that case.  The read of <code>a</code> by thread 2 absolutely can observe the write by thread 1, and there is good reason to suppose that it might sometimes do so in practice.</p>
<p>To look at it another way, the proof chooses to focus on the write not happening before the read, but ignores the fact that the read also does not happen before the write.</p>
<p>Taking the relaxed atomic accesses into account does not change anything.  It is plausible that in a real execution of the paper's three-threaded program, the implementation (for example) speculatively executes the relaxed load of <code>x</code> in thread 2 on the assumption that it will return 1, then reads from <code>a</code> the value written by thread 1, and as a result, executes the store to <code>y</code>.  Because the atomic accesses are performed with relaxed semantics, the execution of thread 3 can read the value of <code>y</code> as 1 (or speculate that it will do so) and consequently perform the write to <code>x</code>.  All speculations involved can then be confirmed correct, with the final result that a = x = y = 1.  It is intentional that this seemingly paradoxical result is allowed by the &quot;relaxed&quot; memory order.</p>
<blockquote>
<p><strong>isn't it indeed valid for a C11 implementation to treat the original
three-threaded program as if it were the two-threaded program
consisting of threads 2' and 3?</strong></p>
</blockquote>
<p>At minimum, the paper's argument does not show otherwise, even if we -- with no basis in the specification -- construe the scope of the UB arising from the data race to be limited to whether the value read from <code>a</code> is its initial one or the one written by thread 1.</p>
<p>Implementations are given broad license to behave as they choose, so long as they produce observable behavior that is consistent with the behavior required of the abstract machine.  The creation and execution of multiple threads of execution is not itself part of the observable behavior of a program, as that is defined by the specification. Therefore, yes, a program that performed the proposed transformation and then behaved accordingly, or one that otherwise behaved as if there were a <em>happens before</em> edge between the write to <code>a</code> and the read from <code>a</code>, would not be acting inconsistently with the specification.</p>
","2402272","","2402272","","2021-08-01 23:55:11","2021-08-01 23:55:11","","","","0","","","","CC BY-SA 4.0"
"68993324","2","","65967690","2021-08-31 05:29:56","","1","","<p>&quot;Java Version Tested on Android 11&quot;
This will copy file from assets folder to any directory inside android/data/xxx</p>
<pre><code>@RequiresApi(api = Build.VERSION_CODES.LOLLIPOP)
public class MainActivity extends AppCompatActivity 
{
   private final String EXTERNAL_STORAGE_PROVIDER_AUTHORITY = &quot;com.android.externalstorage.documents&quot;;
    private final String ANDROID_DOCID =
            &quot;primary:Android/data/xxxxFolderName&quot;;
    Uri uri;
    Uri treeUri;
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        Button b=findViewById(R.id.ok);
        uri = DocumentsContract.buildDocumentUri(
                EXTERNAL_STORAGE_PROVIDER_AUTHORITY,
                ANDROID_DOCID
        );
        treeUri = DocumentsContract.buildTreeDocumentUri(
                EXTERNAL_STORAGE_PROVIDER_AUTHORITY,
                ANDROID_DOCID
        );
        if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.Q) {
            openDirectory();
        }

    }

    private Boolean checkIfGotAccess() {
        List&lt;UriPermission&gt; permissionList = getContentResolver().getPersistedUriPermissions();
        for (int i = 0; i &lt; permissionList.size(); i++) {
            UriPermission it = permissionList.get(i);
            if (it.getUri().equals(treeUri) &amp;&amp; it.isReadPermission())
                return true;
        }
        return false;
    }

    @RequiresApi(api = Build.VERSION_CODES.Q)
    private void openDirectory() {

        if (checkIfGotAccess()) {
            copyFile(treeUri);
            //return;
        }
        Intent intent =
                getPrimaryVolume().createOpenDocumentTreeIntent()
                        .putExtra(EXTRA_INITIAL_URI, uri);
        ActivityResultLauncher&lt;Intent&gt; handleIntentActivityResult = registerForActivityResult(
                new ActivityResultContracts.StartActivityForResult(),
                result -&gt; {
                    if (result.getResultCode() == Activity.RESULT_OK) {
                        if (result.getData() == null || result.getData().getData() == null)
                            return;
                        Uri directoryUri = result.getData().getData();
                        getContentResolver().takePersistableUriPermission(
                                directoryUri,
                                Intent.FLAG_GRANT_READ_URI_PERMISSION
                        );
                        if (checkIfGotAccess())
                            copyFile(treeUri);
                        else
                            Log.d(&quot;AppLog&quot;, &quot;you didn't grant permission to the correct folder&quot;);
                    }
                });
        handleIntentActivityResult.launch(intent);

    }


    @RequiresApi(api = Build.VERSION_CODES.N)
    private StorageVolume getPrimaryVolume() {
        StorageManager sm = (StorageManager) getSystemService(STORAGE_SERVICE);
        return sm.getPrimaryStorageVolume();
    }

    private void copyFile(Uri treeUri) {
        AssetManager assetManager = getAssets();

        OutputStream out;
        DocumentFile pickedDir = DocumentFile.fromTreeUri(this, treeUri);
        String extension = &quot;ini&quot;;
        try {
            InputStream inn = assetManager.open(&quot;xxxxfileName.ini&quot;);
            assert pickedDir != null;
           DocumentFile existing = pickedDir.findFile(&quot;xxxxfileName.ini&quot;);
           if(existing!=null)
               existing.delete();
            DocumentFile newFile = pickedDir.createFile(&quot;*/&quot; + extension, &quot;EnjoyCJZC.ini&quot;);
            assert newFile != null;
            out = getContentResolver().openOutputStream(newFile.getUri());
            byte[] buffer = new byte[1024];
            int read;
            while ((read = inn.read(buffer)) != -1) {
                out.write(buffer, 0, read);
            }
            inn.close();
            out.flush();
            out.close();
        } catch (Exception fnfe1) {
            fnfe1.printStackTrace();
        }
    }

}
</code></pre>
","8678059","","12660050","","2021-08-31 22:41:22","2021-08-31 22:41:22","","","","1","","","","CC BY-SA 4.0"
"69096604","2","","65080685","2021-09-08 03:21:45","","0","","<p>A partial solution that worked for me</p>
<p>I was getting this error too. It was stopping my program running.</p>
<ol>
<li>I unplugged all my USB devices, ran the program, with no error.</li>
<li>Plugged the devices back in, ran the program. I am still getting the error, however, the program finished without the error stopping the program.</li>
</ol>
","11922354","","","","","2021-09-08 03:21:45","","","","0","","","","CC BY-SA 4.0"
"69859510","2","","69859509","2021-11-05 21:37:43","","33","","<p>React Router v6 splits apart the history into multiple pieces, for this use case the relevant parts are the <em>navigator</em> and the <em>location</em>. This change is hinted at in <a href=""https://reactrouter.com/docs/en/v6/upgrading/v5#use-usenavigate-instead-of-usehistory"" rel=""nofollow noreferrer""><em>Use <code>useNavigate</code> instead of <code>useHistory</code></em></a>, and you can see it in the definition of the <code>Navigator</code> type used in the <code>Router</code> props:</p>
<pre><code>export declare type Navigator = Omit&lt;History, &quot;action&quot; | &quot;location&quot; | &quot;back&quot; | &quot;forward&quot; | &quot;listen&quot; | &quot;block&quot;&gt;;
</code></pre>
<p>Just changing <code>history={history}</code> to <code>navigator={history}</code> still left the <code>location</code> prop, from which the router was trying to access the <code>pathname</code> (<a href=""https://github.com/remix-run/react-router/blob/d6650e2c1ea23256f87096d734b4ca41d2577658/packages/react-router/index.tsx#L280-L286"" rel=""nofollow noreferrer"">among other properties</a>), undefined. To get the test working again, update the rendering as follows:</p>
<pre><code>const { render } = require(&quot;@testing-library/react&quot;);
const { createMemoryHistory } = require(&quot;history&quot;);
const React = require(&quot;react&quot;);
const { Router } = require(&quot;react-router-dom&quot;);

it(&quot;works&quot;, () =&gt; {
  const history = createMemoryHistory();
  render(
    &lt;Router location={history.location} navigator={history}&gt;&lt;/Router&gt;
  );
});
</code></pre>
<p><strong>Note</strong> that from React Router 6.4 <code>history</code> is no longer included as a dependency, so if you hadn't explicitly installed it you will need to add it back in.</p>
","3001761","","3001761","","2022-09-20 19:05:08","2022-09-20 19:05:08","","","","0","","","","CC BY-SA 4.0"
"70476264","2","","65080685","2021-12-24 20:12:42","","15","","<p>However these log messages can be supressed from appearing on the console through an easy <em>hack</em> i.e. by adding an argument through <em><code>add_experimental_option()</code></em> as follows:</p>
<pre><code>options.add_experimental_option('excludeSwitches', ['enable-logging'])
</code></pre>
<p>Code Block:</p>
<pre><code>from selenium import webdriver

options = webdriver.ChromeOptions() 
options.add_argument(&quot;start-maximized&quot;)
# to supress the error messages/logs
options.add_experimental_option('excludeSwitches', ['enable-logging'])
driver = webdriver.Chrome(options=options, executable_path=r'C:\WebDrivers\chromedriver.exe')
driver.get('https://www.google.com/')
</code></pre>
","7429447","","7429447","","2022-02-16 20:35:05","2022-02-16 20:35:05","","","","0","","","","CC BY-SA 4.0"
"60978914","2","","60859112","2020-04-01 19:31:55","","0","","<p>UPDATE: TL;DR</p>

<pre class=""lang-kotlin prettyprint-override""><code>// Check if this thread already has prepared a looper
if (Looper.myLooper() == null) {
    Looper.prepare()
}
val threadHandler = Handler(Looper.myLooper())
val messenger = Messenger(threadHandler)
messenger.send(...)
</code></pre>

<p><strong>Long Answer</strong></p>

<p>If you want to dig a little bit more on what's going on and in which thread is every piece of code running:</p>

<pre class=""lang-kotlin prettyprint-override""><code>// Check if this thread already has prepared a looper
// Running on Original Thread
if (Looper.myLooper() == null) {
    Looper.prepare()
}
// Save thread's Looper (1)
// Running on Original Thread
val threadLooper = Looper.myLooper()
Handler(Looper.getMainLooper()).post {
    // Do some UI stuff, for instance, show a dialog
    // Running on UI Thread
    AlertDialog
        .Builder(context)
        .setTitle(""Dialog title"")
        .setMessage(""Dialog message"")
        .setNegativeButton(""Cancel"") { _: DialogInterface, _: Int -&gt;
            // Use thread's Looper from (1) to notify the original thread
            // Running on UI Thread
            Handler(threadLooper).post {
                // Running on Original Thread
                callback?.onCancel()
            }
        }
        .setPositiveButton(""Retry"") { _: DialogInterface, _: Int -&gt;
            // Use thread's Looper from (1) to notify the original thread
            // Running on UI Thread
            Handler(threadLooper).post {
                // Running on Original Thread
                callback?.onRetry()
            }
        }
        .show()
}
// Call loop() to start the thread's loop
// Running on Original Thread
Looper.loop()
</code></pre>
","3023434","","3023434","","2020-04-01 20:48:41","2020-04-01 20:48:41","","","","7","","","","CC BY-SA 4.0"
"61151900","2","","61151278","2020-04-11 03:49:06","","10","","<p>There are two kinds of <code>resource_acquisition</code> supported by <code>using</code> as per <a href=""https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/statements#the-using-statement"" rel=""noreferrer"">the specifications</a>: <code>local_variable_declaration</code> and <code>expression</code>.</p>
<p>I believe the local using in C# 8 is a shortcut to <code>local_variable_declaration</code> form not <code>expression</code> form as per <a href=""https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/proposals/csharp-8.0/using"" rel=""noreferrer"">the language feature proposal</a>, where you could see:</p>
<blockquote>
<p><strong>Restrictions around using declaration:</strong></p>
<p>Must have an initializer for each declarator.</p>
</blockquote>
<p>This also provides the ability to use more than one resources in a single using statement as per the language specs states:</p>
<blockquote>
<p>When a <code>resource_acquisition</code> takes the form of a <code>local_variable_declaration</code>, it is possible to acquire multiple resources of a given type.</p>
</blockquote>
<p>So you could do:</p>
<pre><code>using IDisposable a = Foo1();
using IDisposable a = Foo1(), b = Foo2(), c = Foo3();
</code></pre>
<p>It <em>may</em> be possible that the language team could add <code>expression</code> form support in the future versions, but for now, <code>expression</code> is not yet supported.</p>
","10620317","","-1","","2020-06-20 09:12:55","2020-04-11 04:28:26","","","","4","","","","CC BY-SA 4.0"
"63991379","2","","63646183","2020-09-21 11:29:49","","2","","<p>With this you can both call and write <code>name</code></p>
<pre><code>interface Foo extends Function{
    name: string
}
const d: Foo = function(){}
d.name ='not foo'
d()
</code></pre>
<blockquote>
<p>Thanks. It technically solves the problem but Function ignores the
signature of the function, d('should cause TS error', 'for unexpected
args') (this wasn't mentioned in the question but seems to be a
reasonable requirement). Also const itself is able to remove the error
because it's treated differently than let</p>
</blockquote>
<pre><code>type  Incrementer = (x: number)=&gt;string
interface Foo extends Incrementer{
    name: string
}
let d: Foo = (x)=&gt;'a'+x
d.name ='not foo'
d(1)
d('s') // string not expceted must be number
</code></pre>
<p>If you want a general answer, here is your <code>Writable</code></p>
<pre><code>interface Writable&lt;T extends (...args: any) =&gt; any&gt; {
    (...arg: Parameters&lt;T&gt;): ReturnType&lt;T&gt;;

    name: string
}

type  Incrementer = (x: number, y: boolean) =&gt; string

let d: Writable&lt;Incrementer&gt; = (x, y) =&gt; 'a' + x + y
d.name = 'not foo' // no error
d(1, true) // no error
d('d', true)  // 'd' is not assignable to number
d(2, 1) // 1 is not assignable to boolean
</code></pre>
","6727914","","6727914","","2020-09-27 12:21:15","2020-09-27 12:21:15","","","","4","","","","CC BY-SA 4.0"
"66651132","2","","63421086","2021-03-16 08:02:52","","1","","<p>I found that this one worked for me so:</p>
<pre class=""lang-py prettyprint-override""><code>pip3 install webdrivermanager
</code></pre>
<p>Not sure if it'll help anyone, but pip3 works better than normal pip as it installs correct dependencies</p>
","14879187","","","","","2021-03-16 08:02:52","","","","1","","","","CC BY-SA 4.0"
"66916229","2","","60624851","2021-04-02 08:00:36","","4","","<p>I remembered that the <a href=""https://github.com/RxSwiftCommunity/RxSwiftExt"" rel=""nofollow noreferrer"">RxSwiftExt</a> library had a really nice implementation of a custom retry + delay operator with many options (linear and exponential delay, plus an option to provide a custom closure) and I tried to recreate it in Combine. The original implementation is <a href=""https://github.com/RxSwiftCommunity/RxSwiftExt/blob/main/Source/RxSwift/retryWithBehavior.swift"" rel=""nofollow noreferrer"">here</a>.</p>
<pre><code>/**
 Provides the retry behavior that will be used - the number of retries and the delay between two subsequent retries.
 - `.immediate`: It will immediatelly retry for the specified retry count
 - `.delayed`: It will retry for the specified retry count, adding a fixed delay between each retry
 - `.exponentialDelayed`: It will retry for the specified retry count.
 The delay will be incremented by the provided multiplier after each iteration
 (`multiplier = 0.5` corresponds to 50% increase in time between each retry)
 - `.custom`: It will retry for the specified retry count. The delay will be calculated by the provided custom closure.
 The closure's argument is the current retry
 */
enum RetryBehavior&lt;S&gt; where S: Scheduler {
  case immediate(retries: UInt)
  case delayed(retries: UInt, time: TimeInterval)
  case exponentialDelayed(retries: UInt, initial: TimeInterval, multiplier: Double)
  case custom(retries: UInt, delayCalculator: (UInt) -&gt; TimeInterval)
}

fileprivate extension RetryBehavior {
  
  func calculateConditions(_ currentRetry: UInt) -&gt; (maxRetries: UInt, delay: S.SchedulerTimeType.Stride) {
    
    switch self {
    case let .immediate(retries):
      // If immediate, returns 0.0 for delay
      return (maxRetries: retries, delay: .zero)
    case let .delayed(retries, time):
      // Returns the fixed delay specified by the user
      return (maxRetries: retries, delay: .seconds(time))
    case let .exponentialDelayed(retries, initial, multiplier):
      // If it is the first retry the initial delay is used, otherwise it is calculated
      let delay = currentRetry == 1 ? initial : initial * pow(1 + multiplier, Double(currentRetry - 1))
      return (maxRetries: retries, delay: .seconds(delay))
    case let .custom(retries, delayCalculator):
      // Calculates the delay with the custom calculator
      return (maxRetries: retries, delay: .seconds(delayCalculator(currentRetry)))
    }
    
  }
  
}

public typealias RetryPredicate = (Error) -&gt; Bool

extension Publisher {
  /**
   Retries the failed upstream publisher using the given retry behavior.
   - parameter behavior: The retry behavior that will be used in case of an error.
   - parameter shouldRetry: An optional custom closure which uses the downstream error to determine
   if the publisher should retry.
   - parameter tolerance: The allowed tolerance in firing delayed events.
   - parameter scheduler: The scheduler that will be used for delaying the retry.
   - parameter options: Options relevant to the scheduler’s behavior.
   - returns: A publisher that attempts to recreate its subscription to a failed upstream publisher.
   */
  func retry&lt;S&gt;(
    _ behavior: RetryBehavior&lt;S&gt;,
    shouldRetry: RetryPredicate? = nil,
    tolerance: S.SchedulerTimeType.Stride? = nil,
    scheduler: S,
    options: S.SchedulerOptions? = nil
  ) -&gt; AnyPublisher&lt;Output, Failure&gt; where S: Scheduler {
    return retry(
      1,
      behavior: behavior,
      shouldRetry: shouldRetry,
      tolerance: tolerance,
      scheduler: scheduler,
      options: options
    )
  }
  
  private func retry&lt;S&gt;(
    _ currentAttempt: UInt,
    behavior: RetryBehavior&lt;S&gt;,
    shouldRetry: RetryPredicate? = nil,
    tolerance: S.SchedulerTimeType.Stride? = nil,
    scheduler: S,
    options: S.SchedulerOptions? = nil
  ) -&gt; AnyPublisher&lt;Output, Failure&gt; where S: Scheduler {
    
    // This shouldn't happen, in case it does we finish immediately
    guard currentAttempt &gt; 0 else { return Empty&lt;Output, Failure&gt;().eraseToAnyPublisher() }
    
    // Calculate the retry conditions
    let conditions = behavior.calculateConditions(currentAttempt)
    
    return self.catch { error -&gt; AnyPublisher&lt;Output, Failure&gt; in
      
      // If we exceed the maximum retries we return the error
      guard currentAttempt &lt;= conditions.maxRetries else {
        return Fail(error: error).eraseToAnyPublisher()
      }
      
      if let shouldRetry = shouldRetry, shouldRetry(error) == false {
        // If the shouldRetry predicate returns false we also return the error
        return Fail(error: error).eraseToAnyPublisher()
      }
      
      guard conditions.delay != .zero else {
        // If there is no delay, we retry immediately
        return self.retry(
          currentAttempt + 1,
          behavior: behavior,
          shouldRetry: shouldRetry,
          tolerance: tolerance,
          scheduler: scheduler,
          options: options
        )
        .eraseToAnyPublisher()
      }
      
      // We retry after the specified delay
      return Just(()).delay(for: conditions.delay, tolerance: tolerance, scheduler: scheduler, options: options).flatMap {
        return self.retry(
          currentAttempt + 1,
          behavior: behavior,
          shouldRetry: shouldRetry,
          tolerance: tolerance,
          scheduler: scheduler,
          options: options
        )
        .eraseToAnyPublisher()
      }
      .eraseToAnyPublisher()
    }
    .eraseToAnyPublisher()
  }
  
}
</code></pre>
","4772647","","4772647","","2021-04-02 08:19:42","2021-04-02 08:19:42","","","","0","","","","CC BY-SA 4.0"
"69439302","2","","69439301","2021-10-04 16:20:51","","37","","<blockquote>
<p>Is this a change in iOS 15?</p>
</blockquote>
<p>Yes and no. There is indeed a change in iOS 15, but the reason for the problem you're experiencing is a change in Xcode 13.</p>
<p>The change in iOS 15 is that there's a whole new way of configuring a button. This starts with giving the button one of four new iOS 15 types: Plain, Gray, Tinted, and Filled. If you set your button to have any of those types, you are opting in to the new behavior.</p>
<p>The problem you're seeing is because, in Xcode 13, when you make a button in the storyboard, it <em>does</em> give the button one of those types: Plain. So you have opted into the new dispensation without knowing it!</p>
<p>The solution, if you want the old behavior, is to change the Style pop-up menu (in the Attributes inspector) from Plain to Default. Now you have an old-style button and it will behave in the way you're accustomed to.</p>
<p>(Of course, in the long run, you're going to want to adopt the new dispensation. I'm just explaining the apparent change in behavior.)</p>
","341994","","341994","","2021-10-04 17:26:50","2021-10-04 17:26:50","","","","7","","","","CC BY-SA 4.0"
"70224830","2","","63421086","2021-12-04 10:31:14","","-3","","<p>This works for me in all python version.</p>
<pre><code>pip install webdriver-manager
</code></pre>
<p>Here's Lib, Check out:
<a href=""https://pypi.org/project/webdriver-manager/"" rel=""nofollow noreferrer"">https://pypi.org/project/webdriver-manager/</a></p>
","17587130","","","","","2021-12-04 10:31:14","","","","1","","","","CC BY-SA 4.0"
"70314583","2","","63421086","2021-12-11 11:03:44","","-1","","<p>It is an installation error.</p>
<p>It can be solved by:</p>
<p><strong>pip install webdriver_manager</strong></p>
","9881195","","","","","2021-12-11 11:03:44","","","","0","","","","CC BY-SA 4.0"
"70373366","2","","63421086","2021-12-16 03:03:04","","0","","<p>some times just restarting your code editor can be the ultimate solution
that is what worked for me after spending 2 hours on the web trying to find out why the webdriver_manager is not picked up by python</p>
<p>use this to install</p>
<pre><code>pip install webdriver_manager
</code></pre>
<p>and then restart your VScode if that is what you are using as a code editor
I don't know why I have to but it worked the time waste.</p>
","12962371","","","","","2021-12-16 03:03:04","","","","0","","","","CC BY-SA 4.0"
"72002001","2","","63421086","2022-04-25 15:27:35","","4","","<p>You can try this</p>
<p><code>py -3 -m pip install webdriver_manager</code></p>
","18941224","","","","","2022-04-25 15:27:35","","","","0","","","","CC BY-SA 4.0"
"72542197","2","","63421086","2022-06-08 08:07:20","","-1","","<p>Use this in code:
from webdriver_manager.chrome import ChromeDriverManager</p>
","19296803","","","","","2022-06-08 08:07:20","","","","1","","","","CC BY-SA 4.0"
"72760798","2","","63421086","2022-06-26 10:35:54","","-1","","<p>Make sure u have installed a correct python version.</p>
<p>I have noted that it works on python version 3.7 or lower version.</p>
","18048015","","","","","2022-06-26 10:35:54","","","","0","","","","CC BY-SA 4.0"
"73241208","2","","63421086","2022-08-04 19:15:05","","0","","<p>for newer selenium versions, install package &quot;webdriver-manager&quot; from pycharm IDE</p>
<p><img src=""https://i.stack.imgur.com/TRatC.png"" alt=""1"" /></p>
","8411269","","2395282","","2022-08-09 12:08:12","2022-08-09 12:08:12","","","","0","","","","CC BY-SA 4.0"
"59565524","2","","59557910","2020-01-02 15:05:14","","29","","<h1>Case 1: sinusoid <em>without</em> noise</h1>
<p>If your sinusoid does not contain any noise, you can use a very classic signal processing technique: taking the first derivative and detecting when it is equal to zero.</p>
<p>For example:</p>
<pre class=""lang-matlab prettyprint-override""><code>function signal = derivesignal( d )

% Identify signal
signal = zeros(size(d));
for i=2:length(d)
    if d(i-1) &gt; 0 &amp;&amp; d(i) &lt;= 0
        signal(i) = +1;     % peak detected
    elseif d(i-1) &lt; 0 &amp;&amp; d(i) &gt;= 0
        signal(i) = -1;     % trough detected
    end
end

end
</code></pre>
<p>Using your example data:</p>
<pre class=""lang-matlab prettyprint-override""><code>% Generate data
dt = 1/8000;
t  = (0:dt:(1-dt)/4)';
y  = sin(2*pi*60*t);

% Add some trends
y(1:1000) = y(1:1000) + 0.001*(1:1000)';
y(1001:2000) = y(1001:2000) - 0.002*(1:1000)';

% Approximate first derivative (delta y / delta x)
d = [0; diff(y)];

% Identify signal
signal = derivesignal(d);

% Plot result
figure(1); clf; set(gcf,'Position',[0 0 677 600])
subplot(4,1,1); hold on;
title('Data');
plot(t,y);
subplot(4,1,2); hold on;
title('First derivative');
area(d);
ylim([-0.05, 0.05]);
subplot(4,1,3); hold on;
title('Signal (-1 for trough, +1 for peak)');
plot(t,signal); ylim([-1.5 1.5]);
subplot(4,1,4); hold on;
title('Signals marked on data');
markers = abs(signal) &gt; 0;
plot(t,y); scatter(t(markers),y(markers),30,'or','MarkerFaceColor','red');
</code></pre>
<p>This yields:</p>
<p><a href=""https://i.stack.imgur.com/TF997.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/TF997.png"" alt=""Example sinuisoid detection"" /></a></p>
<p>This method will work extremely well for any type of sinusoid, with the only requirement that the input signal contains no noise.</p>
<hr />
<h1>Case 2: sinusoid <em>with</em> noise</h1>
<p>As soon as your input signal contains noise, the derivative method will fail. For example:</p>
<pre class=""lang-matlab prettyprint-override""><code>% Generate data
dt = 1/8000;
t  = (0:dt:(1-dt)/4)';
y  = sin(2*pi*60*t);

% Add some trends
y(1:1000) = y(1:1000) + 0.001*(1:1000)';
y(1001:2000) = y(1001:2000) - 0.002*(1:1000)';

% Add some noise
y = y + 0.2.*randn(2000,1);
</code></pre>
<p>Will now generate this result because <a href=""https://dsp.stackexchange.com/questions/55361/proof-that-first-difference-filter-amplifies-noise""><strong>first differences amplify noise</strong></a>:</p>
<p><a href=""https://i.stack.imgur.com/gVDaQ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/gVDaQ.png"" alt=""Sinusoid with noise example"" /></a></p>
<p>Now there are many ways to deal with noise, and the most standard way is to apply a <a href=""https://en.wikipedia.org/wiki/Moving_average"" rel=""noreferrer"">moving average filter</a>. One disadvantage of moving averages is that they are slow to adapt to new information, such that signals may be identified after they have occurred (moving averages have a lag).</p>
<p>Another <strong>very typical approach</strong> is to use <a href=""https://en.wikipedia.org/wiki/Fourier_analysis"" rel=""noreferrer"">Fourier Analysis</a> to identify all the frequencies in your input data, disregard all low-amplitude and high-frequency sinusoids, and use the remaining sinusoid as a filter. The remaining sinusoid will be (largely) cleansed from the noise and you can then use first-differencing again to determine the peaks and troughs (or for a single sine wave you know the peaks and troughs happen at 1/4 and 3/4 pi of the phase). I suggest you pick up any <em>signal processing theory</em> book to learn more about this technique. Matlab also has some <a href=""https://nl.mathworks.com/help/matlab/fourier-analysis-and-filtering.html"" rel=""noreferrer"">educational material</a> about this.</p>
<p>If you want to use this algorithm in hardware, I would suggest you also take a look at WFLC (<a href=""https://www.google.com/search?q=Weighted+Fourier+Linear+Combiner"" rel=""noreferrer"">Weighted Fourier Linear Combiner</a>) with e.g. 1 oscillator or PLL (<a href=""https://en.wikipedia.org/wiki/Phase-locked_loop"" rel=""noreferrer"">Phase-Locked Loop</a>) that can estimate the phase of a noisy wave <em>without</em> doing a full Fast Fourier Transform. You can find a Matlab algorithm for a phase-locked loop <a href=""https://en.wikipedia.org/wiki/Phase-locked_loop#Implementing_a_digital_phase-locked_loop_in_software"" rel=""noreferrer"">on Wikipedia</a>.</p>
<p>I will suggest a slightly more sophisticated approach here that will identify the peaks and troughs in real-time: <strong>fitting a sine wave function to your data using moving <a href=""https://en.wikipedia.org/wiki/Least_squares"" rel=""noreferrer"">least squares minimization</a> with initial estimates from Fourier analysis.</strong></p>
<p>Here is my function to do that:</p>
<pre class=""lang-matlab prettyprint-override""><code>function [result, peaks, troughs] = fitsine(y, t, eps)

% Fast fourier-transform
f = fft(y);
l = length(y);
p2 = abs(f/l);
p1 = p2(1:ceil(l/2+1));
p1(2:end-1) = 2*p1(2:end-1);
freq = (1/mean(diff(t)))*(0:ceil(l/2))/l;

% Find maximum amplitude and frequency
maxPeak = p1 == max(p1(2:end)); % disregard 0 frequency!
maxAmplitude = p1(maxPeak);     % find maximum amplitude
maxFrequency = freq(maxPeak);   % find maximum frequency

% Initialize guesses
p = [];
p(1) = mean(y);         % vertical shift
p(2) = maxAmplitude;    % amplitude estimate
p(3) = maxFrequency;    % phase estimate
p(4) = 0;               % phase shift (no guess)
p(5) = 0;               % trend (no guess)

% Create model
f = @(p) p(1) + p(2)*sin( p(3)*2*pi*t+p(4) ) + p(5)*t;
ferror = @(p) sum((f(p) - y).^2);
% Nonlinear least squares
% If you have the Optimization toolbox, use [lsqcurvefit] instead!
options = optimset('MaxFunEvals',50000,'MaxIter',50000,'TolFun',1e-25);
[param,fval,exitflag,output] = fminsearch(ferror,p,options);

% Calculate result
result = f(param);

% Find peaks
peaks = abs(sin(param(3)*2*pi*t+param(4)) - 1) &lt; eps;

% Find troughs
troughs = abs(sin(param(3)*2*pi*t+param(4)) + 1) &lt; eps;

end
</code></pre>
<p>As you can see, I first perform a <a href=""https://en.wikipedia.org/wiki/Fourier_transform"" rel=""noreferrer"">Fourier transform</a> to find initial estimates of the amplitude and frequency of the data. I then fit a sinusoid to the data using the model <strong>a + b sin(ct + d) + et</strong>. The fitted values represent a sine wave of which I know that +1 and -1 are the peaks and troughs, respectively. I can therefore identify these values as the signals.</p>
<p>This works very well for sinusoids with (slowly changing) trends and general (white) noise:</p>
<pre class=""lang-matlab prettyprint-override""><code>% Generate data
dt = 1/8000;
t  = (0:dt:(1-dt)/4)';
y  = sin(2*pi*60*t);

% Add some trends
y(1:1000) = y(1:1000) + 0.001*(1:1000)';
y(1001:2000) = y(1001:2000) - 0.002*(1:1000)';

% Add some noise
y = y + 0.2.*randn(2000,1);

% Loop through data (moving window) and fit sine wave
window = 250;   % How many data points to consider
interval = 10;  % How often to estimate
result = nan(size(y));
signal = zeros(size(y));
for i = window+1:interval:length(y)
    data = y(i-window:i);   % Get data window
    period = t(i-window:i); % Get time window
    [output, peaks, troughs] = fitsine(data,period,0.01);
    
    result(i-interval:i) = output(end-interval:end);
    signal(i-interval:i) = peaks(end-interval:end) - troughs(end-interval:end);
end

% Plot result
figure(1); clf; set(gcf,'Position',[0 0 677 600])
subplot(4,1,1); hold on;
title('Data');
plot(t,y); xlim([0 max(t)]); ylim([-4 4]);
subplot(4,1,2); hold on;
title('Model fit');
plot(t,result,'-k'); xlim([0 max(t)]); ylim([-4 4]);
subplot(4,1,3); hold on;
title('Signal (-1 for trough, +1 for peak)');
plot(t,signal,'r','LineWidth',2); ylim([-1.5 1.5]);
subplot(4,1,4); hold on;
title('Signals marked on data');
markers = abs(signal) &gt; 0;
plot(t,y,'-','Color',[0.1 0.1 0.1]);
scatter(t(markers),result(markers),30,'or','MarkerFaceColor','red');
xlim([0 max(t)]); ylim([-4 4]);
</code></pre>
<p><a href=""https://i.stack.imgur.com/woFQt.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/woFQt.png"" alt=""Fitting a sine wave to a sinusoid"" /></a></p>
<p>Main advantages of this approach are:</p>
<ul>
<li>You have an actual model of your data, so you can predict signals in the future before they happen! (e.g. fix the model and calculate the result by inputting future time periods)</li>
<li>You don't need to estimate the model every period (see parameter <code>interval</code> in the code)</li>
</ul>
<p>The disadvantage is that you need to select a lookback <code>window</code>, but you will have this problem with any method that you use for real-time detection.</p>
<h1>Video demonstration</h1>
<p><code>Data</code> is the input data, <code>Model fit</code> is the fitted sine wave to the data (see code), <code>Signal</code> indicates the peaks and troughs and <code>Signals marked on data</code> gives an impression of how accurate the algorithm is. <strong>Note: watch the model fit adjust itself to the trend in the middle of the graph!</strong></p>
<p><a href=""https://i.stack.imgur.com/ObzDF.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ObzDF.gif"" alt=""Fitting a sine wave model to a sinusoid in real-time"" /></a></p>
<p>That should get you started. There are also a lot of excellent books on signal detection theory (just google that term), which will go much further into these types of techniques. Good luck!</p>
","2431885","","2431885","","2021-04-13 11:49:30","2021-04-13 11:49:30","","","","0","","","","CC BY-SA 4.0"
"59618877","2","","59618213","2020-01-06 20:56:50","","5","","<p>You can thanks to a UUID:</p>
<pre><code>fn generate_unique_ident(prefix: &amp;str) -&gt; Ident {
    let uuid = uuid::Uuid::new_v4();
    let ident = format!(&quot;{}_{}&quot;, prefix, uuid).replace('-', &quot;_&quot;);

    Ident::new(&amp;ident, Span::call_site())
}
</code></pre>
","4498831","","2470818","","2020-12-07 16:41:13","2020-12-07 16:41:13","","","","5","","","","CC BY-SA 4.0"
"59619026","2","","59618213","2020-01-06 21:10:22","","7","","<p><strong>Summary</strong>: you can't yet use hygienic identifiers with proc macros on stable Rust. Your best bet is to use a particularly ugly name such as <code>__your_crate_your_name</code>. </p>

<hr>

<p>You are creating identifiers (in particular, <code>f</code>) by using <a href=""https://docs.rs/quote/1.0.2/quote/macro.quote.html"" rel=""nofollow noreferrer""><code>quote!</code></a>. This is certainly convenient, but it's just a helper around <a href=""https://doc.rust-lang.org/stable/proc_macro/index.html"" rel=""nofollow noreferrer"">the actual proc macro API the compiler offers</a>. So let's take a look at that API to see how we can create identifiers! In the end we need <a href=""https://doc.rust-lang.org/stable/proc_macro/struct.TokenStream.html"" rel=""nofollow noreferrer"">a <code>TokenStream</code></a>, as that's what our proc macro returns. How can we construct such a token stream?</p>

<p>We can parse it from a string, e.g. <code>""let f = 3;"".parse::&lt;TokenStream&gt;()</code>. But this was basically an early solution and is discouraged now. In any case, all identifiers created this way behave in a non-hygienic manner, so this won't solve your problem.</p>

<p>The second way (which <code>quote!</code> uses under the hood) is to create a <code>TokenStream</code> manually by creating a bunch of <a href=""https://doc.rust-lang.org/stable/proc_macro/enum.TokenTree.html"" rel=""nofollow noreferrer""><code>TokenTree</code>s</a>. One kind of <code>TokenTree</code> is an <a href=""https://doc.rust-lang.org/stable/proc_macro/struct.Ident.html"" rel=""nofollow noreferrer""><code>Ident</code></a> (identifier). We can create an <code>Ident</code> via <code>new</code>:</p>

<pre><code>fn new(string: &amp;str, span: Span) -&gt; Ident
</code></pre>

<p>The <code>string</code> parameter is self explanatory, but the <code>span</code> parameter is the interesting part! A <a href=""https://doc.rust-lang.org/stable/proc_macro/struct.Span.html"" rel=""nofollow noreferrer""><code>Span</code></a> stores the location of something in the source code and is usually used for error reporting (in order for <code>rustc</code> to point to the misspelled variable name, for example). But in the Rust compiler, spans carry more than location information: the kind of hygiene! We can see two constructor functions for <code>Span</code>:</p>

<ul>
<li><p><a href=""https://doc.rust-lang.org/stable/proc_macro/struct.Span.html#method.call_site"" rel=""nofollow noreferrer""><strong><code>fn call_site() -&gt; Span</code></strong></a>: creates a span with <em>call site hygiene</em>. This is what you call ""unhygienic"" and is equivalent to ""copy and pasting"". If two identifiers have the same string, they will collide or shadow each other. </p></li>
<li><p><a href=""https://doc.rust-lang.org/stable/proc_macro/struct.Span.html#method.def_site"" rel=""nofollow noreferrer""><strong><code>fn def_site() -&gt; Span</code></strong></a>: this is what you are after. Technically called <em>definition site hygiene</em>, this is what you call ""hygienic"". The identifiers you define and the ones of your user live in different universes and won't ever collide. As you can see in the docs, this method is still unstable and thus only usable on a nightly compiler. Bummer!</p></li>
</ul>

<p>There are no really great workarounds. The obvious one is to use a really ugly name like <code>__your_crate_some_variable</code>. To make it a bit easier for you, you can create that identifier once and use it within <code>quote!</code> (<a href=""https://stackoverflow.com/a/59619245/2408867"">slightly better solution here</a>):</p>

<pre><code>let ugly_name = quote! { __your_crate_some_variable };
quote! {
    let #ugly_name = 3;
    println!(""{}"", #ugly_name);
}
</code></pre>

<p>Sometimes you can even search through all identifiers of the user that could collide with yours and then simply algorithmically chose an identifier that does not collide. This is actually what <a href=""https://github.com/auto-impl-rs/auto_impl/pull/21"" rel=""nofollow noreferrer"">we did for <code>auto_impl</code></a>, with a fallback super ugly name. This was mainly to improve the generated documentation from having super ugly names in it.</p>

<p>Apart from that, I'm afraid you cannot really do anything.</p>
","2408867","","2408867","","2020-01-06 21:32:03","2020-01-06 21:32:03","","","","1","","","","CC BY-SA 4.0"
"70604506","2","","69859509","2022-01-06 08:43:28","","1","","<p>This is my solution to the issue, from a course I have been following on Udemy:</p>
<pre class=""lang-js prettyprint-override""><code>const { render } = require(&quot;@testing-library/react&quot;);
const { createBrowserHistory } = require(&quot;history&quot;);
const React = require(&quot;react&quot;);
const { unstable_HistoryRouter: HistoryRouter } = require(&quot;react-router-dom&quot;);

it(&quot;works&quot;, () =&gt; {
  const history = createBrowserHistory();
  render(
    &lt;HistoryRouter history={history}&gt;&lt;/HistoryRouter&gt;
  );
});
</code></pre>
","14561019","","3001761","","2022-01-06 11:47:27","2022-01-06 11:47:27","","","","2","","","","CC BY-SA 4.0"
"71569624","2","","65463893","2022-03-22 09:23:56","","10","","<p>Beware about this active glitch prior to using Jetpack Security EncryptedSharedPreferences ( even stable ), It's hitting on our crash-free sessions hard mostly from exotic devices - <a href=""https://issuetracker.google.com/issues/176215143?pli=1"" rel=""noreferrer"">https://issuetracker.google.com/issues/176215143?pli=1</a></p>
<p>The only dirty workaround is - <a href=""https://github.com/google/tink/issues/535#issuecomment-912661574"" rel=""noreferrer"">https://github.com/google/tink/issues/535#issuecomment-912661574</a></p>
<p>I'll update the answer once I find an amicable solution. Here is the workaround solution -</p>
<pre><code>/**
 * A builder for creating an encrypted shared preference class.
 */
private const val KEYSTORE_PROVIDER = &quot;AndroidKeyStore&quot;
private const val SHARED_PREFS_FILENAME = &quot;TVPrefs&quot;

@KoinApiExtension
class EncryptedSharedPreferenceBuilder(var context: Context) : KoinComponent {
    private val reporter: Reporter by inject()

    private val masterKeyAlias =
        MasterKey.Builder(context).setKeyScheme(MasterKey.KeyScheme.AES256_GCM).build()

    fun build(): SharedPreferences {
        return try {
            createSharedPreferences()
        } catch (gsException: GeneralSecurityException) {
            reporter.logException(gsException)
            Timber.d(&quot;EncryptedSharedPref: Error occurred while create shared pref=$gsException&quot;)
            // There's not much point in keeping data you can't decrypt anymore,
            // delete &amp; re-create; user has to start from scratch
            deleteSharedPreferences()
            createSharedPreferences()
        }
    }

    private fun createSharedPreferences() = EncryptedSharedPreferences.create(
        context,
        SHARED_PREFS_FILENAME,
        masterKeyAlias,
        EncryptedSharedPreferences.PrefKeyEncryptionScheme.AES256_SIV,
        EncryptedSharedPreferences.PrefValueEncryptionScheme.AES256_GCM
    )

    // Clearing getSharedPreferences using default Preference wrapper.
    // This is to work around any key-mismatches that may happen.
    fun clearSharedPreference() {
        context.getSharedPreferences(SHARED_PREFS_FILENAME, Context.MODE_PRIVATE).edit().clear()
            .apply()
    }

    // Workaround [https://github.com/google/tink/issues/535#issuecomment-912170221]
    // Issue Tracker - https://issuetracker.google.com/issues/176215143?pli=1
    private fun deleteSharedPreferences() {
        try {
            val sharedPrefsFile =
                File(&quot;${context.filesDir.parent}/shared_prefs/$SHARED_PREFS_FILENAME.xml&quot;)

            // Clear the encrypted prefs
            clearSharedPreference()

            // Delete the encrypted prefs file
            if (sharedPrefsFile.exists()) {
                val deleted = sharedPrefsFile.delete()
                Timber.d(&quot;EncryptedSharedPref: Shared pref file deleted=$deleted; path=${sharedPrefsFile.absolutePath}&quot;)
            } else {
                Timber.d(&quot;EncryptedSharedPref: Shared pref file non-existent; path=${sharedPrefsFile.absolutePath}&quot;)
            }

            // Delete the master key
            val keyStore = KeyStore.getInstance(KEYSTORE_PROVIDER)
            keyStore.load(null)
            keyStore.deleteEntry(MasterKey.DEFAULT_MASTER_KEY_ALIAS)
        } catch (e: Exception) {
            Timber.d(&quot;EncryptedSharedPref:  Error occurred while trying to reset shared pref=$e&quot;)
        }
    }
}
</code></pre>
","4694013","","4694013","","2022-03-23 05:42:20","2022-03-23 05:42:20","","","","2","","","","CC BY-SA 4.0"
"66129225","2","","66129103","2021-02-10 00:23:50","","12","","<p><code>rbenv install</code> passes thru <code>ruby-build</code>. You need to update (<code>brew upgrade</code> if installed via Homebrew) your <code>ruby-build</code> in order to see the latest versions.</p>
","341994","","341994","","2021-02-10 03:00:25","2021-02-10 03:00:25","","","","0","","","","CC BY-SA 4.0"
"66293105","2","","66129103","2021-02-20 15:10:46","","7","","<h3>On Ubuntu</h3>
<p>Short answer:</p>
<pre class=""lang-sh prettyprint-override""><code># You need to update the available versions via ruby-build
~ git -C ~/.rbenv/plugins/ruby-build pull
~ rbenv install 3.0.0
...
Installed ruby-3.0.0 to ~/.rbenv/versions/3.0.0
</code></pre>
<p>Long answer with a beautiful picture🐈: <a href=""https://richstone.io/where-is-ruby-3-0-0-on-rbenv/"" rel=""noreferrer"">https://richstone.io/where-is-ruby-3-0-0-on-rbenv/</a></p>
","5925094","","","","","2021-02-20 15:10:46","","","","0","","","","CC BY-SA 4.0"
"66702340","2","","66129103","2021-03-19 04:00:57","","7","","<h2>Ubuntu</h2>
<ol>
<li><code>git -C ~/.rbenv/plugins/ruby-build pull</code>  (pulls latest ruby versions)</li>
<li><code>rbenv install 3.0.0</code> (or for later versions: 3.x.x)</li>
<li><code>echo &quot;3.0.0&quot; &gt; .ruby-version</code> OR <code>rbenv local 3.0.0</code> to ensure ruby 3.0.0 is used.</li>
</ol>
<h2>Mac</h2>
<pre><code>brew upgrade
</code></pre>
","4880924","","4880924","","2022-08-09 20:05:11","2022-08-09 20:05:11","","","","4","","","","CC BY-SA 4.0"
"67006959","2","","66924519","2021-04-08 15:14:19","","3","","<p>I think that what you want is what is described in this <a href=""https://github.com/webpack/webpack/issues/6717#issuecomment-391999529"" rel=""nofollow noreferrer"">webpack issue reply</a></p>
<p>the reply uses a function to exclude the dependencies of a specific entrypoint from being included in a chunk:</p>
<pre><code>  optimization: {
    splitChunks: {
      cacheGroups: {
          vendors: {
            // ... your current config, just change the chunks property            

            // Exclude pre-main dependencies going into vendors, as doing so
            // will result in webpack only loading pre-main once vendors loaded.
            // But pre-main is the one loading vendors.
            // Currently undocument feature:  https://github.com/webpack/webpack/pull/6791
            chunks: chunk =&gt; chunk.name !== &quot;barWidget&quot;
          }
      }
    }
  },
</code></pre>
<p>to do this with vue should be just a matter of changing the webpack config in the vue.config.js file like this:</p>
<pre><code>module.exports = {
  configureWebpack: config =&gt; {
     config.optimization.splitChunks.cacheGroups.vendors.chunks = 
       chunk =&gt; chunk.name !== &quot;barWidget&quot;;
  }
}
</code></pre>
<p>I haven't tried this but I think it should work as is or with some minimal tweaks</p>
","4023734","","","","","2021-04-08 15:14:19","","","","1","","","","CC BY-SA 4.0"
"67007315","2","","66924519","2021-04-08 15:34:57","","3","","<p>You can use a function to filter the chunks. See this <a href=""https://github.com/webpack/webpack/issues/6717"" rel=""nofollow noreferrer"">Webpack issue</a></p>
<p><code>vue.config.js</code></p>
<pre class=""lang-js prettyprint-override""><code>module.exports = {
  pages: {
    foo: {
      entry: 'src/foo.js',
      template: 'public/foo.html',
      filename: 'foo.html'
    },
    barWidget: {
      entry: 'src/barWidget.js',
      template: 'public/barWidget.html',
      filename: 'barWidget.html',
      chunks: ['barWidget']
    },
  },
  chainWebpack: config =&gt; {
    if (process.env.NODE_ENV !== 'test') {
      config.optimization.splitChunks({
        cacheGroups: {
          defaultVendors: {
            name: `chunk-vendors`,
            test: /[\\/]node_modules[\\/]/,
            priority: -10,
            chunks: chunk =&gt; chunk.name !== &quot;barWidget&quot;
          },
          common: {
            name: `chunk-common`,
            minChunks: 2,
            priority: -20,
            chunks: 'initial',
            reuseExistingChunk: true
          }
        }
      })
    }
  }
}
</code></pre>
<p>Note the <code>pages.barWidget.chunks</code> - it is needed because otherwise HtmlWebpackPlugin includes vendors chunk into <code>barWidget.html</code> even it is not needed at all...</p>
<p>Result:
<a href=""https://i.stack.imgur.com/h0ir8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/h0ir8.png"" alt=""Result"" /></a></p>
","381282","","2080707","","2022-09-28 12:46:44","2022-09-28 12:46:44","","","","1","","","","CC BY-SA 4.0"
"59660145","2","","59557910","2020-01-09 08:48:10","","0","","<p>Consider using findpeaks, it is fast, which may be important for realtime. You should filter high-frequency noise to improve accuracy. here I smooth the data with a moving window.</p>

<pre><code>t = 0:0.001:10;
x = 0.3*sin(t) + sin(1.3*t) + 0.9*sin(4.2*t) + 0.02*randn(1, 10001);
[~,iPeak0] = findpeaks(movmean(x,100),'MinPeakProminence',0.5);
</code></pre>

<p>You can time the process (0.0015sec)</p>

<pre><code>f0 = @() findpeaks(movmean(x,100),'MinPeakProminence',0.5)
disp(timeit(f0,2))
</code></pre>

<p>To compare, processing the slope is only a bit faster (0.00013sec), but findpeaks have many useful options, such as minimum interval between peaks etc.</p>

<pre><code>iPeaks1 = derivePeaks(x);
f1 = @() derivePeaks(x)
disp(timeit(f1,1))
</code></pre>

<p>Where derivePeaks is:</p>

<pre><code>function iPeak1 = derivePeaks(x)
xSmooth = movmean(x,100);
goingUp = find(diff(movmean(xSmooth,100)) &gt; 0);
iPeak1 = unique(goingUp([1,find(diff(goingUp) &gt; 100),end]));
iPeak1(iPeak1 == 1 | iPeak1 == length(iPeak1)) = [];
end
</code></pre>
","4407697","","","","","2020-01-09 08:48:10","","","","0","","","","CC BY-SA 4.0"
"60690213","2","","60565299","2020-03-15 06:08:37","","0","","<p>Likely you'd have to handle all of the special cases you've already identified.</p>

<p>Aliases &amp; hexadecimal references might confuse it; these would need to be resolved.</p>

<p>For example, to fall-back from <code>manifest</code> to <code>mnfs</code> would at least solve one issue:</p>

<pre><code>fun getRootNode(document: Document): Node? {
    var node: Node? = document.getElementsByTagName(""manifest"")?.item(0)
    if (node == null) {
        node = document.getElementsByTagName(""mnfs"")?.item(0)
    }
    return node
}
</code></pre>

<p>""Features &amp; Tests"" would require <code>TextUtils.htmlEncode()</code> for <code>&amp;amp;</code> or another parser configuration.</p>

<p>Making it parse single <code>AndroidManifest.xml</code> files would make it easier to test, because with each other package there may be more unexpected input - until it comes close to the manifest parser which the OS uses (the <a href=""https://github.com/aosp-mirror/platform_frameworks_base/blob/master/core/java/android/content/pm/PackageParser.java#L1359"" rel=""nofollow noreferrer"">source code</a> might help). As one can see, it may set cookies for reading it. Take this list of package names and set up a test case for each of them, then the issues are rather isolated. But the main issue is that these cookies are <em>most likely</em> not available to 3rd party applications.</p>
","549372","","549372","","2020-03-15 07:45:29","2020-03-15 07:45:29","","","","1","","","","CC BY-SA 4.0"
"60711547","2","","60565299","2020-03-16 18:40:30","","0","","<p>It seems that <em>ApkManifestFetcher</em> doesn't handle all cases such as text (between tags) and  name space declarations and, maybe, a few other things. Below is a rework of <em>ApkManifestFetcher</em> that handles all 300+ APKs on my phone except for the Netflix APK which is coming up with some blank attributes.</p>

<p>I no longer believe that the files that start with <code>&lt;mnfs</code> have anything to do with obfuscation but are encoded using UTF-8 rather than UTF-16 which the app assumes (16 bits vs 8 bits). The reworked app handles UTF-8 encoding and can parse these files.</p>

<p>As mentioned above, name spaces are not handled correctly by the original class or this rework although the rework can skip past them. Comments in the code describe this a little.</p>

<p>That said, the code below may be good enough for certain applications. The better, although longer, course of action would be to use code from <em>apktool</em> which seems to be able to handle all APKs.</p>

<p><em>ApkManifestFetcher</em></p>

<pre><code>object ApkManifestFetcher {
    fun getManifestXmlFromFile(apkFile: File) =
            getManifestXmlFromInputStream(FileInputStream(apkFile))

    fun getManifestXmlFromFilePath(apkFilePath: String) =
            getManifestXmlFromInputStream(FileInputStream(File(apkFilePath)))

    fun getManifestXmlFromInputStream(ApkInputStream: InputStream): String? {
        ZipInputStream(ApkInputStream).use { zipInputStream: ZipInputStream -&gt;
            while (true) {
                val entry = zipInputStream.nextEntry ?: break
                if (entry.name == ""AndroidManifest.xml"") {
                    return decompressXML(zipInputStream.readBytes())
                }
            }
        }
        return null
    }

    /**
     * Binary XML name space starts
     */
    private const val startNameSpace = 0x00100100

    /**
     * Binary XML name space ends
     */
    private const val endNameSpace = 0x00100101

    /**
     * Binary XML start Tag
     */
    private const val startTag = 0x00100102

    /**
     * Binary XML end Tag
     */
    private const val endTag = 0x00100103

    /**
     * Binary XML text Tag
     */
    private const val textTag = 0x00100104

    /*
     * Flag for UTF-8 encoded file. Default is UTF-16.
     */
    private const val FLAG_UTF_8 = 0x00000100

    /**
     * Reference var for spacing
     * Used in prtIndent()
     */
    private const val spaces = ""                                             ""

    // Flag if the manifest is in UTF-8 but we don't really handle it.
    private var mIsUTF8 = false

    /**
     * Parse the 'compressed' binary form of Android XML docs
     * such as for AndroidManifest.xml in .apk files
     * Source: http://stackoverflow.com/questions/2097813/how-to-parse-the-androidmanifest-xml-file-inside-an-apk-package/4761689#4761689
     *
     * @param xml Encoded XML content to decompress
     */
    private fun decompressXML(xml: ByteArray): String {
        val resultXml = StringBuilder()
        /*
        Compressed XML file/bytes starts with 24x bytes of data
            9 32 bit words in little endian order (LSB first):
                0th word is 03 00 (Magic number) 08 00 (header size words 0-1)
                1st word is the size of the compressed XML. This should equal size of xml array.
                2nd word is 01 00 (Magic number) 1c 00 (header size words 2-8)
                3rd word is offset of byte after string table
                4th word is number of strings in string table
                5th word is style count
                6th word are flags
                7th word string table offset
                8th word is styles offset
                [string index table (little endian offset into string table)]
                [string table (two byte length followed by text for each entry UTF-16, nul)]
        */

        mIsUTF8 = (lew(xml, 24) and FLAG_UTF_8) != 0

        val numbStrings = lew(xml, 4 * 4)

        // StringIndexTable starts at offset 24x, an array of 32 bit LE offsets
        // of the length/string data in the StringTable.
        val sitOff = 0x24  // Offset of start of StringIndexTable

        // StringTable, each string is represented with a 16 bit little endian
        // character count, followed by that number of 16 bit (LE) (Unicode) chars.
        val stOff = sitOff + numbStrings * 4  // StringTable follows StrIndexTable

        // XMLTags, The XML tag tree starts after some unknown content after the
        // StringTable.  There is some unknown data after the StringTable, scan
        // forward from this point to the flag for the start of an XML start tag.
        var xmlTagOff = lew(xml, 3 * 4)  // Start from the offset in the 3rd word.
        // Scan forward until we find the bytes: 0x02011000(x00100102 in normal int)
        run {
            var ii = xmlTagOff
            while (ii &lt; xml.size - 4) {
                if (lew(xml, ii) == startTag) {
                    xmlTagOff = ii
                    break
                }
                ii += 4
            }
        }

        /*
        XML tags and attributes:

        Every XML start and end tag consists of 6 32 bit words:
            0th word: 02011000 for startTag and 03011000 for endTag
            1st word: a flag?, like 38000000
            2nd word: Line of where this tag appeared in the original source file
            3rd word: 0xFFFFFFFF ??
            4th word: StringIndex of NameSpace name, or 0xFFFFFF for default NS
            5th word: StringIndex of Element Name
            (Note: 01011000 in 0th word means end of XML document, endDocTag)

        Start tags (not end tags) contain 3 more words:
            6th word: 14001400 meaning??
            7th word: Number of Attributes that follow this tag(follow word 8th)
            8th word: 00000000 meaning??

        Attributes consist of 5 words:
            0th word: StringIndex of Attribute Name's Namespace, or 0xFFFFFF
            1st word: StringIndex of Attribute Name
            2nd word: StringIndex of Attribute Value, or 0xFFFFFFF if ResourceId used
            3rd word: Flags?
            4th word: str ind of attr value again, or ResourceId of value

        Text blocks consist of 7 words
            0th word: The text tag (0x00100104)
            1st word: Size of the block (28 bytes)
            2nd word: Line number
            3rd word: 0xFFFFFFFF
            4th word: Index into the string table
            5th word: Unknown
            6th word: Unknown

        startNameSpace blocks consist of 6 words
            0th word: The startNameSpace tag (0x00100100)
            1st word: Size of the block (24 bytes)
            2nd word: Line number
            3rd word: 0xFFFFFFFF
            4th word: Index into the string table for the prefix
            5th word: Index into the string table for the URI

        endNameSpace blocks consist of 6 words
            0th word: The endNameSpace tag (0x00100101)
            1st word: Size of the block (24 bytes)
            2nd word: Line number
            3rd word: 0xFFFFFFFF
            4th word: Index into the string table for the prefix
            5th word: Index into the string table for the URI
        */

        // Step through the XML tree element tags and attributes
        var off = xmlTagOff
        var indent = 0
        while (off &lt; xml.size) {
            val tag0 = lew(xml, off)
            val nameSi = lew(xml, off + 5 * 4)

            when (tag0) {
                startTag -&gt; {
                    val numbAttrs = lew(xml, off + 7 * 4)  // Number of Attributes to follow
                    off += 9 * 4  // Skip over 6+3 words of startTag data
                    val name = compXmlString(xml, sitOff, stOff, nameSi)

                    // Look for the Attributes
                    val sb = StringBuffer()
                    for (ii in 0 until numbAttrs) {
                        val attrNameSi = lew(xml, off + 1 * 4)  // AttrName String Index
                        val attrValueSi = lew(xml, off + 2 * 4) // AttrValue Str Ind, or 0xFFFFFF
                        val attrResId = lew(xml, off + 4 * 4)  // AttrValue ResourceId or dup AttrValue StrInd
                        off += 5 * 4  // Skip over the 5 words of an attribute

                        val attrName = compXmlString(xml, sitOff, stOff, attrNameSi)
                        val attrValue = if (attrValueSi != -1)
                            compXmlString(xml, sitOff, stOff, attrValueSi)
                        else
                            ""resourceID 0x"" + Integer.toHexString(attrResId)
                        sb.append("" $attrName=\""$attrValue\"""")
                    }
                    resultXml.append(prtIndent(indent, ""&lt;$name$sb&gt;""))
                    indent++
                }
                endTag -&gt; {
                    indent--
                    off += 6 * 4  // Skip over 6 words of endTag data
                    val name = compXmlString(xml, sitOff, stOff, nameSi)
                    resultXml.append(prtIndent(indent, ""&lt;/$name&gt;"")
                    )

                }
                textTag -&gt; {  // Text that is hanging out between start and end tags
                    val text = compXmlString(xml, sitOff, stOff, lew(xml, off + 16))
                    resultXml.append(text)
                    off += lew(xml, off + 4)
                }
                startNameSpace -&gt; {
                    //Todo startNameSpace and endNameSpace are effectively skipped, but they are not handled.
                    off += lew(xml, off + 4)
                }
                endNameSpace -&gt; {
                    off += lew(xml, off + 4)
                }
                else -&gt; {
                    Log.d(
                            ""Applog"", ""  Unrecognized tag code '"" + Integer.toHexString(tag0)
                            + ""' at offset "" + off
                    )
                }
            }
        }
        return resultXml.toString()
    }

    /**
     * Tool Method for decompressXML();
     * Compute binary XML to its string format
     * Source: Source: http://stackoverflow.com/questions/2097813/how-to-parse-the-androidmanifest-xml-file-inside-an-apk-package/4761689#4761689
     *
     * @param xml Binary-formatted XML
     * @param sitOff
     * @param stOff
     * @param strInd
     * @return String-formatted XML
     */
    private fun compXmlString(
            xml: ByteArray, @Suppress(""SameParameterValue"") sitOff: Int,
            stOff: Int,
            strInd: Int
    ): String? {
        if (strInd &lt; 0) return null
        val strOff = stOff + lew(xml, sitOff + strInd * 4)
        return compXmlStringAt(xml, strOff)
    }

    /**
     * Tool Method for decompressXML();
     * Apply indentation
     *
     * @param indent Indentation level
     * @param str String to indent
     * @return Indented string
     */
    private fun prtIndent(indent: Int, str: String): String {
        return spaces.substring(0, min(indent * 2, spaces.length)) + str
    }

    /**
     * Tool method for decompressXML()
     * Return the string stored in StringTable format at
     * offset strOff.  This offset points to the 16 bit string length, which
     * is followed by that number of 16 bit (Unicode) chars.
     *
     * @param arr StringTable array
     * @param strOff Offset to get string from
     * @return String from StringTable at offset strOff
     */
    private fun compXmlStringAt(arr: ByteArray, strOff: Int): String {
        var start = strOff
        var charSetUsed: Charset = Charsets.UTF_16LE

        val byteLength = if (mIsUTF8) {
            charSetUsed = Charsets.UTF_8
            start += 2
            arr[strOff + 1].toInt() and 0xFF
        } else { // UTF-16LE
            start += 2
            ((arr[strOff + 1].toInt() and 0xFF shl 8) or (arr[strOff].toInt() and 0xFF)) * 2
        }
        return String(arr, start, byteLength, charSetUsed)
    }

    /**
     * Return value of a Little Endian 32 bit word from the byte array
     * at offset off.
     *
     * @param arr Byte array with 32 bit word
     * @param off Offset to get word from
     * @return Value of Little Endian 32 bit word specified
     */
    private fun lew(arr: ByteArray, off: Int): Int {
        return (arr[off + 3] shl 24 and -0x1000000 or ((arr[off + 2] shl 16) and 0xff0000)
                or (arr[off + 1] shl 8 and 0xff00) or (arr[off].toInt() and 0xFF))
    }

    private infix fun Byte.shl(i: Int): Int = (this.toInt() shl i)
}
</code></pre>
","6287910","","6287910","","2020-03-18 02:25:06","2020-03-18 02:25:06","","","","16","","","","CC BY-SA 4.0"
"63738442","2","","63675627","2020-09-04 09:26:47","","2","","<p>Since you did not provide the full code, it is difficult to tell what's wrong.<br>
My guess would be that you are not modifying the correct object.</p>
<p>In your code example for Pictures, you are creating and modifying <code>elementClone</code>.<br>
In your code example for ole objects, you are working with and modifying <code>oleObject</code> (which is a descendant of <code>element</code>) and it is not exacly clear from the context, whether it is a part of the source document or of the target document.</p>
<hr />
<p>You can try this minimal example:</p>
<ul>
<li>use a new pptx with one embedded ole object for <code>c:\testdata\input.pptx</code></li>
<li>use a new pptx (a blank one) for <code>c:\testdata\output.pptx</code></li>
</ul>
<p>After running the code, I was able to open the embedded ole object in the output document.</p>
<pre><code>using DocumentFormat.OpenXml.Presentation;
using DocumentFormat.OpenXml.Packaging;
using System.Linq;

namespace ooxml
{
    class Program
    {
        static void Main(string[] args)
        {            
            CopyOle(&quot;c:\\testdata\\input.pptx&quot;, &quot;c:\\testdata\\output.pptx&quot;);
        }

        private static void CopyOle(string inputFile, string outputFile)
        {
            using (PresentationDocument sourceDocument = PresentationDocument.Open(inputFile, true))
            {
                using (PresentationDocument targetDocument = PresentationDocument.Open(outputFile, true))
                {
                    var sourceSlidePart = sourceDocument.PresentationPart.SlideParts.First();
                    var targetSlidePart = targetDocument.PresentationPart.SlideParts.First();

                    
                    foreach (var element in sourceSlidePart.Slide.CommonSlideData.ShapeTree.ChildElements)
                    {
                        //clones an element, does not copy the actual relationship target (e.g. ppt\embeddings\oleObject1.bin)
                        var elementClone = element.CloneNode(true);                      
                        
                        //for each cloned OleObject, fix its relationship
                        foreach(var clonedOleObject in elementClone.Descendants&lt;OleObject&gt;())
                        {
                            //find the original EmbeddedObjectPart in the source document
                            //(we can use the id from the clonedOleObject to do that, since it contained the same id
                            // as the source ole object)
                            var sourceObjectPart = sourceSlidePart.GetPartById(clonedOleObject.Id);

                            //create a new EmbeddedObjectPart in the target document and copy the data from the original EmbeddedObjectPart
                            var targetObjectPart = targetSlidePart.AddEmbeddedObjectPart(sourceObjectPart.ContentType);
                            targetObjectPart.FeedData(sourceObjectPart.GetStream());

                            //update the relationship target on the clonedOleObject to point to the newly created EmbeddedObjectPath
                            clonedOleObject.Id = targetSlidePart.GetIdOfPart(targetObjectPart);
                        }

                        //add cloned element to the document
                        targetSlidePart.Slide.CommonSlideData.ShapeTree.Append(elementClone);
                    }
                    targetDocument.PresentationPart.Presentation.Save();
                }
            }
        }
    }
}
</code></pre>
<hr />
<p>As for troubleshooting, the <a href=""https://chrome.google.com/webstore/detail/ooxml-tools/bjmmjfdegplhkefakjkccocjanekbapn?hl=en"" rel=""nofollow noreferrer"">OOXML Tools</a> chrome extension was helpful. <br>
It allows to compare the structure of two documents, so it is way easier to analyze what went wrong.</p>
<p>Examples:</p>
<ul>
<li>if you were to only clone all elements, you could see that /ppt/embeddings/* and /ppt/media/* would be missing
<a href=""https://i.stack.imgur.com/gjoDD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gjoDD.png"" alt=""enter image description here"" /></a></li>
<li>or you can check whether the relationships are correct (e.g. input document uses &quot;rId1&quot; to reference the embedded data and the output document uses &quot;R3a2fa0c37eaa42b5&quot;)
<a href=""https://i.stack.imgur.com/Hq6IW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Hq6IW.png"" alt=""enter image description here"" /></a><br><br>
<a href=""https://i.stack.imgur.com/ERZo5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ERZo5.png"" alt=""enter image description here"" /></a></li>
</ul>
","11240642","","","","","2020-09-04 09:26:47","","","","0","","","","CC BY-SA 4.0"
"66072472","2","","66072471","2021-02-06 00:41:12","","10","","<p>First off: keep in mind that Firebase Realtime Database is best when used to keep data in sync between the client and the database server (or between multiple clients) by using a long-lived listener. On Android you do this with <code>addValueEventListener</code>, which you should try to use whenever possible.</p>
<p>But in some cases you’ll want to read a value from the database only once. So let's see if I can answer the questions in turn, starting with the most important one:</p>
<h1>Which method should I use when I want to read a value from the database once?</h1>
<p><strong>If you need to read a value from the database only once, use the new <code>get()</code> method.</strong></p>
<p>In Java that looks like this:</p>
<pre><code>ref.get().addOnCompleteListener(new OnCompleteListener&lt;DataSnapshot&gt;() {
    @Override
    public void onComplete(@NonNull Task&lt;DataSnapshot&gt; task) {
        if (!task.isSuccessful()) {
            Log.e(&quot;firebase&quot;, &quot;Error getting data&quot;, task.getException());
        }
        else {
            Log.d(&quot;firebase&quot;, String.valueOf(task.getResult().getValue()));
        }
    }
});
</code></pre>
<p>And in Kotlin it is:</p>
<pre><code>ref.get().addOnSuccessListener {
    Log.i(&quot;firebase&quot;, &quot;Got value ${it.value}&quot;)
}.addOnFailureListener{
    Log.e(&quot;firebase&quot;, &quot;Error getting data&quot;, it)
}
</code></pre>
<h2>Why do you recommend using <code>get()</code> when <code>addListenerForSingleValueEvent</code> is mentioned so much more?</h2>
<p>We introduced <code>addListenerForSingleValueEvent</code> in our first Android SDK, and it has been there ever since. Over the years a lot of tutorials have been written, and a lot of questions have been asked and answered.</p>
<p>We’re updating the documentation of course. But there’s no way we can get all tutorials updated. So for the foreseeable future, there will be more mentions of <code>addListenerForSingleValueEvent</code> than of the new <code>get()</code> method.</p>
<h3>what is the difference between <code>get()</code> and <code>addListenerForSingleValueEvent</code>?</h3>
<p>As said: the <code>addListenerForSingleValueEvent</code> method has been part of the Firebase Android SDK for as long as it exists, and is used to read a value from the database once. It does this by:</p>
<ol>
<li>Attaching a listener with <code>addValueEventListener</code></li>
<li>Waiting for the value to show up from the persistence layer</li>
<li>Calling <code>onDataChange</code></li>
<li>Removing the listener</li>
</ol>
<p>This worked really well... until we introduced disk caching in version 2.0 of the SDK (way back at I/O 2015). Before that, all values in step 2 would always come from the server, either because the client already had a listener, or because this would attach the first listener to the server. But with disk caching, if you had previously read the value but currently had no listener to it, step 2 will read the value from the disk cache, and your <code>onDataChange</code> will be called with that value immediately. Even if the value on the server has been updated since. In fact, behind the scenes the listener will update the value in the disk cache, but only after calling your <code>onDataChange</code> with the (possibly stale) value from the cache.</p>
<p>While this behavior can be explained, it is not what almost anyone wanted. Unfortunately we found this edge case too late to classify it as a simple implementation bug and fix it. So we left it in, and recommended that folks <em>either</em> use disk persistence <em>or</em> use <code>addListenerToSingleValueEvent</code>, but not both. Or you could call <code>keepSynced(true)</code> on the same reference/query as a workaround. All messy, and not good.</p>
<p>Fast forward 5+ years, and we finally introduced a new method that doesn’t have this awkward behavior anymore. And since Android APIs have moved on quite a bit since 2015, we also use a (slightly) more modern method signature: <code>Task&lt;DataSnapshot&gt; get()</code>.</p>
","209103","","209103","","2021-02-06 21:10:48","2021-02-06 21:10:48","","","","3","","","","CC BY-SA 4.0"
"66996192","2","","65224327","2021-04-08 01:31:20","","1","","<p>I got the same error when migrating to <strong>Spring Boot 2.4.4</strong> which forced me to migrate to <strong>Spring Cloud 2020.0.1</strong> as well. In my case, the error was due to <em>Bootstrap</em>, provided by <code>spring-cloud-commons</code>, not being any longer enabled by default. I had to re-enabled it by adding the following new starter in my <code>build.gradle</code> file as stated <a href=""https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#breaking-changes"" rel=""nofollow noreferrer"">here</a>:</p>
<pre><code>implementation 'org.springframework.cloud:spring-cloud-starter-bootstrap'
</code></pre>
<p>You say your app doesn't use Spring Cloud, so I'm not sure why you ended up facing which seems to be the same issue. Hopefully this workaround might work for you and help out others using Spring Cloud.</p>
<hr />
<p>To fix the failing JUnit 4 tests, I have just added it as a dependency:</p>
<pre><code>testImplementation 'junit:junit:4.13' 
</code></pre>
","7066647","","7066647","","2021-11-27 14:46:30","2021-11-27 14:46:30","","","","0","","","","CC BY-SA 4.0"
"73820602","2","","65080685","2022-09-22 20:58:09","","0","","<p>Note: For WebdriverIO on Windows 10, this suppresses the error messages for me:</p>
<pre><code>&quot;goog:chromeOptions&quot;: { &quot;excludeSwitches&quot;: [&quot;enable-logging&quot;] }
</code></pre>
","20065052","","","","","2022-09-22 20:58:09","","","","0","","","","CC BY-SA 4.0"
"60438900","2","","60286204","2020-02-27 17:37:11","","0","","<p>I think your service provider is using an apache server . 
if yes then please reset .htacess file (it is server configuration file used to controling server settings including redirects).</p>
","11727445","","","","","2020-02-27 17:37:11","","","","2","","","","CC BY-SA 4.0"
"60451385","2","","60286204","2020-02-28 12:05:32","","2","","<p>Doing application side https forcing behind a reverse proxy is tricky. Generally it is better to let the reverse proxy do the forcing, and set the proxy to communicate on https only to avoid any application side forcing. (If the application has https capabilities of course)</p>

<p>If you must do it from the application, then the proxy must include the necessary headers for the application to evaluate the original connection context. And it may have to know the original hostname and basepath if you rewrite that.</p>

<p>Please review the instructions for asp.net core Forwarded Headers Middleware.
<a href=""https://learn.microsoft.com/en-us/aspnet/core/host-and-deploy/proxy-load-balancer"" rel=""nofollow noreferrer"">https://learn.microsoft.com/en-us/aspnet/core/host-and-deploy/proxy-load-balancer</a></p>

<p>As to why that behaves differently depending on your type of internet connection is a bit of a mystery.</p>
","2824577","","","","","2020-02-28 12:05:32","","","","1","","","","CC BY-SA 4.0"
"62494551","2","","62494522","2020-06-21 04:56:50","","9","","<p>Source code of <code>Instant.now()</code><sup>1</sup>, which you could easily find yourself if you use an IDE<sup>2</sup>:</p>
<pre class=""lang-java prettyprint-override""><code>public static Instant now() {
    return Clock.systemUTC().instant();
}
</code></pre>
<p><sup><em>1) Copied from OpenJDK 14</em></sup><br />
<sup><em>2) In Eclipse, you place cursor on <code>now()</code> and press F3 to see the source code. <br />In IntelliJ, press F4, or choose View &gt; Jump to Source, or on a Mac ⌘+click.</em></sup></p>
<p>It is guaranteed that all compliant versions of Java will do it that way, since it is part of the contract defined for the method, i.e. it is so <strong>documented</strong> in the javadoc of <a href=""https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/time/Instant.html#now()"" rel=""nofollow noreferrer""><code>now()</code></a>:</p>
<blockquote>
<p>This will query the <a href=""https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/time/Clock.html#systemUTC()"" rel=""nofollow noreferrer"">system UTC clock</a> to obtain the current instant.</p>
</blockquote>
<p>That link leads to <a href=""https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/time/Clock.html#systemUTC()"" rel=""nofollow noreferrer""><code>Clock.systemUTC()</code></a>.</p>
","5221149","","642706","","2022-04-23 03:30:31","2022-04-23 03:30:31","","","","4","","","","CC BY-SA 4.0"
"63788915","2","","63788646","2020-09-08 07:18:22","","5","","<p>EDIT: Loking at vernou's answer - i was wrong, i'll leave this here because some may prefer to have different steps and we all love copying from SO.</p>
<p>The Task you're using does not contain that power, but you can (like i have) opt to zip it yourself instead:</p>
<pre class=""lang-yaml prettyprint-override""><code>- task: DotNetCoreCLI@2
  inputs:
    command: 'publish'
    publishWebProjects: false
    projects: |
      **/*Client.csproj
      **/*WorkerService.csproj
      **/*Server.csproj
    arguments: '-c $(BuildConfiguration) -o $(Build.StagingDirectory)/ci-build --no-build --self-contained -r $(runtime)'
    zipAfterPublish: false

# Archive the /staging/ci-build folder to /staging/RemoteData.&lt;BuildNumber&gt;
- task: ArchiveFiles@2
  inputs:
    rootFolderOrFile: '$(Build.StagingDirectory)/ci-build'
    includeRootFolder: false
    archiveType: 'zip'
    archiveFile: '$(Build.ArtifactStagingDirectory)/RemoteData.$(Build.BuildNumber).zip'
    replaceExistingArchive: true

# Publish the zipfile as artifact
- task: PublishBuildArtifacts@1
  inputs:
    PathtoPublish: '$(Build.ArtifactStagingDirectory)/RemoteData.$(Build.BuildNumber).zip'
    ArtifactName: 'RemoteData.$(Build.BuildNumber)'
    publishLocation: 'Container'
</code></pre>
<p>This has the added benefit of being able to more closely manage your jobs:</p>
<p><a href=""https://i.stack.imgur.com/dSbwv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dSbwv.png"" alt=""enter image description here"" /></a></p>
<p>As you can see each step is laid out separately here.</p>
","4122889","","4122889","","2020-09-08 08:02:07","2020-09-08 08:02:07","","","","3","","","","CC BY-SA 4.0"
"67132006","2","","65224327","2021-04-16 20:47:39","","3","","<p>when ever you do upgrades on spring, pls always look at the <a href=""https://spring.io/projects/spring-cloud"" rel=""nofollow noreferrer"">spring / cloud compatibility matrix</a> and then upgrades the versions for both spring and cloud accordingly:</p>
<p>Also, pls note that you may not have added spring cloud as direct dependency but it may be coming into your final jar as a <em>transitive dependency</em> so its always better to add below spring cloud dependency as direct dependency management in your pom to stay away from any conflicts:</p>
<pre><code>&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
            &lt;version&gt;${spring.cloud-version}&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
</code></pre>
","5370480","","","","","2021-04-16 20:47:39","","","","1","","","","CC BY-SA 4.0"
"67228976","2","","67222143","2021-04-23 11:15:51","","13","","<p>The <a href=""https://stackoverflow.com/a/49386744/298225"">default rule for JavaScript when converting a <code>Number</code> value to a decimal numeral</a> is to use just enough digits to distinguish the <code>Number</code> value. Specifically, this arises from step 5 in clause 7.1.12.1 of the ECMAScript 2017 Language Specification, per the linked answer. (It is 6.1.6.1.20 in the 2020 version.)</p>
<p>So while 5,726,718,050,568,503,296 is representable, printing it yields “5726718050568503000” because that suffices to distinguish it from the neighboring representable values, 5,726,718,050,568,502,272 and 5,726,718,050,568,504,320.</p>
<p>You can request more precision in the conversion to string with <code>.toPrecision</code>, as in <code>x.toPrecision(21)</code>.</p>
","298225","","","","","2021-04-23 11:15:51","","","","0","","","","CC BY-SA 4.0"
"68136129","2","","68136128","2021-06-25 19:16:49","","11","","
<h3>PowerShell CLI fundamentals:</h3>
<ul>
<li><p><strong>PowerShell editions</strong>: The CLI of the legacy, bundled-with-Windows <em><strong>Windows PowerShell</strong></em> edition is <strong><a href=""https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_powershell_exe"" rel=""noreferrer""><code>powershell.exe</code></a></strong>, whereas that of the cross-platform, install-on-demand <strong><a href=""https://github.com/PowerShell/PowerShell/blob/master/README.md"" rel=""noreferrer""><em>PowerShell (Core) 7+</em></a></strong> edition is <strong><a href=""https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_Pwsh"" rel=""noreferrer""><code>pwsh.exe</code></a></strong> (just <strong><code>pwsh</code></strong> on Unix-like platforms).</p>
</li>
<li><p><strong>Interactive use</strong>:</p>
<ul>
<li><p>By default, unless code to execute is specified (via <code>-Command</code> (<code>-c</code>) or <code>-File</code> (<code>-f</code>, see below), an interactive session is entered. However, unlike in POSIX-compatible shells such as <code>bash</code>, <strong>you can use <code>-NoExit</code> to still enter an interactive session <em>after</em> executing code</strong>. This is especially handy for troubleshooting command lines when the CLI is called without a preexisting console window.</p>
</li>
<li><p>Use <strong><code>-NoLogo</code></strong> to suppress the startup text that is shown when entering an interactive session (not needed if code to execute is passed). <a href=""https://github.com/PowerShell/PowerShell/issues/15644"" rel=""noreferrer"">GitHub issue #15644</a> suggest <em>not</em> showing this startup text <em>by default</em>.</p>
</li>
<li><p>To <strong>opt out of telemetry / update notifications</strong>, define the following environment variables <em>before</em> entering an interactive session: <code>POWERSHELL_TELEMETRY_OPTOUT=1</code> / <code>POWERSHELL_UPDATECHECK=Off</code></p>
</li>
</ul>
</li>
<li><p><strong>Parameters and defaults</strong>:</p>
<ul>
<li><p>All <strong>parameter names are case-<em>insensitive</em></strong> (as PowerShell generally is); most parameters <strong>have short aliases</strong>, such as <strong><code>-h</code></strong> and <strong><code>-?</code></strong> for <strong><code>-Help</code></strong>, which shows command-line help, which with <code>pwsh</code> (but not <code>powershell.exe</code>) also lists these short aliases.</p>
<ul>
<li>Caveat: For long-term stability of your code, you should either use the full parameter names or their official aliases. Note that PowerShell's &quot;elastic syntax&quot; also allows you to use <em>prefixes</em> of parameter names <em>ad hoc</em>, as long as such a prefix <em>unambiguously</em> identifies the target parameter; e.g., <code>-ver</code> unambiguously targets <code>-version</code> <em>currently</em>, but - at least hypothetically - such a call could break in the future if a new parameter whose name also starts with <code>ver</code> were to be introduced.</li>
</ul>
</li>
<li><p><a href=""https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_Pwsh"" rel=""noreferrer""><code>pwsh</code></a> supports <em>more</em> parameters than <code>powershell.exe</code>, such as <code>-WorkingDirectory</code> (<code>-wd</code>).</p>
</li>
<li><p>There are <strong>two (mutually exclusive) ways to pass code to execute</strong>, in which case the PowerShell process exits automatically when execution ends; pass <code>-NonInteractive</code> to prevent use of interactive commands in the code or <code>-NoExit</code> to keep the session open after execution:</p>
<ul>
<li><p><strong><code>-Command</code> (<code>-c</code>)</strong> is for <strong>passing <em>arbitrary PowerShell commands</em></strong>, which may be passed either as a single string or as individual arguments, which, after removing (unescaped) double-quotes, are later joined with spaces and then interpreted as PowerShell code.</p>
</li>
<li><p><strong><code>-File</code> (<code>-f</code>)</strong> is for <strong>invoking <em>script files</em> (<code>.ps1</code>)</strong> with pass-through arguments, which are treated as <em>verbatim</em> values.</p>
</li>
<li><p><strong>These parameters must come <em>last</em> on the command line</strong>, because all subsequent arguments are interpreted as part of the command being passed / the script-file call.</p>
</li>
<li><p>See <a href=""https://stackoverflow.com/a/57443822/45375"">this answer</a> for guidance on when to use <code>-Command</code> vs. <code>-File</code>, and the bottom section for quoting / escaping considerations.</p>
</li>
<li><p>It is <strong>advisable to use <code>-Command</code> (<code>-c</code>) or <code>-File</code> (<code>-f</code>) <em>explicitly</em></strong>, because <strong>the two editions have different <em>defaults</em></strong>:</p>
<ul>
<li><code>powershell.exe</code> defaults to <code>-Command</code> (<code>-c</code>)</li>
<li><code>pwsh</code> defaults to <code>-File</code> (<code>-f</code>), a change that was necessary for supporting shebang lines on Unix-like platforms.</li>
</ul>
</li>
<li><p>Unfortunately, <strong>even with <code>-Command</code> (<code>-c</code>) or <code>-File</code> (<code>-f</code>), <a href=""https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_Profiles"" rel=""noreferrer"">profiles</a> (initialization files) are <em>loaded by default</em></strong> (unlike POSIX-compatible shells such as <code>bash</code>, which only do so when starting <em>interactive</em> shells).</p>
<ul>
<li><p>Therefore, it is <strong>advisable to routinely precede <code>-Command</code> (<code>-c</code>) or <code>-File</code> (<code>-f</code>) with <code>-NoProfile</code> (<code>-nop</code>)</strong>, which suppresses profile loading for the sake of both avoiding extra overhead and a more predictable execution environment (given that profiles can make changes that affect all code executed in a session).</p>
</li>
<li><p><a href=""https://github.com/PowerShell/PowerShell/issues/8072"" rel=""noreferrer"">GitHub proposal #8072</a> discusses introducing a <em>separate CLI (executable)</em> that does <em>not</em> load profiles in combination with these parameters and could also improve other legacy behaviors that the existing executables cannot change for the sake of backward-compatibility.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Character encoding (applies to both in- and output streams)</strong>:</p>
<ul>
<li><p>Note: The <strong>PowerShell CLIs only ever process <em>text</em></strong><sup>[1]</sup>, both on input and output, never raw byte data; what the CLIs output by default is the same text you would see in a PowerShell session, which for complex objects (objects with properties) means human-friendly formatting <em>not</em> designed for programmatic processing, so <strong>to output complex objects it's better to emit them in a <em>structured</em> text-based format, such as JSON</strong>.</p>
<ul>
<li>Note what while you can use <code>-OutputFormat xml</code> (<code>-of xml</code>) to get CLIXML output, which uses XML for object serialization, this particular format is of little use <em>outside</em> of PowerShell; ditto for accepting CLIXML input via stdin (<code>-InputFormat xml</code> / <code>-if xml</code>).</li>
</ul>
</li>
<li><p>On <strong>Windows</strong>, the PowerShell CLIs respect the console's code page, as reflected in the output from <code>chcp</code> and, inside PowerShell, in <code>[Console]::InputEncoding</code>. A console's code page defaults to <strong>the system's active OEM code page</strong>.</p>
<ul>
<li><p><strong>Caveat</strong>: OEM code pages such as <a href=""https://en.wikipedia.org/wiki/Code_page_437"" rel=""noreferrer""><code>437</code></a> on US-English systems are fixed, single-byte character encodings limited to 256 characters in total. <strong>To get full Unicode support, you must switch to code page <code>65001</code></strong> <em>before</em> calling a PowerShell CLI (from <code>cmd.exe</code>, call <code>chcp 65001</code>); while this works in both PowerShell editions, <code>powershell.exe</code> unfortunately switches the console to a raster font in this case, which causes many Unicode characters not to <em>display</em> properly; however, the actual data is not affected.</p>
<ul>
<li><strong>On Windows 10, you may switch to UTF-8 <em>system-wide</em></strong>, which sets both the OEM and the ANSI code page to <code>65001</code>; note, however, that this <strong>has far-reaching consequences</strong>, and that the feature is still in beta as of this writing - see <a href=""https://stackoverflow.com/a/57134096/45375"">this answer</a>.</li>
</ul>
</li>
</ul>
</li>
<li><p>On <strong>Unix</strong>-like platforms (<code>pwsh</code>), <strong>UTF-8</strong> is <em>invariably</em> used (even if the active locale (as reported by <code>locale</code>) is <em>not</em> UTF-8-based, but that is very rare these days).</p>
</li>
</ul>
</li>
<li><p><strong><em>Input</em>-stream (stdin) handling</strong> (received via <em>stdin</em>, either piped to a CLI call or provided via input redirection <code>&lt;</code>):</p>
<ul>
<li><p>To process stdin input <strong>as data</strong>:</p>
<ul>
<li><p>Explicit use of the <a href=""https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_Automatic_Variables#input"" rel=""noreferrer"">automatic <code>$input</code> variable</a> is required.</p>
</li>
<li><p>This in turn means that in order to pass stdin input to a <em>script file</em> (<code>.ps1</code>), <code>-Command</code> (<code>-c</code>) rather than <code>-File</code> (<code>-f</code>) must be used. Note that this makes any arguments passed to the script (symbolized with <code>...</code> below) subject to interpretation by PowerShell (whereas with <code>-File</code> they would be used verbatim):<br />
<code>-c &quot;$Input | ./script.ps1 ...&quot;</code></p>
</li>
</ul>
</li>
<li><p>To process stdin input <strong>as code</strong> (<code>pwsh</code> only, seems to be broken in <code>powershell.exe</code>):</p>
<ul>
<li>While passing PowerShell code to execute via stdin works in principle (by default, which implies <code>-File -</code>, and also with <code>-Command -</code>), it <strong>exhibits undesirable pseudo-interactive behavior and prevents passing of arguments</strong>: see <a href=""https://github.com/PowerShell/PowerShell/issues/3223"" rel=""noreferrer"">GitHub issue #3223</a>; e.g.:<br />
<code>echo &quot;Get-Date; 'hello'&quot; | pwsh -nologo -nop</code></li>
</ul>
</li>
</ul>
</li>
<li><p><strong><em>Output</em>-stream (stdout, stderr) handling</strong>:</p>
<ul>
<li><p>(Unless you use a script block (<code>{ ... }</code>), which only works from <em>inside</em> PowerShell, see below), <strong><em>all</em> 6 PowerShell's <a href=""https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_Redirection"" rel=""noreferrer"">output streams</a> are sent to <em>stdout</em>, including <em>errors</em>(!)</strong> (the latter are normally sent to <em>stderr</em>).</p>
<ul>
<li><p>However, when you apply an - external - stderr <em>redirection</em> you can selectively suppress error-stream output (<code>2&gt;NUL</code> from <code>cmd.exe</code>, <code>2&gt;/dev/null</code> on Unix) or send it to a file (<code>2&gt;errs.txt</code>).</p>
</li>
<li><p>See the bottom section of <a href=""https://stackoverflow.com/a/15669365/45375"">this answer</a> for more information.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr />
<h3>Quoting and escaping of the <code>-Command</code> (<code>-c</code>) and <code>-File</code> (<code>-f</code>) arguments:</h3>
<p><strong>When calling <em>from PowerShell</em></strong> (rarely needed):</p>
<ul>
<li><p><strong>There is rarely a need to call the PowerShell CLI <em>from</em> PowerShell</strong>, as as any command or script can simply be called <em>directly</em> and, conversely, calling the CLI introduces overhead due to creating a child process and results in loss of type fidelity.</p>
</li>
<li><p>If you still need to, the most robust approach is to <strong>use a <a href=""https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_Script_Blocks"" rel=""noreferrer"">script block</a> (<code>{ ... }</code>)</strong>, which avoids all quoting headaches, because you can use PowerShell's own syntax, as usual. Note that using script blocks <em>only</em> works from inside PowerShell, and that you cannot refer to the <em>caller's</em> variables in the script block; however, you can use the <code>-args</code> parameter to pass arguments (based on the caller's variables) to the script block, e.g., <code>pwsh -c { &quot;args passed: $args&quot; } -args foo, $PID</code>; using script blocks has additional benefits with respect to output streams and supporting data types other than strings; see <a href=""https://stackoverflow.com/a/57404296/45375"">this answer</a>.</p>
<pre class=""lang-sh prettyprint-override""><code># From PowerShell ONLY
PS&gt; pwsh -nop -c { &quot;Caller PID: $($args[0]); Callee PID: $PID&quot; } -args $PID
</code></pre>
</li>
</ul>
<p><strong>When calling from <em>outside</em> PowerShell</strong> (the typical case):</p>
<p>Note:</p>
<ul>
<li><p><code>-File</code> (<code>-f</code>) arguments <em>must</em> be passed as <em>individual arguments</em>: the script-file path, followed by arguments to pass to the script, if any. Both the script-file path and the pass-through arguments are used <em>verbatim</em> by PowerShell, after having stripping (unescaped) double quotes on Window<sup>[2]</sup>.</p>
</li>
<li><p><code>-Command</code> (<code>-c</code>) arguments <em>may</em> be passed as multiple arguments, but in the end PowerShell simply joins them together with spaces, after having stripped (unescaped) double quotes on Windows, before interpreting the resulting string <em>as PowerShell code</em> (as if you had submitted it in a PowerShell session).</p>
<ul>
<li><strong>For robustness and conceptual clarity, it is best to pass the command(s) as a <em>single argument</em> to <code>-Command</code> (<code>-c</code>)</strong>, which <strong>on Windows requires a <em>double</em>-quoted string (<code>&quot;...&quot;</code>)</strong> (although the overall <code>&quot;...&quot;</code> enclosure isn't strictly necessary for robustness in no-shell invocation environments such as Task Scheduler and some CI/CD and configuration-management environments, i.e. in cases where it isn't <code>cmd.exe</code> that processes the command line first).</li>
</ul>
</li>
<li><p>Again, see <a href=""https://stackoverflow.com/a/57443822/45375"">this answer</a> for guidance on when to use <code>-File</code> (<code>-f</code>) vs. when to use <code>-Command</code> (<code>-c</code>).</p>
</li>
<li><p>To <em>test-drive</em> a command line, call it from a <code>cmd.exe</code> console window, or, in order to simulate a no-shell invocation, use <kbd>WinKey-R</kbd> (the <code>Run</code> dialog) and use <code>-NoExit</code> as the first parameter in order to keep the resulting console window open.</p>
<ul>
<li>Do <em>not</em> test from <em>inside</em> PowerShell, because PowerShell's own parsing rules will result in <em>different</em> interpretation of the call, notably with respect to recognizing <code>'...'</code> (single-quoting) and potential up-front expansion of <code>$</code>-prefixed tokens.</li>
</ul>
</li>
</ul>
<p>On <strong>Unix</strong>, <em>no</em> special considerations apply (this includes Unix-on-Windows environments such as WSL and Git Bash):</p>
<ul>
<li><p>You only need to satisfy the <em>calling</em> shell's syntax requirements. Typically, programmatic invocation of the PowerShell CLI uses the POSIX-compatible system default shell on Unix, <code>/bin/sh</code>), which means that inside <code>&quot;...&quot;</code> strings, <em>embedded</em> <code>&quot;</code> must be escaped as <code>\&quot;</code>, and <code>$</code> characters that should be passed through <em>to PowerShell</em> as <code>\$</code>; the same applies to interactive calls from POSIX-compatible shells such as <code>bash</code>; e.g.:</p>
<pre class=""lang-sh prettyprint-override""><code># From Bash: $$ is interpreted by Bash, (escaped) $PID by PowerShell.
$ pwsh -nop -c &quot; Write-Output \&quot;Caller PID: $$; PowerShell PID: \$PID \&quot; &quot;

# Use single-quoting if the command string need not include values from the caller:
$ pwsh -nop -c ' Write-Output &quot;PowerShell PID: $PID&quot; '
</code></pre>
</li>
</ul>
<p>On <strong>Windows</strong>, things are more complicated:</p>
<ul>
<li><p><code>'...'</code> (single-quoting) can only be used with <code>-Command</code> (<code>-c</code>) and never has <em>syntactic</em> function on the PowerShell CLI <em>command line</em>; that is, single quotes are always preserved and interpreted as verbatim string literals when the parsed-from-the-command-line argument(s) are later interpreted as PowerShell code; see <a href=""https://stackoverflow.com/a/61124361/45375"">this answer</a> for more information.</p>
</li>
<li><p><code>&quot;...&quot;</code> (double-quoting) <em>does</em> have syntactic command-line function, and <em>unescaped</em> double quotes are <em>stripped</em>, which in the case of <code>-Command</code> (<code>-c</code>) means that they are <em>not</em> seen as part of the code that PowerShell ultimate executes. <strong><code>&quot;</code> characters you want to <em>retain</em> must be <em>escaped</em></strong> - even if you pass your command as individual arguments rather than as part of a single string.</p>
<ul>
<li><p><strong><code>powershell.exe</code></strong> requires <code>&quot;</code> to be escaped as <strong><code>\&quot;</code></strong><sup>[3]</sup> (sic) - even though <em>inside</em> PowerShell it is <code>`</code> (backtick) that acts as the escape character; however <code>\&quot;</code> is the most widely established convention for escaping <code>&quot;</code> chars. on Windows <em>command lines</em>.</p>
<ul>
<li><p>Unfortunately, from <code>cmd.exe</code> this can <em>break</em> calls, if the characters between two <code>\&quot;</code> instances happen to contain <code>cmd.exe</code> metacharacters such as <code>&amp;</code> and <code>|</code>; <strong>the robust - but cumbersome and obscure - choice is <code>&quot;^&quot;&quot;</code></strong>; <code>\&quot;</code> will <em>typically</em> work, however.</p>
<pre class=""lang-sh prettyprint-override""><code>:: powershell.exe: from cmd.exe, use &quot;^&quot;&quot; for full robustness (\&quot; often, but not always works)
powershell.exe -nop -c &quot; Write-Output &quot;^&quot;&quot;Rock  &amp;  Roll&quot;^&quot;&quot; &quot;

:: With double nesting (note the ` (backticks) needed for PowerShell's syntax).
powershell.exe -nop -c &quot; Write-Output &quot;^&quot;&quot;The king of `&quot;^&quot;&quot;Rock  &amp;  Roll`&quot;^&quot;&quot;.&quot;^&quot;&quot; &quot;

:: \&quot; is OK here, because there's no &amp; or similar char. involved.
powershell.exe -nop -c &quot; Write-Output \&quot;Rock  and  Roll\&quot; &quot;
</code></pre>
</li>
</ul>
</li>
<li><p><strong><code>pwsh.exe</code></strong> accepts <strong><code>\&quot;</code></strong> or <strong><code>&quot;&quot;</code></strong>.</p>
<ul>
<li><p><code>&quot;&quot;</code> is the robust choice when calling from <code>cmd.exe</code> (<code>&quot;^&quot;&quot;</code> does <em>not</em> work robustly, because it normalizes whitespace; again, <code>\&quot;</code> will <em>typically</em>, but not always work).</p>
<pre class=""lang-sh prettyprint-override""><code>:: pwsh.exe: from cmd.exe, use &quot;&quot; for full robustness
pwsh.exe -nop -c &quot; Write-Output &quot;&quot;Rock  &amp;  Roll&quot;&quot; &quot;

:: With double nesting (note the ` (backticks)).
pwsh.exe -nop -c &quot; Write-Output &quot;&quot;The king of `&quot;&quot;Rock  &amp;  Roll`&quot;&quot;.&quot;&quot; &quot;

:: \&quot; is OK here, because there's no &amp; or similar char. involved.
pwsh.exe -nop -c &quot; Write-Output \&quot;Rock  and  Roll\&quot; &quot;
</code></pre>
</li>
</ul>
</li>
<li><p>In <strong><em>no-shell</em> invocation scenarios</strong>, <strong><code>\&quot;</code> can safely be used in <em>both</em> editions</strong>; e.g., from the Windows <code>Run</code> dialog (<kbd>WinKey-R</kbd>); note that the first command would <em>break</em> from <code>cmd.exe</code> (<code>&amp;</code> would be interpreted as <code>cmd.exe</code>'s statement separator, and it would attempt to execute a program named <code>Roll</code> on exiting the PowerShell session; try without <code>-noexit</code> to see the problem instantly):</p>
<pre class=""lang-sh prettyprint-override""><code>  pwsh.exe -noexit -nop -c &quot; Write-Output \&quot;Rock  &amp;  Roll\&quot; &quot;

  pwsh.exe -noexit -nop -c &quot; Write-Output \&quot;The king of `\&quot;Rock  &amp;  Roll`\&quot;.\&quot; &quot;
</code></pre>
</li>
</ul>
</li>
</ul>
<hr />
<p>See also:</p>
<ul>
<li><p><strong>Quoting headaches</strong> also apply in the <em>inverse</em> scenario: <strong>calling external programs <em>from</em> a PowerShell session</strong>: see <a href=""https://stackoverflow.com/a/66837948/45375"">this answer</a>.</p>
</li>
<li><p>When calling from <code>cmd.exe</code>, <strong><code>%...%</code>-enclosed tokens such as <code>%USERNAME%</code></strong> are <strong>interpreted as (environment) variable references</strong> by <code>cmd.exe</code> itself, up front, both when used unquoted and inside <code>&quot;...&quot;</code> strings (and <code>cmd.exe</code> has no concept of <code>'...'</code> strings to begin with). While typically desired, <strong>sometimes this needs to be prevented</strong>, and, unfortunately, the solution depends on whether a command is being invoked <em>interactively</em> or <em>from a batch file</em> (<code>.cmd</code>, <code>.bat</code>): see <a href=""https://stackoverflow.com/a/31420292/45375"">this answer</a>.</p>
</li>
</ul>
<hr />
<p><sup>[1] This also applies to PowerShell's in-session communication with external programs.</sup></p>
<p><sup>[2] On Unix, where no process-level command lines exist, PowerShell only ever receives an array of <em>verbatim</em> arguments, which are the result of the calling shell's parsing of its command line.</sup></p>
<p><sup>[3] Use of <code>&quot;&quot;</code> is <em>half broken</em>; try <code>powershell.exe -nop -c &quot;Write-Output 'Nat &quot;&quot;King&quot;&quot; Cole'&quot;</code> from <code>cmd.exe</code>.</sup></p>
","45375","","45375","","2021-06-27 19:23:13","2021-06-27 19:23:13","","","","1","","","","CC BY-SA 4.0"
"70099258","2","","65224327","2021-11-24 16:03:17","","0","","<p>I had the same error for JUnit 4 tests after migration my project to Spring Boot 2.5.6. Adding JUnit 4 dependencies did not fix this error as well as migration JUnit 4 tests to JUnit 5. My  project does not define Spring Cloud dependencies in build.gradle so in order to find where those dependencies come from I simply ran gradle command:</p>
<pre><code>gradle dependencyInsight --dependency org.springframework.cloud
</code></pre>
<p>and saw that spring cloud dependencies were pulled within one of the custom libraries. Upgrade spring cloud dependencies to a <a href=""https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes"" rel=""nofollow noreferrer"">compatible version</a> there and reimport custom library fixed the error.</p>
","2315526","","2315526","","2022-01-22 17:08:03","2022-01-22 17:08:03","","","","0","","","","CC BY-SA 4.0"
"67414243","2","","67267094","2021-05-06 08:10:43","","0","","<p>You need to use Dokka for auto documenting Kotlin project. You can find a brief explanation of Dokka on <a href=""https://medium.com/geekculture/auto-generate-kotlin-android-documentation-with-dokka-d9e9075bc001"" rel=""nofollow noreferrer"">this article</a> and also read the documentation if required.</p>
<blockquote>
<h1 id=""using-the-gradle-plugin-qaad"">Using the Gradle plugin</h1>
<p>The preferred way is to use plugins block.</p>
<pre><code>build.gradle.kts:

plugins {
    id(&quot;org.jetbrains.dokka&quot;) version &quot;1.4.32&quot; }

repositories {
    mavenCentral() }
</code></pre>
<p>The plugin adds <code>dokkaHtml</code>, <code>dokkaJavadoc</code>, <code>dokkaGfm</code> and <code>dokkaJekyll</code>
tasks to the project.</p>
</blockquote>
<blockquote>
<h1 id=""applying-plugins-6pv1"">Applying plugins</h1>
<p>Dokka plugin creates Gradle configuration for each output format in
the form of <code>dokka${format}Plugin</code>:</p>
<pre><code>dependencies {
    dokkaHtmlPlugin(&quot;org.jetbrains.dokka:kotlin-as-java-plugin:1.4.32&quot;) }
</code></pre>
<p>You can also create a custom Dokka task and add plugins directly
inside:</p>
<pre><code>val customDokkaTask by creating(DokkaTask::class) {
    dependencies {
        plugins(&quot;org.jetbrains.dokka:kotlin-as-java-plugin:1.4.32&quot;)
    } }
</code></pre>
<p>Please note that dokkaJavadoc task will properly document only single
jvm source set</p>
<p>To generate the documentation, use the appropriate dokka${format}
Gradle task:</p>
<pre><code>./gradlew dokkaHtml
</code></pre>
<p>Please see the Dokka Gradle example project for an example.</p>
<p>Make sure you apply Dokka after <code>com.android.library</code> and
<code>kotlin-android</code>.</p>
<pre><code>buildscript {
    dependencies {
        classpath(&quot;org.jetbrains.kotlin:kotlin-gradle-plugin:${kotlin_version}&quot;)
        classpath(&quot;org.jetbrains.dokka:dokka-gradle-plugin:${dokka_version}&quot;)
    } } repositories {
    mavenCentral() } apply(plugin= &quot;com.android.library&quot;) apply(plugin= &quot;kotlin-android&quot;) apply(plugin= &quot;org.jetbrains.dokka&quot;)

dokkaHtml.configure {
    dokkaSourceSets {
        named(&quot;main&quot;) {
            noAndroidSdkLink.set(false)
        }   
    } }
</code></pre>
</blockquote>
<p>More at official GitHub repo - <a href=""https://github.com/Kotlin/dokka"" rel=""nofollow noreferrer"">https://github.com/Kotlin/dokka</a>
You may like <a href=""https://medium.com/geekculture/auto-generate-kotlin-android-documentation-with-dokka-d9e9075bc001"" rel=""nofollow noreferrer"">this article</a> as well.</p>
","9640177","","9640177","","2021-07-25 09:45:58","2021-07-25 09:45:58","","","","7","","","","CC BY-SA 4.0"
"67619540","2","","67619477","2021-05-20 11:34:27","","9","","<p>No it isn't well-defined. Suppose we replace all sequence point in your code with pseudo code &quot;SQ&quot;:</p>
<pre><code>SQ
int b = (a = 0 SQ a) + (a = 1 SQ a) SQ
</code></pre>
<p>Then we have <code>SQ a) + (a = 1 SQ</code> where two accesses and one side effect happens to <code>a</code> between sequence points, so it is still undefined behavior.</p>
<p>We could write well-defined (but of course very bad and fishy) code like this:</p>
<pre><code>(0, a = 0) + (0, a = 1)
</code></pre>
<p>The order of evaluation of the + operands is still unspecified, but the compiler must evaluate either parenthesis before moving on to the next. So there's always a comma operator sequence point between the side-effects/access of <code>a</code>.</p>
","584518","","584518","","2021-05-20 11:43:49","2021-05-20 11:43:49","","","","0","","","","CC BY-SA 4.0"
"67940440","2","","67913756","2021-06-11 16:21:43","","7","","<p>As I understand it, given that this is all very new, there is no guarantee that <code>asyncDetached</code> must schedule off the main thread.</p>
<p>In the <a href=""https://developer.apple.com/videos/play/wwdc2021/10254/"" rel=""noreferrer"">Swift Concurrency: Behind the Scenes</a> session, it's discussed that the scheduler will try to keep things on the same thread to avoid context switches. Given that though, I don't know how you would specifically avoid the main thread, but maybe we're not supposed to care as long as the task makes progress and never blocks.</p>
<p>I found the timestamp (23:18) that explains that there is no guarantee that the same thread will pick up a continuation after an await. <a href=""https://developer.apple.com/videos/play/wwdc2021/10254/?time=1398"" rel=""noreferrer"">https://developer.apple.com/videos/play/wwdc2021/10254/?time=1398</a></p>
","1131011","","1131011","","2021-06-11 16:33:40","2021-06-11 16:33:40","","","","1","","","","CC BY-SA 4.0"
"63788990","2","","63788646","2020-09-08 07:23:37","","1","","<p><code>dotnet publish</code> task copy file in the output and zip this folder. You can output to folder with a suffix like :</p>
<pre class=""lang-yaml prettyprint-override""><code>- task: DotNetCoreCLI@2
  displayName: 'dotnet build'
  inputs:
    command: 'build'
    projects: '$(solution)'

- task: DotNetCoreCLI@2
  displayName: 'dotnet publish'
  inputs:
    command: publish
    publishWebProjects: False
    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)/app_v1.5.7'
    zipAfterPublish: True

- task: PublishBuildArtifacts@1
  inputs:
    pathtoPublish: '$(Build.ArtifactStagingDirectory)' 
    artifactName: 'MyTool_LatestBuild'
</code></pre>
<p>You can define a build number and replace the suffix with :
<a href=""https://learn.microsoft.com/en-us/azure/devops/pipelines/process/run-number?view=azure-devops&amp;tabs=yaml"" rel=""nofollow noreferrer"">https://learn.microsoft.com/en-us/azure/devops/pipelines/process/run-number?view=azure-devops&amp;tabs=yaml</a></p>
<pre><code>...
- task: DotNetCoreCLI@2
  displayName: 'dotnet publish'
  inputs:
    command: publish
    publishWebProjects: False
    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)/app_$(Build.BuildNumber)'
    zipAfterPublish: True
...
</code></pre>
","2703673","","13302","","2020-09-14 09:24:35","2020-09-14 09:24:35","","","","3","","","","CC BY-SA 4.0"
"63790022","2","","63788646","2020-09-08 08:27:27","","14","","<p>1.Agree with <strong>Vernou</strong>. You can customize the name by specifying the folder name that contains your binaries. So we need to modify the <code>--output</code> argument of <code>dotnet publish</code> step and <code>PathtoPublish</code> argument of <code>PublishBuildArtifacts</code> step.</p>
<p>2.But to get Date time, you can use <a href=""https://learn.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&amp;tabs=yaml#build-variables"" rel=""noreferrer"">Build.BuildNumber</a> which is predefined variables.</p>
<p>My working sample:</p>
<pre><code>name: $(Date:yyyyMMdd)$(Rev:.r)

steps:
- task: DotNetCoreCLI@2
  inputs:
    command: 'build'
    projects: '**/*.csproj'

- task: DotNetCoreCLI@2
  displayName: 'dotnet publish'
  inputs:
    command: publish
    publishWebProjects: False
    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)/MyTool_$(Build.BuildNumber)'
    zipAfterPublish: True

- task: PublishBuildArtifacts@1
  inputs:
    PathtoPublish: '$(Build.ArtifactStagingDirectory)/MyTool_$(Build.BuildNumber)'
    ArtifactName: 'MyTool_LatestBuild'
    publishLocation: 'Container'
</code></pre>
<p>More details about using BuildNumber to get date, you can check <a href=""https://learn.microsoft.com/en-us/azure/devops/pipelines/process/run-number?view=azure-devops&amp;tabs=yaml"" rel=""noreferrer"">Configure run or build numbers</a>.</p>
<p><strong>The result:</strong></p>
<p><a href=""https://i.stack.imgur.com/H5Gif.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/H5Gif.png"" alt=""enter image description here"" /></a></p>
<p>We can control the format via modifying how we define the <code>Build.BuildNumber</code>(In Yaml, it's <code>name</code>). If we define <code>name: $(Date:yyyyMMdd)</code>, then the output zip would be <code>MyTool_20200908.zip</code>.</p>
","10910450","","10910450","","2020-09-08 08:35:36","2020-09-08 08:35:36","","","","2","","","","CC BY-SA 4.0"
"63938605","2","","63937663","2020-09-17 13:01:17","","7","","<p>tl;dr: Every class field (static or not) is internally wrapped in a method which gets invoked with the corresponding receiver (class or instance) at some point.</p>
<hr />
<p>So, I'm not sure on some of those details *, but basically this happens:</p>
<p>For every field with an initializer (static or not), a function/method is created, with the initializer as its body. So this</p>
<pre><code>static foo = () =&gt; this.v;
</code></pre>
<p>becomes <em>something</em> like this internally</p>
<pre><code>function () { () =&gt; this.v }
</code></pre>
<p>That's in <a href=""https://tc39.es/proposal-static-class-features/#sec-method-definitions-runtime-semantics-classelementevaluation"" rel=""noreferrer"">the proposal</a> in step 28, which eventually leads to <a href=""https://tc39.es/proposal-class-fields/#runtime-semantics-class-field-definition-evaluation"" rel=""noreferrer""><code>ClassFieldDefinitionEvaluation</code> in this spec</a>. The method is created in step 3.e.</p>
<p>The static fields (which are methods now) are then taken and called with the class object itself as <em>receiver</em> (i.e. the <code>this</code> value inside that intermediate method is set to the class object). This happens in step 34.a, which leads to <a href=""https://tc39.es/proposal-class-fields/#sec-define-field"" rel=""noreferrer""><code>DefineField</code> in this spec</a>. Finally the return value (in your case the arrow function) is used as value for the actual property.</p>
<p>Expressed as code, this is roughly what happens:</p>
<pre><code>class Foo {}

Foo.v = function() { return 123; }.call(Foo);
Foo.bar = function() { return () =&gt; this.v; }.call(Foo);
</code></pre>
<hr />
<p>*: I'm not quite clear how the intermediate method <em>returns</em> the value, but there is probably something that says that the last expression of the function body is returned or something.</p>
","218196","","218196","","2020-09-17 13:06:21","2020-09-17 13:06:21","","","","1","","","","CC BY-SA 4.0"
"67943247","2","","67913756","2021-06-11 20:39:38","","5","","<p>Even if you do the testing to figure out the exact threading behavior of awaiting on <code>@MainActor</code> functions, you should not rely on it. As in @fullsailor's answer, the language explicitly does not guarantee that work will be resumed on the same thread after an await, so this behavior could change in any OS update. In the future, you may be able to request a specific thread by using a custom executor, but this is not currently in the language. See <a href=""https://github.com/rjmccall/swift-evolution/blob/custom-executors/proposals/0000-custom-executors.md"" rel=""noreferrer"">https://github.com/rjmccall/swift-evolution/blob/custom-executors/proposals/0000-custom-executors.md</a> for more details.</p>
<p>Further, it hopefully should not cause any problems that you are running on the main thread. See <a href=""https://developer.apple.com/videos/play/wwdc2021/10254/?time=2074"" rel=""noreferrer"">https://developer.apple.com/videos/play/wwdc2021/10254/?time=2074</a> for details about how scheduling works. You should not be afraid of blocking the main thread by calling a <code>@MainActor</code> function and then doing expensive work afterwards: if there is more important UI work available, this will be scheduled before your work, or your work will be run on another thread. If you are particularly worried, you can use <code>Task.yield()</code> before your expensive work to give Swift another opportunity to move your work off the main thread. See <em>Voluntary Suspension</em> <a href=""https://github.com/apple/swift-evolution/blob/main/proposals/0304-structured-concurrency.md"" rel=""noreferrer"">here</a> for more details on <code>Task.yield()</code>.</p>
<p>In your example, it is likely that Swift decided that it is not worth the performance hit of context switching <em>back</em> from the main thread since it was already there, but if the main thread were more saturated, you might experience different behavior.</p>
<p>Edit:</p>
<p>The behavior you're seeing with <code>async let</code> is because this spawns a child task which runs concurrently with the work you are doing. Thus, since that child is running on the main thread, your other code isn't. See <a href=""https://forums.swift.org/t/concurrency-structured-concurrency/41622"" rel=""noreferrer"">https://forums.swift.org/t/concurrency-structured-concurrency/41622</a> for more details on child tasks.</p>
","3397903","","3397903","","2021-06-11 20:53:32","2021-06-11 20:53:32","","","","4","","","","CC BY-SA 4.0"
"67962899","2","","67913756","2021-06-13 21:48:30","","3","","<p>The following formulation works, and solves the entire problem very elegantly, though I'm a little reluctant to post it because I don't really understand how it works:</p>
<pre><code>override func viewDidLoad() {
    super.viewDidLoad()
    Task {
        await self.test2()
    }
}
nonisolated func test2() async {
    print(&quot;test 1&quot;, Thread.isMainThread) // false
    let bounds = await self.view.bounds // access on main thread!
    print(&quot;test 2&quot;, bounds, Thread.isMainThread) // false
}
</code></pre>
<p>I've tested the <code>await self.view.bounds</code> call up the wazoo, and both the <code>view</code> access and the <code>bounds</code> access are on the main thread. The <code>nonisolated</code> designation here is essential to ensuring this. The need for this and the concomitant need for <code>await</code> are very surprising to me, but it all seems to have to do with the nature of actors and the fact that a UIViewController is a MainActor.</p>
","341994","","341994","","2021-09-22 14:11:44","2021-09-22 14:11:44","","","","0","","","","CC BY-SA 4.0"
"70182138","2","","70042442","2021-12-01 09:54:24","","2","","<p>With <strong>T</strong> as <code>int</code> and <strong>D</strong> as <code>* foo</code>, the &quot;T D&quot; does not give <em>ident</em> the type <strong>T</strong>, but <strong>pointer to T</strong>.</p>
<p>The second part of the <code>if</code>:</p>
<blockquote>
<p>If ... <strong>and</strong> the type specified for ident in the declaration “T D” is
“derived-declarator-type-list T”</p>
</blockquote>
<p>seems to make sure that the <em>nesting</em> is correct.</p>
<p>With two stars, you would have to use D2 - D1 - D before you reach the direct declarator.</p>
<p>The second example:</p>
<pre><code>typedef int *int_ptr;
const int_ptr foo;
</code></pre>
<p>shows how tricky it can get; <code>const</code> is far away from <em>ident</em>, but still the pointer is constant, not the data.</p>
<p>The specs call this a clarification - now <em>that</em> is a mistake.</p>
<hr />
<p>Interestingly in the next section &quot;6.7.6.2 Array declarators&quot; there is a <em>footnote</em> after the corresponding semantical definition:</p>
<blockquote>
<p>When several &quot;array of&quot; specifications are adjacent, a
multidimensional array is declared.</p>
</blockquote>
<p>The case of several adjacent &quot;pointer of&quot; specifications is not mentioned. Kind of a &quot;mistake&quot;.</p>
<hr />
<p>In 1988 the &quot;Reference Manual&quot; had the D1 and D switched (!), but otherwise  the wording is almost identical. (there is <em>type-modifier</em> instead of <em>derived-declarator-type-list</em>).</p>
<p>The examples are similar: the main example is <code>int *ap[]</code>:</p>
<blockquote>
<p>Here ap[] plays the role of D1; a declaration &quot;int ap[]&quot; would ...</p>
</blockquote>
<p>With <code>int **pp</code>, <code>*pp</code> plays that role.</p>
","","user17074451","","user17074451","2021-12-04 08:18:05","2021-12-04 08:18:05","","","","2","","","","CC BY-SA 4.0"
"64034157","2","","64034156","2020-09-23 18:26:24","","11","","<p><em><strong>Initial troubleshooting:</strong></em></p>
<ol>
<li>My very initial thought was that it could be control M characters in .pem file OR in private key. But when checked key looked fine.</li>
<li>Then I thought it could be inbound rule issue, that we are NOT allowed to do ssh to aws server but NO I was wrong when I checked configuration of server I found it was fine and 22 port was there for ssh.</li>
<li>Then I thought if .pem file has proper permissions or not  I checked and yes it was having read permissions on all users(whoever has had access to it).</li>
</ol>
<hr />
<p>Obviously nothing of above worked; enough talks so coming now to actual solution now :)</p>
<p><em><strong>ACTUAL FIX with complete steps:</strong></em></p>
<ul>
<li>Since I am using Windows 10 O.S in my P.C so I have thought to go for any other medium to do <code>ssh</code>, hence I tried <em><strong>SSH</strong></em> with <em><strong>powershell</strong></em> as follows.</li>
</ul>
<pre><code>PS E:\test&gt; ssh -i &quot;aws_key_generator.pem&quot; ubuntu@singh_server_test.compute.amazonaws.com
</code></pre>

<pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @
WARNING: UNPROTECTED PRIVATE KEY FILE! @ 
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Permissions for 'aws_key_generator.pem' are too open.
It is required that your private key files are NOT accessible by others.
This private key will be ignored.
Load key &quot;aws_key_generator.pem&quot;: bad permission
</code></pre>
<ul>
<li>Above has given me lot of confidence and shown path to me what to do next. I immediately checked permissions of file again (which was READ and verified as mentioned in my initial troubleshooting column above). Then I saw that other groups are present in permissions and then I removed inheritance by going to <code>&quot;Right click on .pem file&quot;--&gt;&quot;Properties&quot;--&gt;&quot;Security&quot;--&gt;&quot;Advance&quot;</code> and disabled “Inheritance” from there.</li>
<li>Then I only kept &quot;admin&quot; group with READ ONLY permissions to it and saved the properties of file.</li>
<li>Again I tried to SSH from PUTTY(using private key file generated from PuttyGen mentioned in problem statement) but it failed.</li>
<li>But when I tried from powershell command(which used .pem file) it had been successful login now.</li>
<li>Then I su as root and went to /home/ubuntu/.ssh directory and checked authorized_keys file and couldn’t see PUBLIC key inside it.</li>
<li>So I added Public key generated by <code>PuttyGen</code> to <em><strong>&quot;authorized_keys&quot;</strong></em> and saved it.</li>
<li>Again I tried to login to server by Putty with passing private key to it and I was successfully able to login now BINGO :)</li>
</ul>
<p>I have fixed issue with this work around fix and thought to share with all here; other solutions are welcomed too, cheers and Happy learning.</p>
","5866580","","5866580","","2020-09-24 00:14:10","2020-09-24 00:14:10","","","","5","","","","CC BY-SA 4.0"
"64036514","2","","64034156","2020-09-23 21:30:01","","2","","<p>It appears that you are logging into an Ubuntu server.</p>
<p>For that, the username should be <code>ubuntu</code>, not <code>ec2-user</code>.</p>
","174777","","","","","2020-09-23 21:30:01","","","","1","","","","CC BY-SA 4.0"
"66013236","2","","66013007","2021-02-02 16:00:56","","3","","<p>This is a rather strange situation.  I think there are a couple of things going on.</p>
<p>First of all, a string in C ends by definition at the first <code>\0</code>.  You can always scoff at this rule, for example by writing a string literal with an explicit <code>\0</code> in the middle of it.  When you do, though, the characters after the <code>\0</code> are mostly invisible.  Very few standard library functions are able to see them, because of course just about everything that interprets a C string will stop at the first <code>\0</code> it finds.</p>
<p>However: the string you pass as the first argument to <code>scanf</code> is typically parsed twice -- and by &quot;parsed&quot; I mean actually interpreted as a scanf format string possibly containing special <code>%</code> sequences.  It's always going to be parsed at run time, by the actual copy of <code>scanf</code> in your C run-time library.  But it's typically also parsed by the compiler, at compile time, so that the compiler can warn you if the % sequences don't match the actual arguments you call it with.  (The run-time library code for <code>scanf</code>, of course, is unable to perform this checking.)</p>
<p>Now, of course, there's a pretty significant potential problem here: what if the parsing performed by the compiler is in some way different than the parsing performed by the actual <code>scanf</code> code in the run-time library?  That might lead to confusing results.</p>
<p>And, to my considerable surprise, it looks like the scanf format parsing code in compilers <em>can</em> (and in some cases does) do something special and unexpected.  clang doesn't (it doesn't complain about the malformed string at all), but gcc says both &quot;no closing ‘]’ for ‘%[’ format&quot; and &quot;embedded ‘\0’ in format&quot;.  So it's noticing.</p>
<p>This is possible (though still surprising) because the compiler, at least, can see the whole string literal, and is in a position to notice that the null character is an explicit one inserted by the programmer, not the more usual implicit one appended by the compiler.  And indeed the warning &quot;embedded ‘\0’ in format&quot; emitted by gcc proves that gcc, at least, is quite definitely written to accommodate this possibility.  (See the footnote below for a bit more on the compiler's ability to &quot;see&quot; the whole string literal.)</p>
<p>But the second question is, why does it (seem to) work at runtime?  What is the actual <code>scanf</code> code in the C library doing?</p>
<p>That code, at least, has no way of knowing that the <code>\0</code> was explicit and that there are &quot;real&quot; characters following it.  That code simply must stop at the first <code>\0</code> that it finds.  So it's operating as if the format string was</p>
<pre><code>&quot;%31[^&quot;
</code></pre>
<p>That's a malformed format string, of course.  The run-time library code isn't required to do anything reasonable.  But my copy, like yours, is able to read the full string &quot;foo&quot;.  What's up with that?</p>
<p>My guess is that after seeing the <code>%</code> and the <code>[</code> and the <code>^</code>, and deciding that it's going to scan characters not matching some set, it's perfectly willing to, in effect, infer the missing <code>]</code>, and sail on matching characters from the scanset, which ends up having no excluded characters.</p>
<p>I tested this by trying the variant</p>
<pre><code>    x = scanf(&quot;%31[^\0o]&quot;, buf);
</code></pre>
<p>This also matched and printed &quot;foo&quot;, not &quot;f&quot;.</p>
<p>Obviously things are nothing like guaranteed to work like this, of course.  @AnttiHaapala has already posted an answer showing that his C RTL declines to scan &quot;foo&quot; with the malformed scan string at all.</p>
<hr />
<p>Footnote:
Most of the time, an embedded in <code>\0</code> in a string truly, prematurely ends it.  Most of the time, everything following the <code>\0</code> is effectively invisible, because at run time, every piece of string interpreting code will stop at the first <code>\0</code> it finds, with no way to know whether it was one explicitly inserted by the programmer or implicitly appended by the compiler.  But as we've seen, the compiler can tell the difference, because the compiler (obviously) <em>can</em> see the entire string literal, exactly as entered by the programmer.  Here's proof:</p>
<pre><code>char str1[] = &quot;Hello, world!&quot;;
char str2[] = &quot;Hello\0world!&quot;;

printf(&quot;sizeof(str1) = %zu, strlen(str1) = %zu\n&quot;, sizeof(str1), strlen(str1));
printf(&quot;sizeof(str2) = %zu, strlen(str2) = %zu\n&quot;, sizeof(str2), strlen(str2));
</code></pre>
<p>Normally, <code>sizeof</code> on a string literal gives you a number one bigger than <code>strlen</code>.  But this code prints:</p>
<pre><code>sizeof(str1) = 14, strlen(str1) = 13
sizeof(str2) = 13, strlen(str2) = 5
</code></pre>
<p>Just for fun I also tried:</p>
<pre><code>char str3[5] = &quot;Hello&quot;;
</code></pre>
<p>This time, though, <code>strlen</code> gave a larger number:</p>
<pre><code>sizeof(str3) = 5, strlen(str3) = 10
</code></pre>
<p>I was mildly lucky.  <code>str3</code> has no trailing <code>\0</code>, neither one inserted by me nor appended by the compiler, so <code>strlen</code> sails off the end, and could easily have counted hundreds or thousands of characters before finding a random <code>\0</code> somewhere in memory, or crashing.</p>
","3923896","","3923896","","2021-02-02 17:17:43","2021-02-02 17:17:43","","","","1","","","","CC BY-SA 4.0"
"66013611","2","","66013007","2021-02-02 16:23:04","","4","","<p>First of all, Clang <a href=""https://godbolt.org/z/4555Y"" rel=""nofollow noreferrer"">totally fails to output any meaningful diagnostics here</a>, whereas GCC <a href=""https://godbolt.org/z/4555Yf"" rel=""nofollow noreferrer"">knows exactly what is happening</a> - so yet again GCC 1 - 0 Clang.</p>
<p>And as for the format string - well, it doesn't work. The format argument to <code>scanf</code> is a string. The string ends at terminating null, i.e. the format string you're giving to <code>scanf</code> is</p>
<pre><code>scanf(&quot;%31[^&quot;, buf);
</code></pre>
<p>On my computer, compiling the program gives</p>
<pre><code>% gcc scanf.c
scanf.c: In function ‘main’:
scanf.c:8:20: warning: no closing ‘]’ for ‘%[’ format [-Wformat=]
    8 |     x = scanf(&quot;%31[^\0]&quot;, buf);
      |                    ^
scanf.c:8:21: warning: embedded ‘\0’ in format [-Wformat-contains-nul]
    8 |     x = scanf(&quot;%31[^\0]&quot;, buf);
      |                     ^~
</code></pre>
<p>The scanset must have the closing right bracket <code>]</code>, otherwise the conversion specifier is invalid. If conversion specifier is invalid, the behaviour is undefined.</p>
<p>And, on my computer running it,</p>
<pre><code>% printf 'foo\n\0bar' | ./a.out
x = 0, buf=
</code></pre>
<p>Q.E.D.</p>
","918959","","918959","","2021-02-02 17:00:39","2021-02-02 17:00:39","","","","8","","","","CC BY-SA 4.0"
"66017159","2","","66013007","2021-02-02 20:29:02","","1","","<blockquote>
<p>Why can a null character be embedded in a conversion specifier for scanf?</p>
</blockquote>
<p>A <em>null character</em> cannot directly be specified as part of a <em>scanset</em> as in <code>&quot;%31[^\0]&quot;</code> as the parsing of the string ends with the first <em>null character</em>.</p>
<p><code>&quot;%31[^\0]&quot;</code> is parsed by <code>scanf()</code> as if it was <code>&quot;%31[^&quot;</code>.  As it is an invalid <code>scanf()</code>
specifier, UB will likely follow.  A compiler may provide diagnostics on more than what <code>scanf()</code> sees.</p>
<hr />
<p>A <em>null character</em> can be part of a <em>scanset</em> as in <code>&quot;%31[^\n]&quot;</code>.  This will read in all characters, including the <em>null character</em>, other than <code>'\n'</code>.</p>
<p>In the unusual case of reading <em>null chracters</em>, to determine the number of characters read scanned, use <code>&quot;%n&quot;</code>.</p>
<pre><code>int n = 0;
scanf(&quot;%31[^\n]%n&quot;, buf, &amp;n);
scanf(&quot;%*1[\n]&quot;); // Consume any 1 trailing \n
if (n) {
  printf(&quot;First part of buf=%s, %d characters read &quot;, buf, n);
}
</code></pre>
","2410359","","2410359","","2021-02-02 22:00:36","2021-02-02 22:00:36","","","","3","","","","CC BY-SA 4.0"
"67051785","2","","67051520","2021-04-12 01:57:17","","14","","<p><strong>tl;dr:</strong> The behavior of <code>type(of:)</code> depends on whether <code>T</code> is existential or concrete, and the type system can't effectively reflect the actual return type syntactically, so it's handled directly in the type checking system. <code>Metatype</code> is specifically not bound in code to be the same as <code>T</code> so that the effective behavior can be specialized. <code>Metatype</code> and <code>T</code> are not necessarily related.</p>
<hr />
<p><code>type(of:)</code> is special in that its behavior differs depending on the type passed into it. Specifically, it has special behavior for existential types by being able to reach <em>through</em> the existential box to get the underlying type of the value passed in. For example:</p>
<pre><code>func myType&lt;T&gt;(of value: T) -&gt; T.Type {
    return T.self
}

protocol Foo {}
struct X: Foo {}

let x = X()
print(type(of: x), &quot;vs.&quot;, myType(of: x)) // =&gt; X vs. X

let f: Foo = X()
print(type(of: f), &quot;vs.&quot;, myType(of: f)) // =&gt; X vs. Foo
</code></pre>
<p>When given an existential type like <code>Foo</code>, a return type of <code>T.Type</code> could <em>only</em> return the metatype of the existential itself (i.e. <code>Foo.self</code>), as opposed to the metatype of the <em>value</em> inside of the existential container (<code>X.self</code>). So instead of returning <code>T.Type</code>, <code>type(of:)</code> returns an <em>unrelated</em> type <code>Metadata</code> which is bound to the correct type in the type checker itself. This is the edge case you were looking for:</p>
<blockquote>
<p>My guess is that there is some edge case where <code>type(of:)</code> will return a completely unrelated type to <code>T</code>, but I have no idea what that is.</p>
</blockquote>
<p>If you look in <a href=""https://github.com/apple/swift/blob/a5a79f23c0257c36c297d3c1b9275a873434468a/lib/Sema/TypeChecker.h"" rel=""noreferrer""><code>lib/Sema/TypeChecker.h</code></a>, you can see some special semantics declarations for several stdlib function types:</p>
<pre><code>/// Special-case type checking semantics for certain declarations.
enum class DeclTypeCheckingSemantics {
  /// A normal declaration.
  Normal,

  /// The type(of:) declaration, which performs a &quot;dynamic type&quot; operation,
  /// with different behavior for existential and non-existential arguments.
  TypeOf,

  /// The withoutActuallyEscaping(_:do:) declaration, which makes a nonescaping
  /// closure temporarily escapable.
  WithoutActuallyEscaping,

  /// The _openExistential(_:do:) declaration, which extracts the value inside
  /// an existential and passes it as a value of its own dynamic type.
  OpenExistential,
};
</code></pre>
<p>The key one here is <code>TypeOf</code>, which is indeed returned for functions with the <code>@_semantics(&quot;typechecker.type(of:)&quot;)</code> attribute you noted. (You can see how that attribute is checked in <a href=""https://github.com/apple/swift/blob/a5a79f23c0257c36c297d3c1b9275a873434468a/lib/Sema/TypeChecker.cpp#L505"" rel=""noreferrer""><code>TypeChecker::getDeclTypeCheckingSemantics</code></a>)</p>
<p>If you go looking for usages of <code>TypeOf</code>, there are two key locations in type-checking:</p>
<ol>
<li><a href=""https://github.com/apple/swift/blob/583d617254af7067f36e87cc276373232af73ca1/lib/Sema/ConstraintSystem.cpp#L2028"" rel=""noreferrer""><code>getTypeOfReferenceWithSpecialTypeCheckingSemantics</code></a> which injects the type constraint in the type checker constraint system. <strong><code>type(of:)</code> is handled here as an <em>overload</em>, because <code>Metadata</code> isn't actually bound; the constraint solver here applies an effective type checking constraint which constrains <code>Metadata</code> to be the actual type of <code>value</code>.</strong> The key here is that <code>type(of:)</code> is written in this way so that it <em>would be</em> an overload, and handled here.</li>
<li><a href=""https://github.com/apple/swift/blob/fd8e34913a68d4d5dfed6213aa5efbcd27dafbf8/lib/Sema/CSApply.cpp#L7515"" rel=""noreferrer""><code>ExprRewriter::finishApply</code></a> which performs the actual expression rewriting in the AST to replace the return type with the effective actual type of the value</li>
</ol>
<p>From (1):</p>
<pre><code>// Proceed with a &quot;DynamicType&quot; operation. This produces an existential
// metatype from existentials, or a concrete metatype from non-
// existentials (as seen from the current abstraction level), which can't
// be expressed in the type system currently.
</code></pre>
<p>Pulling back some history — this was implemented back in commit <a href=""https://github.com/apple/swift/commit/1889fde2284916e2c368c9c7cc87906adae9155b"" rel=""noreferrer"">1889fde2284916e2c368c9c7cc87906adae9155b</a>. The commit message from Joe is illuminating:</p>
<blockquote>
<p>Resolve <code>type(of:)</code> by overload resolution rather than parse hackery.</p>
<p><code>type(of:)</code> has behavior whose type isn't directly representable in Swift's type system, since it produces both concrete and existential metatypes. In Swift 3 we put in a parser hack to turn <code>type(of: &lt;expr&gt;)</code> into a DynamicTypeExpr, but this effectively made <code>type(of:)</code> a reserved name. It's a bit more principled to put <code>Swift.type(of:)</code> on the same level as other declarations, even with its special-case type system behavior, and we can do this by special-casing the type system we produce during overload resolution if <code>Swift.type(of:)</code> shows up in an overload set. This also lays groundwork for handling other declarations we want to ostensibly behave like normal declarations but with otherwise inexpressible types, viz. <code>withoutActuallyEscaping</code> from SE-0110.</p>
</blockquote>
<p>Since then, as we can see from <code>WithoutActuallyEscaping</code> and <code>OpenExistential</code>, other special functions have been rewritten to take advantage of this.</p>
","169394","","169394","","2021-04-12 14:08:51","2021-04-12 14:08:51","","","","2","","","","CC BY-SA 4.0"
"68906532","2","","68864640","2021-08-24 11:13:39","","6","","<p>You are right that such access is unsafe and Swift 5.5 today does not prevent this, unless you pass the <code>-warn-concurrency</code> flag explicitly.</p>
<p>Please refer to the <a href=""https://github.com/DougGregor/swift-evolution/blob/sendable-staging/proposals/nnnn-sendable-staging.md"" rel=""nofollow noreferrer"">Staging in Sendable checking</a> proposal (and <a href=""https://forums.swift.org/t/pitch-staging-in-sendable-checking/51341"" rel=""nofollow noreferrer"">forums post</a> which discuss the rollout plan of the checking feature).</p>
<p>You can also read about the general plan with regards to concurrency safety between now in Swift 5.5 and Swift 6 in the roadmap update here: <a href=""https://forums.swift.org/t/concurrency-in-swift-5-and-6/49337"" rel=""nofollow noreferrer"">Concurrency in Swift 5 and 6</a>.</p>
","","anon","","anon","2021-08-24 22:02:31","2021-08-24 22:02:31","","","","0","","","","CC BY-SA 4.0"
"70283057","2","","70042442","2021-12-08 23:40:41","","0","","<p>For the record, there are three answers that were deleted by their authors, supporting a conclusion that this aspect of the C standard is tricky. I do not believe the other current answer correctly matches the example source text (<code>int * const * foo</code>) to the symbols in the passage from the standard (<strong>T</strong>, <strong>D1</strong>, <em>type-qualifier-list</em>, and so on).</p>
<p>Thus I conclude this is indeed a mistake in the standard.</p>
<p>I believe a fix is simply to remove the last sentence, “For each type qualifier in the list, <em>ident</em> is a so-qualified pointer.” Any qualifier in the <em>type-qualifier</em> list is already incorporated, correctly, into the previous sentence, and any qualifier inside <em>D</em> is already incorporated in that declarator. So this seems like just a superfluous sentence that may have arisen inadvertently in some edit.</p>
","298225","","298225","","2021-12-12 20:54:38","2021-12-12 20:54:38","","","","0","","","","CC BY-SA 4.0"
"70304965","2","","70042442","2021-12-10 13:05:36","","0","","<p>Here is an alternative interpretation that makes the standard correct.</p>
<p>For</p>
<pre><code>int * const * foo
</code></pre>
<p>The form</p>
<pre><code>* type-qualifier-listopt D
</code></pre>
<p>tells that D in your example is <code>* foo</code></p>
<p>So I think <em>indent</em> is to be replaced with <code>* foo</code> instead of just <code>foo</code></p>
<p>So the standard says <code>* foo</code> is a <code>const</code> pointer.</p>
<p>which means that <code>foo</code> is a pointer to a <code>const</code> pointer.</p>
","4386427","","4386427","","2021-12-10 13:15:12","2021-12-10 13:15:12","","","","0","","","","CC BY-SA 4.0"
"71221828","2","","67913756","2022-02-22 13:03:02","","0","","<p>I had the same problem with a function which runs a long task and should always be run on a background thread. Ultimately using the new Swift async await syntax I could not find a easy way based on Task or TaskGroup to ensure this.
A Task.detached call will use a different thread as will the Task call itself. If this is called from the MainThread it will be another thread, if not it can be the main thread.
Ultimately I found a solution which always works - but looks very &quot;hacky&quot;.</p>
<ol>
<li><p>Make sure your background function is not isolated to the main thread by being part of a class that is a MainActor isolated class (like view controllers)</p>
<pre><code>nonisolated func iAllwaysRunOnBackground() {}
</code></pre>
</li>
<li><p>Test for main thread and if executed on the main thread call the function again in a Task, wait for execution and return</p>
<pre><code>nonisolated func iAllwaysRunOnBackground() async throws {
  if Thread.isMainThread {
     async let newTask = Task {
       try await self.iAllwaysRunOnBackground()
     }
    let _ = try await newTask.value
    return 
  }

  function body
}
</code></pre>
</li>
</ol>
","6819770","","","","","2022-02-22 13:03:02","","","","3","","","","CC BY-SA 4.0"
"73314035","2","","67267094","2022-08-11 00:24:28","","0","","<p>As someone relatively new to Android development, this took me a long time to figure out, so wanted to take the time to share what I found.</p>
<p>The solution for publishing aar libraries along with the documentation is to package a &quot;sources.jar&quot; artifact along with your aar. If you're familiar with iOS, then the sources.jar will essentially act as your header files for your code, where you can expose your unminified library API and KDocs with it. When a user with Android Studio/Gradle downloads your library, it will automatically pull in your sources.jar, and be able to link your aar to your KDocs within the IDE.</p>
<p>In your build.gradle, make sure you are using 'maven-publish'.</p>
<p>Create a new task that will build your sources.jar. Since I'm working with closed source, I didn't want to expose my entire library, so I hand select specific files that comprise my public API and its documentation:</p>
<pre><code>task androidSourcesJar(type: Jar) {
  group(&quot;documentation&quot;)
  classifier(&quot;sources&quot;)
  def sdkDir = &quot;$projectDir/src/main/java/com/project/sdk&quot;
  def publicAPI = [&quot;$sdkDir/MyLibAPI.kt&quot;,
                   &quot;$sdkDir/MyLibData.kt&quot;,
                   &quot;$sdkDir/MyLibNotificationInterface.kt&quot;,
                   &quot;$sdkDir/utils&quot;,
  from publicAPI
}
</code></pre>
<p>From there, we need Maven-publish to run this task and include it as an artifact to our maven repository. Everyone's maven publish setup looks a bit different, but simply add <code>artifact(tasks[&quot;androidSourcesJar&quot;])</code> to your publication block. Mine looked something like this:</p>
<pre><code>publishing {
  publications {
    aar(MavenPublication) {
        artifactId = &quot;mylib&quot;
        artifact(tasks[&quot;androidSourcesJar&quot;])
        artifact(&quot;$buildDir/outputs/aar/mylib-release.aar&quot;)
        ... (additional setup)
    }
  }
}
</code></pre>
<p>From there you can publish your aar as usual and the newly created source.jar will be published alongside it, allowing your users to access your Kdocs 🚀</p>
<p>That's it. It does seem a bit absurd to me (coming from iOS) how poorly documented this process is, even though most published libraries seem to have figured it out.</p>
","217208","","","","","2022-08-11 00:24:28","","","","0","","","","CC BY-SA 4.0"
"73510183","2","","67913756","2022-08-27 10:27:01","","1","","<p>Checking on which thread task is running is unreliable since swift concurrency may use same thread across multiple tasks to avoid context switches. You have to use actor isolation to make sure your tasks aren't executed on actor (this applies to any actor along with <code>MainActor</code>).</p>
<p>First of all, actors in swift are reentrant. This means whenever you are making an <code>async</code> call actor suspends current task until the method returns and proceeds to execute other tasks submitted. This makes sure actor is never blocked due to a long-running task. So if you are calling any <code>async</code> call inside <code>test</code> method and fear that the method will be executed on main thread then you have nothing to worry about. Since your ViewController class will be <code>MainActor</code> isolated your code becomes:</p>
<pre class=""lang-swift prettyprint-override""><code>override func viewDidLoad() {
    super.viewDidLoad()
    Task {
        await self.test()
    }
}

func getBounds() -&gt; CGRect {
    let bounds = self.view.bounds
    return bounds
}

func test() async {
    // long running async calls
    let bounds = self.getBounds()
    // long running async calls
}
</code></pre>
<p>Now if some of your long running calls are synchronous then you have to remove <code>test</code> method from <code>MainActor</code>'s isolation by applying <code>nonisolated</code> attribute. Also, creating Task with <code>Task.init</code> inherits the current actor context which is then executed on actor, to prevent this you have to use <code>Task.detached</code> to execute the <code>test</code> method:</p>
<pre class=""lang-swift prettyprint-override""><code>override func viewDidLoad() {
    super.viewDidLoad()
    Task.detached {
        await self.test()
    }
}

func getBounds() -&gt; CGRect {
    let bounds = self.view.bounds
    return bounds
}

nonisolated func test() async {
    // long running async calls
    // long running sync calls
    let bounds = await self.getBounds()
    // long running async calls
    // long running sync calls
}
</code></pre>
","13225760","","","","","2022-08-27 10:27:01","","","","0","","","","CC BY-SA 4.0"
"73537284","2","","67913756","2022-08-30 04:50:06","","2","","<p>A brief note that since the question was asked, the UIKit classes got marked with <code>@MainActor</code>, so the code in discussion would print <code>true</code> on both occasions. But the problem can still be reproducible with a &quot;regular&quot; class.</p>
<p>Now, getting back to the dicussed behaviour, it's expected, and as others have said its also logical:</p>
<ul>
<li>premature optimization is the root of all evil, thread context switches are expensive, so the runtime doesn't easily jump at doing them</li>
<li>the <code>test</code> function is not entirely in a concurrent context, because the code hops between the <code>MainActor</code> and your class, thus, the Swift runtime doesn't know that it has to get back to the cooperative thread pool.</li>
</ul>
<p>If you convert your class to an actor, you'll see the behaviour you expect. Here's a tweaked actor based on the code from the question:</p>
<pre class=""lang-swift prettyprint-override""><code>actor ThreadTester {
    func viewDidLoad() {
        Task.detached(priority: .userInitiated) {
            await self.test()
        }
    }

    @MainActor func getBounds() async -&gt; CGRect {
        .zero
    }

    func test() async {
        print(&quot;test 1&quot;, Thread.isMainThread) // false
        let bounds = await self.getBounds()
        print(&quot;test 2&quot;, Thread.isMainThread) // true
    }
}

Task {
    await ThreadTester().viewDidLoad()
}
</code></pre>
<p>You can toggle between <code>actor</code> and <code>class</code>, leaving the other code untouched, and you'll consistently see the two behaviours.</p>
<p>Swift's structured concurrency works best if all entities involved in concurrent operations are already part of the structured concurrency family, as in this case the compiler has all the necessary information to make informed decisions.</p>
","1974224","","","","","2022-08-30 04:50:06","","","","0","","","","CC BY-SA 4.0"
"60674947","2","","60644544","2020-03-13 17:34:06","","14","","<p>If you want to run an arbitrary TSQL batch and return a scalar value, you can do it like this:</p>

<pre><code>var p = new SqlParameter(""@result"", System.Data.SqlDbType.Int);
p.Direction = System.Data.ParameterDirection.Output;
context.Database.ExecuteSqlRaw(""set @result = next value for some_seq"", p);
var nextVal = (int)p.Value;
</code></pre>
","7297700","","","","","2020-03-13 17:34:06","","","","2","","","","CC BY-SA 4.0"
"62294950","2","","60644544","2020-06-10 02:40:54","","0","","<p>Ugly, but the best thing I could come up with:</p>

<pre><code>var connection = repcontext.Database.GetDbConnection();
connection.Open();
using var cmd = connection.CreateCommand();
cmd.CommandText = ""SELECT NEXT VALUE FOR AA.TransSeq;"";
var obj = cmd.ExecuteScalar();
connection.Close();
seqnum = (int)obj;
</code></pre>
","13458302","","10251345","","2020-06-10 03:24:08","2020-06-10 03:24:08","","","","1","","","","CC BY-SA 4.0"
"62421551","2","","60644544","2020-06-17 04:33:08","","5","","<p>In your fluent api configs you can create migration that set ID automatically to be next value from Sequence</p>

<pre><code>protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.HasSequence&lt;int&gt;(""OrderNumbers"");

    modelBuilder.Entity&lt;Order&gt;()
        .Property(o =&gt; o.OrderNo)
        .HasDefaultValueSql(""NEXT VALUE FOR shared.OrderNumbers"");
}
</code></pre>

<p>For creating sequence: </p>

<pre><code>protected override void OnModelCreating(ModelBuilder modelBuilder)
{
    modelBuilder.HasSequence&lt;int&gt;(""OrderNumbers"", schema: ""shared"")
        .StartsAt(1000)
        .IncrementsBy(5);
}
</code></pre>

<p>Read more from here: <a href=""https://www.talkingdotnet.com/use-sql-server-sequence-in-entity-framework-core-primary-key/"" rel=""noreferrer"">https://www.talkingdotnet.com/use-sql-server-sequence-in-entity-framework-core-primary-key/</a></p>
","5452961","","","","","2020-06-17 04:33:08","","","","1","","","","CC BY-SA 4.0"
"63017789","2","","63017136","2020-07-21 15:22:24","","0","","<p>Well, I gave it a try, and I included .Net5 as well, and as expected they're pretty much identical in performance.</p>
<p>I would take this as a sign to use more rigorous testing methodologies (Benchmark.NET), because at this point I'm positive you're not running the correct executable, and Benchmark.NET takes care of that for you.</p>
<pre><code>C:\Users\_\source\repos\ConsoleApp3\ConsoleApp3\bin\Release\net48&gt;ConsoleApp3.exe
Computed 4199.58 in 00:00:01.0134120
Computed 4199.58 in 00:00:01.0136130
Computed 4199.58 in 00:00:01.0163664
Computed 4199.58 in 00:00:01.0161655

C:\Users\_\source\repos\ConsoleApp3\ConsoleApp3\bin\Release\net5&gt;ConsoleApp3
Computed 4199.580000000003 in 00:00:01.0269673
Computed 4199.580000000003 in 00:00:01.0214385
Computed 4199.580000000003 in 00:00:01.0295102
Computed 4199.580000000003 in 00:00:01.0241006

C:\Users\_\source\repos\ConsoleApp3\ConsoleApp3\bin\Release\netcoreapp3.1&gt;ConsoleApp3
Computed 4199.580000000003 in 00:00:01.0234075
Computed 4199.580000000003 in 00:00:01.0216327
Computed 4199.580000000003 in 00:00:01.0227448
Computed 4199.580000000003 in 00:00:01.0328213
</code></pre>
","108796","","","","","2020-07-21 15:22:24","","","","9","","","","CC BY-SA 4.0"
"63019727","2","","63017136","2020-07-21 17:19:12","","4","","<p><strong>Cannot reproduce.</strong></p>
<p>Looks like <strong>.NET Core 3.1</strong> is faster at least for <strong>x86</strong>. I checked it 5 or more times for each build and the Output is nearly the same.</p>
<pre class=""lang-none prettyprint-override""><code>.NET Framework 4.8

Is 64 bits = False
Computed 4199,58 in 00:00:01.2679838
Computed 4199,58 in 00:00:01.1270864
Computed 4199,58 in 00:00:01.1163893
Computed 4199,58 in 00:00:01.1271687

Is 64 bits = True
Computed 4199,58 in 00:00:01.0910610
Computed 4199,58 in 00:00:00.9695353
Computed 4199,58 in 00:00:00.9601170
Computed 4199,58 in 00:00:00.9696420

.NET Core 3.1

Is 64 bits = False
Computed 4199,580000000003 in 00:00:00.9852276
Computed 4199,580000000003 in 00:00:00.9493986
Computed 4199,580000000003 in 00:00:00.9562083
Computed 4199,580000000003 in 00:00:00.9467359

Is 64 bits = True
Computed 4199,580000000003 in 00:00:01.0199652
Computed 4199,580000000003 in 00:00:00.9763987
Computed 4199,580000000003 in 00:00:00.9612935
Computed 4199,580000000003 in 00:00:00.9815544
</code></pre>
<hr />
<h3>Updated with new sample</h3>
<pre class=""lang-none prettyprint-override""><code>NET48: Is 64 bits = False
Average ms for calls to sum() = 110

NETCOREAPP3_1: Is 64 bits = False
Average ms for calls to sum() = 110
</code></pre>
<hr />
<h3>Hardware</h3>
<pre class=""lang-none prettyprint-override""><code>Intel(R) Core(TM) i7-4700HQ CPU @ 2.40GHz

Base speed: 2,40 GHz
Sockets:    1
Cores:  4
Logical processors: 8
Virtualization: Enabled
L1 cache:   256 KB
L2 cache:   1,0 MB
L3 cache:   6,0 MB
</code></pre>
<hr />
<h3>Bonus</h3>
<p>If the code is so performance-sensitive, maybe SIMD may help.</p>
<pre class=""lang-csharp prettyprint-override""><code>using System.Numerics;
</code></pre>
<pre class=""lang-csharp prettyprint-override""><code>const int ITERS = 100000;

int vectorSize = Vector&lt;double&gt;.Count;
Console.WriteLine($&quot;Vector size = {vectorSize}&quot;);
            
for (int trial = 0; trial &lt; 4; ++trial)
{
    double windowSum = 0;
    sw.Restart();
               
    for (int iter = 0; iter &lt; ITERS; ++iter)
    {
        Vector&lt;double&gt; accVector = Vector&lt;double&gt;.Zero;
        for (int i = 0; i &lt;= window.Length - vectorSize; i += vectorSize)
        {
            Vector&lt;double&gt; v = new Vector&lt;double&gt;(window, i);
            accVector += Vector.Abs(v);
        }
        windowSum = Vector.Dot(accVector, Vector&lt;double&gt;.One);
    }
               
    Console.WriteLine($&quot;Computed {windowSum} in {sw.Elapsed}&quot;);
}
</code></pre>
<p>Awesomeness of <strong>.NET Core</strong> is here :)</p>
<pre class=""lang-none prettyprint-override""><code>.NET Core 3.1

Is 64 bits = False
Vector size = 4
Computed 4199,58 in 00:00:00.3678926
Computed 4199,58 in 00:00:00.3046166
Computed 4199,58 in 00:00:00.2910941
Computed 4199,58 in 00:00:00.2900221

Is 64 bits = True
Vector size = 4
Computed 4199,58 in 00:00:00.3446433
Computed 4199,58 in 00:00:00.2616570
Computed 4199,58 in 00:00:00.2606452
Computed 4199,58 in 00:00:00.2582038
</code></pre>
","12888024","","12888024","","2020-07-22 12:16:58","2020-07-22 12:16:58","","","","12","","","","CC BY-SA 4.0"
"69309617","2","","69309346","2021-09-24 04:35:54","","5","","<p>Rust follow <a href=""https://llvm.org/docs/LangRef.html#noalias"" rel=""nofollow noreferrer""><code>noalias</code></a> model for <code>&amp;mut T</code> from LLVM see <a href=""https://doc.rust-lang.org/reference/behavior-considered-undefined.html#behavior-considered-undefined"" rel=""nofollow noreferrer"">Behavior considered undefined</a>:</p>
<blockquote>
<p>This indicates that memory locations accessed via pointer values based on the argument or return value are not also accessed, during the execution of the function, via pointer values not based on the argument or return value. This guarantee only holds for memory locations that are modified, by any means, during the execution of the function. The attribute on a return value also has additional semantics described below. The caller shares the responsibility with the callee for ensuring that these requirements are met.</p>
</blockquote>
<p>So If I get it correctly that mean simply having <code>i: &amp;mut u32</code> in argument list expect it should have no alias. Even use an auxiliary function like:</p>
<pre class=""lang-rust prettyprint-override""><code>pub unsafe fn assign_mixed(i: &amp;mut u32, j: *mut u32) -&gt; u32 {
    aux(i, j)
}

pub unsafe fn aux(i: *mut u32, j: *mut u32) -&gt; u32 {
    *i = 42;
    *j = 7;
    *i
}
</code></pre>
<p>Would not work.</p>
<p>I think the only way to have something similar would be to use <a href=""https://doc.rust-lang.org/std/cell/struct.UnsafeCell.html#"" rel=""nofollow noreferrer""><code>UnsafeCell</code></a> like:</p>
<pre class=""lang-rust prettyprint-override""><code>use std::cell::UnsafeCell;

pub unsafe fn assign_mixed(i: &amp;UnsafeCell&lt;u32&gt;, j: *mut u32) -&gt; u32 {
    *i.get() = 42;

    *j = 7;
    *i.get()
}
</code></pre>
<p>Would produce the desired assembler code. Be sure to not use <code>&amp;mut UnsafeCell</code> for this.</p>
","7076153","","7076153","","2021-09-24 09:23:05","2021-09-24 09:23:05","","","","7","","","","CC BY-SA 4.0"
"71604964","2","","60644544","2022-03-24 15:10:31","","1","","<p>For people suffering with oracle version of this problem, here's a solution:</p>
<pre><code>var p = new OracleParameter(&quot;result&quot;, OracleDbType.Decimal, null, System.Data.ParameterDirection.Output);
Database.ExecuteSqlRaw($&quot;BEGIN :result := my_seq.nextval; END;&quot;, p);
var nextVal = p.Value;
</code></pre>
","18045363","","","","","2022-03-24 15:10:31","","","","1","","","","CC BY-SA 4.0"